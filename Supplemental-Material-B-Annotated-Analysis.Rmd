---
title: "Supplemental Information B: Full Annotated Analysis and Reproducible Code"
subtitle: "Suppplemental Material for 'The Migration Experience: A Conceptual Framework and Systematic Scoping Review of Psychological Acculturation'"
author:
- █████████████████^1^ #Jannis Kreienkamp^1^
- ███████████████^1^ #Laura Bringmann^1^
- ████████████^1^ #Raili Engler^1^
- ██████████████^1^ #Peter de Jonge^1^
- ███████████^1^ #Kai Epstude^1^
- ^1^████████████████████ #University of Groningen
- "Author Information:"
- "Correspondence concerning this supplemental material should be addressed to ██████ ██████████, ██████████ ██ ██████████, █████████ ██ ██████████, █████ ██████████ ███, ████ ██ █████████ ████████████████. E-mail: █████████████████"
- 'The main manuscript is available at <a href="https://www.doi.org/ToBePublished" target="_blank">doi.org/ToBePublished</a>'
- 'The data repository for this manuscript is available at <a href="https://osf.io/n587w/?view_only=0809085870604eda8349baa90b4fd3e5" target="_blank">https://osf.io/n587w/?view_only=0809085870604eda8349baa90b4fd3e5</a>'
- 'The GitHub repository for this manuscript is available at <a href="https://github.com/maskedForPeerReview" target="_blank">github.com/maskedForPeerReview</a>'
- 'An interactive directory of all included acculturation scales is available at <a href="https://acculturation-review.shinyapps.io/scale-directory/" target="_blank">acculturation-review.shinyapps.io/scale-directory/</a>'
date: "Last updated: `r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2:
    fig_caption: yes
    md_extensions: +footnotes
    code_folding: hide
    mathjax: default
    theme: yeti
    toc: yes
    toc_float: yes
    number_sections: false
    css: style.css
    includes:
      in_header: "_includes/head-custom-rmd.html" 
editor_options:
  chunk_output_type: console
bibliography: references.bib
csl: apa.csl
---

<style type="text/css">
.main-container {
  max-width: 1300px;
  margin-left: auto;
  margin-right: auto;
}
.table {
  margin-left:auto; 
  margin-right:auto;
}
</style>


```{r setup, include=FALSE}
# R Studio Clean-Up
  cat("\014") # clear console
  #rm(list=ls()) # clear workspace - use restart R instead [cmd/alt + shift + F10]
  gc() # garbage collector
  
# Install and Load Packages
# !IMPORTANT!
# BEFORE FIRST RENDER:
# To install all relevant packages please run "renv::restore()" (or renv::init() and then initiate from lockfile) in the console before the first use to ensure that all packages are using the correct version.
# to store the packages in a contained library within the project folder: renv::settings$use.cache(FALSE) and add 'RENV_CONFIG_SANDBOX_ENABLED = FALSE' to an '.Renviron' file 
# remotes::install_github("rstudio/webshot2")
lib <- c("rmarkdown", "knitr", "remedy", "bookdown", "rmdfiltr", "psych",
         "ggplot2", "ggthemes", "haven", "RColorBrewer", "plotly", "forcats", "wordcloud", "visNetwork", "ggwordcloud", "gridExtra",
         "webshot2", "sessioninfo", 
         "data.table", "dplyr", "tidyr", "Hmisc", "kableExtra", "readxl", "stringr", "stringi", "reshape2",
         "tibble", "sqldf", "networkD3", "GGally", "ggstatsplot","hrbrthemes", "patchwork", "cowplot",
         "mada", "naniar", "stats", "matrixStats", "ISOcodes", "pander", "lubridate", "gsheet",
         "DiagrammeR", "janitor", "DiagrammeRsvg", "rsvg", "manipulateWidget", "htmlwidgets", "boot")
invisible(lapply(lib, library, character.only = TRUE))  
rm(lib)  

# Load Custom Packages  
  source("./scripts/functions/fun.panel.R")
  source("./scripts/functions/themes.R")
  source("./scripts/functions/prismaGraph.R")
  source("./scripts/functions/binaryCor.R")
  source("./scripts/functions/kappa.R")

# Markdown Options
  knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # set working directory
  knitr::opts_knit$get("root.dir") # check working directory
  options(scipen = 999, digits = 4, width = 400) #removes scientific quotation
  #knitr::opts_chunk$set(echo = TRUE, cache = F, cache.path = rprojroot::find_rstudio_root_file('cache/')) # cache settings
  knitr::knit_hooks$set(
   error = function(x, options) {
     paste('\n\n<div class="alert alert-danger">',
           gsub('##', '\n', gsub('^##\ Error', '**Error**', x)),
           '</div>', sep = '\n')
   },
   warning = function(x, options) {
     paste('\n\n<div class="alert alert-warning">',
           gsub('##', '\n', gsub('^##\ Warning:', '**Warning**', x)),
           '</div>', sep = '\n')
   },
   message = function(x, options) {
     paste('\n\n<div class="alert alert-info">',
           gsub('##', '\n', x),
           '</div>', sep = '\n')
   }
  )
  htmltools::tagList(rmarkdown::html_dependency_font_awesome())

# Global Chunk Options
  knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figures/',
                        echo=TRUE, warning=FALSE, message=FALSE)
```

<br/>

Note. Boxplots display the interquartile range (IQR, center box), and the whiskers extend 1.5*IQR from the lower and upper hinge. The white point indicates the mean and the white center line indicates the median.   

<br/>

# **Data Preparation**  

## Data Import 
In a first step we import the raw data of the systematic review from the shared coding Google Sheet. We, import the databases of theories and scale validations as well as the database of the empirical papers. Beyond that we also import parts of the codebook for list creations.  

```{r importCoding, warning=F, message=F}
# Import theory database (and theory search for PRISMA)
urlTheorySearch <- gsheet::construct_download_url('https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing',
                                             format = "csv", sheetid = "94494555")
dt.TheorySearch <- gsheet::gsheet2tbl(urlTheorySearch)
urlTheories <- gsheet::construct_download_url('https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing',
                                             format = "csv", sheetid = "1370266195")
dt.Theories <- gsheet::gsheet2tbl(urlTheories)

# Import scale database
urlScales <- gsheet::construct_download_url('https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing',
                                             format = "csv", sheetid = "1211291373")
dt.Scales <- gsheet::gsheet2tbl(urlScales)

# Import empirical database
urlPsycInfo <- gsheet::construct_download_url('https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing',
                                              format = "csv", sheetid = "2129881335")
dt.Empirical <- gsheet::gsheet2tbl(urlPsycInfo)

# Import input and domain codebooks
urlInput <- gsheet::construct_download_url('https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing',
                                             format = "csv", sheetid = "168002198")
dt.Input <- gsheet::gsheet2tbl(urlInput)
urlDomains <- gsheet::construct_download_url('https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing',
                                             format = "csv", sheetid = "1826792378")
dt.Domains <- gsheet::gsheet2tbl(urlDomains)

# Clean up workspace
rm(list = ls(pattern='^url'))
```

For the field comparisons we also import the most recent Scimago Journal Database.  
```{r importJournals, warning=F, message=F}
# Collect all names of the individual field database files
fileNam = list.files(path = "data/JournalDatabase", pattern="scimagojr 2019  Subject Area")

# Extract field names
fieldNam <- gsub("scimagojr 2019  Subject Area - |.csv", "", fileNam) 

# import all files
fieldList <- list()
for (i in 1:length(fileNam)) fieldList[[fieldNam[i]]] <- read.csv2(paste0("data/JournalDatabase/",fileNam[i])) 

# There are some more Publishers in the individual field databases.
dfJournals <- plyr::ldply(fieldList, data.frame)
#length(unique(dfJournals$Title)) # check

# import combined file (that might miss some field-specific data)
PublisherInfo <- read.csv2("data/JournalDatabase/scimagojr 2019.csv") 

# make field labels coherent
PublisherInfo$fields <- ""
for (i in 1:nrow(PublisherInfo)) {
  for(j in 1:length(fileNam)) {
    PublisherInfo$fields[i] <- ifelse(PublisherInfo$Title[i] %in% fieldList[[fieldNam[j]]]$Title, 
                                       paste(PublisherInfo$fields[i],fieldNam[j], sep = "; "), 
                                       PublisherInfo$fields[i])
  }
}
PublisherInfo$fields <- gsub("^; ", "", PublisherInfo$fields)

# Fix column names
colNam <- gsub("\\.", "", names(PublisherInfo))
colNam <- gsub("^Title$", "PublicationTitleDb", colNam)
colNam <- gsub("^Type$", "PublicationTypeDb", colNam)
colNam <- gsub("^Country$", "PublisherCountry", colNam)
colNam <- gsub("^Region$", "PublisherRegion", colNam)
colNam <- gsub("^Publisher$", "PublisherName", colNam)

names(PublisherInfo) <- colNam

# clean up workspace
rm(fileNam, fieldNam, fieldList, colNam)
```


## Data Cleaning  
We then go on to clean the data sets in order to use them in later analyses. This step includes cleaning up variable names, extracting variables (e.g., publication year), and checking for inconsistencies between databases (all of these operations are still within the data wrangling or data munging phase).   

```{r cleanTheories}
# THEORIES
# Extract publication year (crude but seems to work)
dt.Theories$year <- str_extract(dt.Theories$Source, "([0-9]{4})")
```

```{r cleanScales}
# SCALES
# Frequency of all scales within the database
n_occur_ScaleDT <- data.frame(table(Scale = dt.Scales$Scale)) 

# Extract publication year (crude but seems to work)
dt.Scales$year <- str_extract(dt.Scales$CitationKey, "([0-9]{4})")
```

```{r cleanEmpirical}
# EMPIRICAL
# non necessary on global level
```

## Data Exclusions  

### Theories
```{r TheoryExclusion}
# duplicate
dt.TheorySearch.unique <- dt.TheorySearch %>%
  filter(DuplicateAny != "TRUE")

# title screening
dt.TheorySearch.title <- dt.TheorySearch %>%
  filter(TitleScreening == 1)

# abstract screening
dt.TheorySearch.abstract <- dt.TheorySearch %>%
  filter(TitleScreening == 1,
         AbstractScreening == 1)

# full-text inclusion
dt.TheorySearch.included <- dt.TheorySearch %>%
  filter(TitleScreening == 1,
         AbstractScreening == 1,
         Extracted == 1)

# added from empirical literature
dt.Theories.Included <- dt.Theories %>%
  filter(is.na(MissingABCD))
dt.TheorySearch.added <- nrow(dt.Theories.Included)-nrow(dt.TheorySearch.included)

## reasons for exclusion ##
# title exclusion reason
theoryExclTitle <- data.frame(table(Exclusion = dt.TheorySearch$TitleNote)) %>%
  mutate(screening = "Title") %>%
  arrange(desc(Freq))

# abstract exclusion reason
theoryExclAbstract <- data.frame(table(Exclusion = dt.TheorySearch$AbstractNote)) %>%
  mutate(screening = "Abstract") %>%
  arrange(desc(Freq))

# full text exclusion reason
theoryExclFull <- data.frame(table(Exclusion = dt.TheorySearch$ExtractedReason)) %>%
  mutate(screening = "Full Text") %>%
  arrange(desc(Freq))

# # Table
# rbind(theoryExclTitle, theoryExclAbstract, theoryExclFull) %>%
#   reshape(., idvar = "Exclusion", timevar = "screening", direction = "wide") %>%
#   mutate_if(is.numeric, ~replace(., is.na(.), "")) %>%
#   rename_at(vars(starts_with("Freq.")),
#             funs(sub("Freq[.]", "", .))) %>%
#   rename(., "Exclusion Reason" = Exclusion) %>%
#   kbl(., 
#         #label = "",
#         caption = "Exclusion Reasons Theoretical Literature",
#         format = "html",
#         linesep = "",
#         booktabs = T,
#         align = c("l", "c", "c", "c"))  %>%
#   add_header_above(., c(" ", "Screening" = 3)) %>%
#   kable_styling(position = "left")

# dataframe with all exclusion reasons
theoryExclCombined <- rbind(theoryExclTitle, theoryExclAbstract, theoryExclFull) %>%
  reshape(., idvar = "Exclusion", timevar = "screening", direction = "wide") %>%
  mutate_if(is.numeric, ~replace(., is.na(.), "")) %>%
  rename_at(vars(starts_with("Freq.")),
            funs(sub("Freq[.]", "", .))) %>%
  rename(., "Exclusion Reason" = Exclusion)
```

At the more abstract level, the theory-specific literature search produced a total of `r nrow(dt.TheorySearch)` results from which we identified `r nrow(dt.TheorySearch.included)` theories. From our review of the empirical literature we added an additional `r dt.TheorySearch.added` theories (total *N* = `r nrow(dt.Theories.Included)`, for exclusion reasons see Table \@ref(tab:ExclusionsCombined) and for a PRISMA diagram see Figure \@ref(fig:PrismaCombined)).

```{r PrismaTheories}
prismaTheory <- prismaGr(found = nrow(dt.TheorySearch),
         found_other = dt.TheorySearch.added,
         no_dupes = nrow(dt.TheorySearch.unique)+dt.TheorySearch.added, 
         screened = nrow(dt.TheorySearch.unique)+dt.TheorySearch.added, 
         screen_exclusions = nrow(dt.TheorySearch.unique)-nrow(dt.TheorySearch.abstract), 
         full_text = nrow(dt.TheorySearch.abstract)+dt.TheorySearch.added,
         full_text_exclusions = nrow(dt.TheorySearch.abstract)-nrow(dt.TheorySearch.included), 
         qualitative = nrow(dt.Theories.Included), 
         #quantitative = nrow(dt.Theories.Included), 
         title = "(A) PRISMA Diagram for the Theoretical Literature",
         extra_dupes_box = F,
         width = 800, height = 800)
```

### Scales
```{r ScalesExclusion}
# Past reviews
scalesPastN <- dt.Scales %>%
  dplyr::select(Source) %>%
  mutate(Source = strsplit(as.character(Source), "; ")) %>% 
  unnest(Source) %>%
  filter(Source != "own review") %>%
  na.omit %>%
  nrow

# Own review
scalesOwnN <- dt.Scales %>%
  dplyr::select(Source) %>%
  mutate(Source = strsplit(as.character(Source), "; ")) %>% 
  unnest(Source) %>%
  filter(Source == "own review") %>%
  na.omit%>%
  nrow

# after duplicate removal
scalesNoDupsN <- nrow(dt.Scales)

# remove non-available and excluded scales
dt.Scales.Included <- dt.Scales %>%
  filter(Coded == 1)
scalesAfterExclusionN <- nrow(dt.Scales.Included)

# # Table
# data.frame(table(Exclusion = dt.Scales$MissingNote)) %>%
#   arrange(desc(Freq)) %>%
#   kbl(., 
#         #label = "",
#         caption = "Scales Exclusion Reasons",
#         format = "html",
#         col.names = c("Exclusion Reason",
#                       "Frequency"), 
#         linesep = "",
#         booktabs = T,
#         align = c("l", "c"))  %>%
#   kable_styling(position = "left")

# dataframe with all exclusion reasons
scalesExcl <- data.frame(table(dt.Scales$MissingNote)) %>%
  rename("Exclusion Reason" = Var1, "Full Text" = Freq) %>%
  arrange(desc(`Full Text`))
```

Within the past literature we identified five major workks that reviewed the measurement of acculturation [@Celenk2011; @Maestas2000; @Matsudaira2006; @Wallace2010; @Zane2004]. After duplicate removal these five reviews collected a total of `r nrow(dt.Scales[dt.Scales$Source != "own review",])` scales. From our own review we added `r nrow(dt.Scales[dt.Scales$Source == "own review",])` additional validation studies. Of these scales we ultimately had to exclude `r nrow(dt.Scales[!is.na(dt.Scales$MissingNote),])`, because they were either not accessible or did not fit the the topic of our review (see Table \@ref(tab:ExclusionsCombined) and Figure \@ref(fig:PrismaCombined)). 

```{r PrismaScales}
prismaScales <- prismaGrScales(found = scalesPastN,
               found_other = scalesOwnN,
               no_dupes = scalesNoDupsN, 
               full_text = scalesAfterExclusionN,
               full_text_exclusions = scalesNoDupsN-scalesAfterExclusionN, 
               qualitative = scalesAfterExclusionN, 
               quantitative = scalesAfterExclusionN, 
               title = "(B) PRISMA Diagram for the Methodological Literature",
               extra_dupes_box = F,
               width = 800, height = 800)
```

### Empirical
```{r EmpiricalExclusion}
# duplicate
dt.Empirical.unique <- dt.Empirical %>%
  filter(SearchDuplicate != "TRUE")

# title screening
dt.Empirical.title <- dt.Empirical %>%
  filter(TitleScreening == 1)

# abstract screening
dt.Empirical.abstract <- dt.Empirical %>%
  filter(TitleScreening == 1,
         AbstractScreening == 1)

# full text screening
dt.Empirical.fulltext <- dt.Empirical %>%
  filter(TitleScreening == 1,
         AbstractScreening == 1,
         MissingABCD == 0)

# included (empirical)
dt.Empirical.included <- dt.Empirical %>%
  filter(TitleScreening == 1,
         AbstractScreening == 1,
         MissingABCD == 0,
         empirical != 0)

# reasons for exclusion
empiricalExclTitle <- data.frame(table(Exclusion = dt.Empirical$TitleNote)) %>%
  mutate(screening = "Title") %>%
  arrange(desc(Freq))

empiricalExclAbstract <- data.frame(table(Exclusion = dt.Empirical$AbstractNote)) %>%
  mutate(screening = "Abstract") %>%
  arrange(desc(Freq))

empiricalExclFull <- data.frame(table(Exclusion = dt.Empirical.abstract$NoteMissing)) %>%
  mutate(screening = "Full Text") %>%
  arrange(desc(Freq))

# # Table
# rbind(empiricalExclTitle, empiricalExclAbstract, empiricalExclFull) %>%
#   reshape(., idvar = "Exclusion", timevar = "screening", direction = "wide") %>%
#   mutate_if(is.numeric, ~replace(., is.na(.), "")) %>%
#   rename_at(vars(starts_with("Freq.")),
#             funs(sub("Freq[.]", "", .))) %>%
#   rename(., "Exclusion Reason" = Exclusion) %>%
#   kbl(., 
#         #label = "",
#         caption = "Exclusion Reasons Empirical Literature",
#         format = "html",
#         linesep = "",
#         booktabs = T,
#         align = c("l", "c", "c", "c"))  %>%
#   add_header_above(., c(" ", "Screening" = 3)) %>%
#   kable_styling(position = "left")

# dataframe with all exclusion reasons
empiricalEclCombined <- rbind(empiricalExclTitle, empiricalExclAbstract, empiricalExclFull) %>%
  reshape(., idvar = "Exclusion", timevar = "screening", direction = "wide") %>%
  mutate_if(is.numeric, ~replace(., is.na(.), "")) %>%
  rename_at(vars(starts_with("Freq.")),
            funs(sub("Freq[.]", "", .))) %>%
  rename(., "Exclusion Reason" = Exclusion) 
```

At the most applied level, we assessed the broader empirical studies. This final database included the largest number of manuscripts and is in theory the application of the theoretical and methodological literature. The search produced a total of `r nrow(dt.Empirical)` results to which we added 133 articles through contacts with experts in the field and from referenced works within the review. After duplicate removal, title--, abstract--, and full text screening we coded a total of `r nrow(dt.Empirical.included)` empirical works (for exclusion reasons see Table \@ref(tab:ExclusionsCombined) and for a PRISMA diagram see Figure \@ref(fig:PrismaCombined)).

```{r prismaEmpirical}
prismaEmpirical <- prismaGr(found = nrow(dt.Empirical),
         found_other = 133, # from Mendeley library
         no_dupes = nrow(dt.Empirical.unique), 
         screened = nrow(dt.Empirical.unique), 
         screen_exclusions = nrow(dt.Empirical.unique)-nrow(dt.Empirical.abstract), 
         full_text = nrow(dt.Empirical.abstract),
         full_text_exclusions = nrow(dt.Empirical.abstract)-nrow(dt.Empirical.fulltext), 
         qualitative = nrow(dt.Empirical.fulltext), 
         quantitative = nrow(dt.Empirical.included),
         title = "(C) PRISMA Diagram for the Empirical Literature",
         extra_dupes_box = F,
         width = 800, height = 800)
```

### Table and Figure   

```{r ExclusionsCombined}
exclMerged01 <- merge(theoryExclCombined, empiricalEclCombined, by = "Exclusion Reason", suffixes = c(".Theory",".Empirical"), all=T)
exclMerged02 <- merge(exclMerged01, scalesExcl %>% rename("Full Text.Scale" = "Full Text"), by = "Exclusion Reason", all=T)
reasonOrder <- c("not English", "not migration", "not migrant", "not acculturation", "not ABCD", "not theory", "not measured",
                 "items not accessible", "thesis not accessible", "article not accessible", "book not accessible", "chapter not accessible",
                 "poster not accessible", "should still be coded")

options(knitr.kable.NA = '')
exclMerged02 %>%
  slice(match(reasonOrder, `Exclusion Reason`)) %>%
  mutate(across(where(is.character), as.numeric)) %>%
  relocate("Full Text.Scale", .after = "Full Text.Theory") %>%
  kbl(., 
        #label = "",
        col.names = c("Reason", 
                      "Title", "Abstract", "Full Text",
                      "Full Text",
                      "Title", "Abstract", "Full Text"),
        caption = "Exclusion Reasons for all Literature Levels",
        format = "html",
        linesep = "",
        booktabs = T,
        align = c("l", rep("c", length(exclMerged02)-1)))  %>%
  add_header_above(., c(" ", "Theoretical" = 3, "Methodological", "Empirical" = 3)) %>%
  kable_styling(position = "left")
```

```{r PrismaCombined, fig.cap="Prisma diagram for three data sets on psychological acculturation."}
# PrismaCombined <- manipulateWidget::combineWidgets(prismaTheory, prismaScales, prismaEmpirical, ncol = 1, byrow = TRUE)
# htmlwidgets::saveWidget(PrismaCombined, "PrismaCombined.html", selfcontained = TRUE)
# webshot2::webshot("PrismaCombined.html", "Figures/PrismaCombined.pdf", vwidth = 500, vheight = 1600)

manipulateWidget::combineWidgets(prismaTheory, prismaScales, prismaEmpirical, ncol = 1, byrow = TRUE) 
```

# **Full Databases**  {.tabset}

## Theoretical Literature
The `r nrow(dt.Theories.Included)` theoretical works are listed in Table \@ref(tab:theoreticalTbl).  

```{r theoreticalTbl}
dt.Theories.Included %>%
  dplyr::select(Theory, Reference = CitationKey,
                #Affect, Behavior,	Cognition, Desire,
                Affect = AffectFinal, Behavior = BehaviorFinal,	Cognition = CognitionFinal,	Desire = DesireFinal,
                `Type of Theoretical Work` = FrameworkTheoryModel, Focus = GeneralAspect, `Migration Time` = Time, `Source Type` = SourceType) %>%
  mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  mutate(Reference = paste0("@",Reference)) %>%
  kbl(., caption = "Empirical Literature",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "110%", height = "750px")
```

## Methodological Literature  
The `r nrow(dt.Scales.Included)` scales are listed in Table \@ref(tab:methodologicalTbl).  

```{r methodologicalTbl}
dt.Scales.Included %>%
  mutate(SourceShort = stri_replace_all_fixed(Source,
                                         pattern = c("@Celenk2011", "@Maestas2000", "@Matsudaira2006", "@Wallace2010", "@Zane2004", "own review"), 
                                         replacement = c("CEL", "MAE", "MAT", "WAL", "ZAN", "OWN"), 
                                         vectorize_all = FALSE)) %>%
  dplyr::select(Scale, Reference = CitationKey,
                #Affect, 	Behavior,	Cognition,	Desire,
                Affect = AffectFinal, Behavior = BehaviorFinal,	Cognition = CognitionFinal,	Desire = DesireFinal,
                `Source ^a^` = SourceShort, Sample,	`Majority Included` = IncludesMajority, 
                `Country of Settlement` = HostCountry,	`Country of Origin` = OriginCountry) %>%
  mutate_at(vars(Affect, 	Behavior,	Cognition, Desire), ~replace_na(., 0)) %>%
  mutate(Reference = paste0("@",Reference)) %>%
  kbl(., caption = "Acculturation Scales",
      format = "html") %>%
  add_footnote(c("CEL = @Celenk2011, MAE = @Maestas2000, MAT = @Matsudaira2006, WAL = @Wallace2010, ZAN = @Zane2004, OWN = own review (only additional)"), 
               notation = "alphabet") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "110%", height = "750px")
```

## Empirical Literature  
The `r nrow(dt.Empirical.included)` empirical works are listed in Table \@ref(tab:empiricalTbl).  

```{r empiricalTbl}
dt.Empirical.included %>%
  dplyr::select(Reference = CitationKey, 
                #Affect,	Behavior,	Cognition,	Desire,
                Affect = AffectFinal, Behavior = BehaviorFinal,	Cognition = CognitionFinal,	Desire = DesireFinal,
                `Publication Type` = PublicationType, Method, Sample,	`Majority Included` = IncludesMajority, `Migration Time` = MigrationTime,
                `Country of Settlement` = HostCountry,	`Country of Origin` = OriginCountry) %>%
  mutate_at(vars(Affect, 	Behavior,	Cognition, Desire), ~replace_na(., 0)) %>%
  mutate(Reference = paste0("@",Reference)) %>%
  kbl(., caption = "Empirical Literature",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "110%", height = "750px")
```

# **Theoretical Literature**  

## Descriptives  

### Theory type
The authors of the `r nrow(dt.Theories.Included)` included theoretical works self-categorized their contributions as a theoretical conceptualization (*N* = `r nrow(dt.Theories.Included %>% filter(FrameworkTheoryModel=="Conceptualization"))`), theoretical framework (*N* = `r nrow(dt.Theories.Included %>% filter(FrameworkTheoryModel=="Framework"))`), theory (*N* = `r nrow(dt.Theories.Included %>% filter(FrameworkTheoryModel=="Theory"))`), or theoretical model (*N* = `r nrow(dt.Theories.Included %>% filter(FrameworkTheoryModel=="Model"))`; also see Table \@ref(tab:theoryType)).  

```{r theoryType}
data.frame(table(Type = dt.Theories.Included$FrameworkTheoryModel)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Type of Theoretical Work",
      format = "html",
      col.names = c("Type",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Focus
And while `r nrow(dt.Theories.Included %>% filter(GeneralAspect=="Aspect"))` authors explicitly targeted a specific part of acculturation (e.g., `r nrow(dt.Theories.Included %>% filter(Target=="Identity"))` identity acculturation theories and `r nrow(dt.Theories.Included %>% filter(Target=="Work"))` labor market acculturation theories; also see Table \@ref(tab:focusAspect)), a majority of theoretical works offered commentary on the overall construct of acculturation (*N* = `r nrow(dt.Theories.Included %>% filter(GeneralAspect=="General"))`; also see Table \@ref(tab:focusType)).  

```{r focusType}
data.frame(table(Focus = dt.Theories.Included$GeneralAspect)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Focus of Theoretical Work",
      format = "html",
      col.names = c("Focus",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r focusAspect}
data.frame(table(Aspect = dt.Theories.Included$Target)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Aspect Frequency in Specific Theoretical Works",
      format = "html",
      col.names = c("Aspect",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Source  
Looking at the types of theory building, a majority of proposal were purely theoretical (*N* = `r nrow(dt.Theories.Included %>% filter(SourceType=="theoretical"))`) with the remaining theoretical works growing out of qualitative investigations (such as grounded theory approaches; *N* = `r nrow(dt.Theories.Included %>% filter(SourceType=="empirical"))`; also see Table \@ref(tab:theorySource)).  

```{r theorySource}
data.frame(table(Focus = dt.Theories.Included$GeneralAspect)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Source of Theoretical Work",
      format = "html",
      col.names = c("Source",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Time  
We also assessed when theoretical works were published to gain a feel for a theoretical interest in the topic.  

```{r theoryYear, fig.cap="Year of Publication [Theoretical works]. The graph shows the cumulative sum in the main graph as well as the number of works published over time in the marginal graph."}
# marginal histogram of number of manuscripts per year (with minimal theme)
theoryYearHist <- dt.Theories.Included %>%
  dplyr::select(year) %>%
  mutate(year = as.POSIXct(year, format = "%Y")) %>%
  ggplot(., aes(x=year)) + 
  geom_histogram(bins = length(table(dt.Theories.Included$year)), fill = "grey14")+
  labs(title = "Year of Publication [Methodological works]",
       y = "Number of Validations",
       x = "Year") +
  scale_y_continuous(breaks = seq(0,20,10)) +
  scale_x_datetime(breaks = as.POSIXct(as.character(seq(1920,2020,10)), format = "%Y"), date_labels = "%Y") +
  theme_Publication() +
  theme(strip.background = element_rect(fill="grey14", color="grey14"),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_blank(), #element_text(size=16, face="bold", hjust = 0.5),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.line.x = element_blank(),
        axis.line.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        plot.margin = unit(c(5, 5, 0, 5), "pt"),
        legend.position="none")

# cumulative sum of articles over time
theoryYearCum <- data.frame(table(Year = dt.Theories.Included$year)) %>%
  mutate(Year = as.POSIXct(Year, format = "%Y"),
         CumSum = cumsum(Freq)) %>%
  ggplot(., aes(x=Year, y=CumSum, group=1)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(breaks = seq(0,90,10)) +
  scale_x_datetime(breaks = as.POSIXct(as.character(seq(1920,2020,10)), format = "%Y"), date_labels = "%Y") +
  labs(title = "Year of Publication [Theoretical works]",
       y = "Cumulative Sum",
       x = "Year") +
  theme_Publication() +
  theme(strip.background = element_rect(fill="grey14", color="grey14", ),
        axis.title.x = element_text(size=14, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        plot.title = element_blank(), #element_text(size=16, face="bold", hjust = 0.5),
        axis.text.x = element_text(size=14),
        axis.text.y = element_text(size=14),
        #panel.grid.major.x = element_blank(),
        #panel.grid.major.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        plot.margin = unit(c(0, 5, 5, 5), "pt"),
        legend.position="none")

# combine graphs
cowplot::plot_grid(theoryYearHist, theoryYearCum, nrow=2, align = "v", rel_heights = c(1/5, 4/5))
```

```{r theoryTypeYear, fig.cap="Types of Publications over time."}
# potentially type of theoretical works over time.
```

## Experience  
```{r TheoreticalKappa}
names <- c("Affect", "Behavior", "Cognition", "Desire")
kTheo <- dt.Theories.Included %>%
  select(Affect, Affect2, Behavior, Behavior2, Cognition, Cognition2, Desire, Desire2) %>%
  mutate_all(~replace_na(., 0)) %>%
  kappa.full.multiple(., names)
kTheoPooled <- kappa.pooled2(kTheo)
```
We then look at the use of experience aspects within the theoretical works in more detail. Before we inspect the aspect inclusion patterns in more detail we assessed the inter-rater reliability. Because the affect, behavior, cognition, and desire codings were integral to the framework two independent raters coded all included manuscripts. All four experience aspects were coded as either being included [1] or not included [0]. We, thus, used Cohen's $\kappa$ to assess the chance-corrected agreement between the raters. Confidence intervals were calculated using the standard error formula provided in @McHugh2012. Pooled Cohen's $\kappa$s were calculated using the methods developed by @DeVries2008. Note that for the pooled $\kappa$ we provide basic bootstrapped confidence intervals, which should be treated as preliminary because thus far no validated calculation for associated standard errors have been established (to the best of our knowledge). All inter-rater agreements were `r format(round(min(kTheo$Po, na.rm = TRUE)*100, 2), nsmall=2)`% or above and all $\kappa$s were above `r format(round(min(kTheo$k, na.rm = TRUE), 2), nsmall=2)` ($\kappa_{pooled}$ = `r format(round(kTheoPooled$k.pooled, 2), nsmall=2)`, $95\%CI_{boot}$[`r  format(round(kTheoPooled$lwr, 2), nsmall=2)`, `r format(round(kTheoPooled$upr, 2), nsmall=2)`]; full inter-rater reliability is available in Table \@ref(tab:TheoreticalKappaTbl)). 

```{r TheoreticalKappaTbl}
kTheo %>%
  kbl(.,
        #label = "",
        caption = "Theoretical Literature: <br>Cohen's $\\kappa$",
        format = "html",
        #linesep = "",
        #booktabs = T,
        align = c('l', rep('c', length(.)-1)))  %>%
  footnote(general = paste0("$\\kappa_{pooled}$ = ",format(round(kTheoPooled$k.pooled, 2), nsmall=2), ", $95\\%CI_{boot}$(", format(round(kTheoPooled$lwr, 2), nsmall=2), ", ", format(round(kTheoPooled$upr, 2), nsmall=2), ")")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")
```

We were particularly interested in the overall use of each experience aspect (see Table \@ref(tab:TheoriesElementFreq) and Figure \@ref(fig:TheoriesElementFreqBar)), the combined uses of experience aspects (see Table \@ref(tab:TheoriesElementCombinations) and Figure \@ref(fig:TheoriesElementCombinationsBar)), the resulting distribution of the number of aspects considered (see Table \@ref(tab:TheoriesElementComplexity) and Figure \@ref(fig:TheoriesElementComplexityBar)), as well as the number of other aspects that were considered with each of the aspects (see Table \@ref(tab:TheoriesElementAspectComplexity)).  

```{r TheoriesElementFreq}
# Count the times each dimension is measured
TheoElementFreq <- dt.Theories.Included %>%
  dplyr::select(Affect = AffectFinal, Behavior = BehaviorFinal,	Cognition = CognitionFinal,	Desire = DesireFinal) %>%
  mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  colSums(., na.rm = FALSE, dims = 1) 

# transform to data frame and make row names name variable
TheoElementFreq <- data.frame(Element = names(TheoElementFreq), 
                            Frequency = TheoElementFreq, 
                            Percentage = TheoElementFreq/nrow(dt.Theories.Included)*100) %>%
  mutate(Element = fct_reorder(Element, Frequency))

TheoElementFreq %>%
  kbl(., 
        #label = "",
        caption = "Theoretical Literature: <br>Overall Aspect Frequency",
        format = "html", 
        #linesep = "",
        #booktabs = T,
        align = c('l', 'c', 'c'))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r TheoriesElementFreqBar, fig.cap="Theoretical Literature: Bar Graph Aspect Frequency"}
# barplot of dimension frequency
TheoABCDBar <- ggplot(data=TheoElementFreq, aes(x=Element, y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    #aes(label = paste0("N = ",Frequency)),
    aes(label = paste0(format(round(Percentage,2), nsmall=2), "%")),
    position=position_stack(vjust=0.5),
    color = "white",
    size = 4,
    vjust = 0.5
    ) +
  labs(#title = "Aspect Frequency",
       y = "Percentage across all Theories",
       x = "Experience Aspect")+
  coord_flip()+
  theme_Publication()+
  theme(strip.background = element_rect(fill="grey14", color="grey14"),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=10, face="bold", hjust = 0.5),
        axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=10),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        legend.position="none")

TheoABCDBar
```

```{r TheoriesElementCombinations}
# frequency of unique combinations
TheoElementCombFreq <- dt.Theories.Included %>%
  dplyr::select(Affect = AffectFinal, Behavior = BehaviorFinal,	Cognition = CognitionFinal,	Desire = DesireFinal) %>%
  #mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  group_by(Affect, Behavior, Cognition, Desire) %>%
  summarise(Frequency = n()) %>%
  ungroup() %>%
  mutate(complexity = rowSums(dplyr::select(., Affect, Behavior, Cognition, Desire), na.rm = T))

# fill replace ones with colnames to be combined
for (i in 1:4) {
    TheoElementCombFreq[[i]] <- str_replace(as.character(TheoElementCombFreq[[i]]), "1", colnames(TheoElementCombFreq)[i])
}

# collect Elements names for each combination
TheoElementCombFreq <- TheoElementCombFreq %>%
  unite("ExperienceCombination",c("Affect", "Behavior", "Cognition", "Desire"), na.rm = TRUE, sep = ", ") %>%
  mutate(ExperienceCombination = fct_reorder(ExperienceCombination, Frequency),
         Percentage = Frequency/nrow(dt.Theories.Included)*100,
         Affect = ifelse(grepl("Affect", ExperienceCombination, fixed = TRUE), 1,0),
         Behavior = ifelse(grepl("Behavior", ExperienceCombination, fixed = TRUE), 1,0),
         Cognition = ifelse(grepl("Cognition", ExperienceCombination, fixed = TRUE), 1,0),
         Desire = ifelse(grepl("Desire", ExperienceCombination, fixed = TRUE), 1,0)) %>%
  arrange(-Frequency)

TheoElementCombFreq %>%
  kbl(., 
        #label = "",
        caption = "Theoretical Literature: Aspect Combinations",
        format = "html", 
        #linesep = "",
        #booktabs = T,
        align = c('l', rep('c', length(TheoElementCombFreq)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r TheoriesElementCombinationsBar, fig.cap="Theoretical Literature: Bar Graph Aspect Combinations"}
# bar plot frequencies
TheoABCDComb <- ggplot(TheoElementCombFreq, aes(x=ExperienceCombination, y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    aes(y=Percentage, label = paste0(format(round(Percentage,2), nsmall=2),"% [N = ", Frequency, "]")),
    color = "grey14",
    size = 4,
    hjust = -.1,
    inherit.aes = TRUE
    ) +
  scale_y_continuous(limits = c(0, ceiling(max(TheoElementCombFreq$Percentage)*1.15)),
                     breaks = seq(0, ceiling(max(TheoElementCombFreq$Percentage)*1.15), 5))+
  labs(y = "Proportion of all theories [in %]",
       x = "Combination of Experience Aspects")+
  coord_flip()+
  theme_Publication()+
  theme(strip.background = element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")

TheoABCDComb
```

```{r TheoriesElementComplexity}
# summarize by aspect complexity
TheoComplexity <- TheoElementCombFreq %>%
  dplyr::select(complexity, Frequency) %>%
  group_by(complexity) %>%
  summarise(Frequency = sum(Frequency),
            Percentage = sum(Frequency)/nrow(dt.Theories.Included)*100) %>%
  ungroup() %>%
  mutate(complexity = as.factor(complexity),
         complexity = fct_reorder(complexity, Frequency))

# overall complexity mean and standard deviation
TheoComplexityAverage <- weighted.mean(as.numeric(as.character(TheoComplexity$complexity)), TheoComplexity$Frequency)
TheoComplexitySD <- wtd.var(x = as.numeric(as.character(TheoComplexity$complexity)), weights = TheoComplexity$Frequency)

# Table complexity distribution
TheoComplexity %>%
  kbl(., 
        #label = "",
        caption = "Theoretical Literature: <br>Number of Aspects considered",
        format = "html", 
        digits = 2,
        #linesep = "",
        #booktabs = T,
        align = c('l', rep('c', length(TheoComplexity)-1)))  %>%
  footnote(general = paste0("M = ",format(round(TheoComplexityAverage, 2), nsmall=2), ", SD = ", format(round(TheoComplexitySD, 2), nsmall=2))) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r TheoriesElementComplexityBar, fig.cap="Theoretical Literature: Bar Graph Number of Aspects considered"}
# barplot of complexity frequency
TheoComplexityBar <- ggplot(data=TheoComplexity, aes(x=complexity, y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    #aes(label = paste0("N = ",Frequency)),
    aes(label = paste0(format(round(Percentage,2), nsmall=2), "%")),
    position=position_stack(vjust=0.5),
    color = "white",
    size = 4,
    vjust = 0.5
    ) +
  labs(title = "Numer of Aspects Considered",
       y = "Frequency across all Theories",
       x = "Number of Aspects Considered")+
  coord_flip()+
  theme_Publication()+
  theme(strip.background = element_rect(fill="grey14", color="grey14", ),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=10, face="bold", hjust = 0.5),
        axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=10),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        legend.position="none")

TheoComplexityBar
```

```{r TheoriesElementAspectComplexity}
# Numer of Aspects Considered for each element
TheoElementComplexity <- TheoElementCombFreq %>%
  gather(key = "Element", value = "ElementDum", Affect, Behavior, Cognition, Desire) %>%
  filter(ElementDum == 1) %>%
  group_by(Element) %>%
  summarise(n = sum(Frequency),
            avgComplexity = weighted.mean(x = complexity, w = Frequency),
            sdComplexity = wtd.var(x = complexity, weights = Frequency)) %>%
  ungroup() %>%
  mutate(seComplexity = sdComplexity/sqrt(n)) %>%
  arrange(-avgComplexity)

# Table Aspect complexity distribution
TheoElementComplexity %>%
  kbl(., 
        #label = "",
        caption = "Theoretical Literature: <br>Number of Aspects considered with each aspect",
        col.names = c("N", "Aspect", "Mean", "Standard Deviation", "Standard Error"),
        format = "html", 
        digits = 2,
        #linesep = "",
        #booktabs = T,
        align = c('l', rep('c', length(TheoElementComplexity)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

We additionally inspected bi-variate relations between the individual aspects. We calculate the phi coefficient (for binary variables) together with the raw number of co-occurrences (see Table \@ref(tab:TheoriesElementCooccurrences)).  

```{r TheoriesElementCooccurrences}
# make crossproduct matrix to condense co-occurrences (off-diagonals) and get frequencies (diagonals)
as.matrix(dt.Theories.Included %>% dplyr::select(Affect = AffectFinal, Behavior = BehaviorFinal,	Cognition = CognitionFinal,	Desire = DesireFinal) %>%
            mutate_all(~replace(., is.na(.), 0))) %>%
  BinaryCor(., "pearson") %>%
  tibble::rownames_to_column(., var = "Aspect") %>%
  kbl(., 
        #label = "",
        caption = "Theoretical Literature: <br>Aspects Bi-Variate Relations",
        format = "html", 
        linesep = "",
        booktabs = T,
        align = c('l', rep('c', ncol(.)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r theoryExperienceCombinedBar, fig.width=12, fig.height=12, fig.cap="Theoretical Literature: Combined Bar Graphs"}
# draw combined graph
ggdraw() +
  draw_plot(TheoABCDComb, x = 0, y = 0.3, width = 1, height = .7)+
  draw_plot(TheoABCDBar, x = 0, y = 0, width = .55, height = .3) +
  draw_plot(TheoComplexityBar, x = .55, y = 0, width = .45, height = .3) +
  draw_plot_label(c("(A)", "(B)", "(C)"), c(0, 0, 0.55), c(1, 0.3, 0.3), size = 15)
```


## Process  

To assess the focus on psychological acculturation as a process or an outcome, we coded whether authors self-identified the theory as a process (e.g., 'process', 'development', 'longitudinal',  'temporal', 'dynamic') or an outcome (e.g., 'static', 'outcome', 'markers', 'consequence'). 

```{r theoryProcess}
dt.Theories.Included %>%
  dplyr::select(Time) %>%
  mutate(Time = replace_na(Time, "N/A")) %>%
  group_by(Time) %>%
  summarise(Frequency = n(),
            Percentage = Frequency/nrow(.)*100) %>%
  arrange(desc(Frequency)) %>%
  kbl(., caption = "Theoretical Literature: <br>Process Focus",
      format = "html",
      digits = 2,
      col.names = c("Conceptualisation", "Frequency", "Percentage")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")

```

We find that a slight majority of theories focuses on dynamic conceptualizations of psychological acculturation. This is a relatively high percentage, considering that past reviews of the acculturation literature have pointed to a small number of studies actually testing dynamic theories [@Ward2019].

# **Methodological Literature**  

## Descriptives  

### Scale Characteristics
To gain a broad understanding of the methodological diversity in scale constructions we assessed the distributions of the 'number of items measured', 'number of subscales', and 'number of response options' (see Table \@ref(tab:scalesContChar)).  

```{r scalesContChar}
# Count whether validations included Majority and make Table
scaleDescrCont <- dt.Scales.Included %>%
  dplyr::select(NItems, NSubScales, ResponseRange) %>%
  mutate_all(as.numeric)

scaleDescrCont %>%
  psych::describe(., trim = .2) %>%
  as.data.frame %>%
  mutate(vars = rownames(.),
         na = nrow(dt.Scales.Included)-n,
         win.mean = sapply(scaleDescrCont,psych::winsor.mean,simplify=T),
         win.sd = sapply(scaleDescrCont,psych::winsor.sd,simplify=T)) %>%
  dplyr::select(characteristic = vars, n, na, 
                mean, `mean win` = win.mean, `mean trim` = trimmed, median,
                sd, `sd win` = win.sd, MAD = mad, min, max,
                skew, kurtosis) %>%
  kbl(., 
      #label = "",
      caption = "Methodological Literature: Continuous Scale Characteristics",
      format = "html", 
      #linesep = "",
      #booktabs = T,
      row.names = F,
      digits = 2,
      align = c('l', rep('c', ncol(.)-1)))  %>%
  add_header_above(., c(" " = 3,"Centrality" = 4, "Dispersion" = 5, "Distribution" = 2)) %>%
  footnote(general = "'na' indicates the number of scales that were excluded because they had unknown or multiple characteristics.") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Sample
We firstly assessed how many of the scale validations included the dominant group was measured as well (see Table \@ref(tab:scalesMajority)).  

```{r scalesMajority}
# Count whether validations included Majority
scalesMajFreq <- dt.Scales.Included %>%
  dplyr::select(IncludesMajority) %>%
  filter(!is.na(IncludesMajority)) %>%
  mutate(`Includes Majority` = recode_factor(.$IncludesMajority, `0` = "no", `1` = "yes")) %>%
  group_by(`Includes Majority`) %>%
  summarise(Frequency = n(),
            Percentage = Frequency/nrow(.)*100)

scalesMajFreq %>%
  kbl(., 
      #label = "",
      caption = "Methodological Literature: <br>Dominant Group Included Frequency",
      format = "html", 
      #linesep = "",
      #booktabs = T,
      digits = 2,
      align = c('l', rep('c', ncol(.)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

Of the scale we included we also plotted the publication years of the scale validations in order to gain an understanding of the interest in scale development over time (see Figure \@ref(fig:scalesYear)).   

```{r scalesYear, fig.cap="Year of Publication [Methodological works]. The graph shows the cumulative sum in the main graph as well as the number of works published over time in the marginal graph."}
# marginal histogram of number of manuscripts per year (with minimal theme)
scaleHist <- dt.Scales.Included %>%
  dplyr::select(year) %>%
  mutate(year = as.POSIXct(year, format = "%Y")) %>%
  ggplot(., aes(x=year)) + 
  geom_histogram(bins = length(table(dt.Scales.Included$year)), fill = "grey14") +
  labs(title = "Year of Publication [Methodological works]",
       y = "Number of Validations",
       x = "Year") +
  #scale_y_continuous(breaks = seq(0,20,10)) +
  scale_x_datetime(breaks = as.POSIXct(as.character(seq(1920,2020,10)), format = "%Y"), date_labels = "%Y") +
  theme_Publication() +
  theme(strip.background = element_rect(fill="grey14", color="grey14"),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_blank(), #element_text(size=16, face="bold", hjust = 0.5),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.line.x = element_blank(),
        axis.line.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        plot.margin = unit(c(5, 5, 0, 5), "pt"),
        legend.position="none")

# Cumulative Sum of articles published over time
scalesYearCum <- data.frame(table(Year = dt.Scales.Included$year)) %>%
  mutate(Year = as.POSIXct(Year, format = "%Y"),
         CumSum = cumsum(Freq)) %>%
  ggplot(., aes(x=Year, y=CumSum, group=1)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(breaks = seq(0,220,20)) +
  scale_x_datetime(breaks = as.POSIXct(as.character(seq(1920,2020,10)), format = "%Y"), date_labels = "%Y") +
  labs(title = "Year of Publication [Methodological works]",
       y = "Cumulative Sum",
       x = "Year") +
  theme_Publication() +
  theme(strip.background = element_rect(fill="grey14", color="grey14", ),
        axis.title.x = element_text(size=14, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        plot.title = element_blank(), #element_text(size=16, face="bold", hjust = 0.5),
        axis.text.x = element_text(size=14),
        axis.text.y = element_text(size=14),
        #panel.grid.major.x = element_blank(),
        #panel.grid.major.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        plot.margin = unit(c(0, 5, 5, 5), "pt"),
        legend.position="none")

# combine the two plots
cowplot::plot_grid(scaleHist, scalesYearCum, nrow=2, align = "v", rel_heights = c(1/5, 4/5))
```

## Experience  
```{r MethodologicalKappa}
names <- c("Affect", "Behavior", "Cognition", "Desire")
kMeth <- dt.Scales.Included %>%
  select(Affect, Affect2, Behavior, Behavior2, Cognition, Cognition2, Desire, Desire2) %>%
  mutate_all(~replace_na(., 0)) %>%
  kappa.full.multiple(., names)
kMethPooled <- kappa.pooled2(kMeth)
```

We then look at the use of experience aspects within the theoretical works in more detail. All inter-rater agreements were `r format(round(min(kMeth$Po, na.rm = TRUE)*100, 2), nsmall=2)`% or above and all $\kappa$s were above `r format(round(min(kMeth$k, na.rm = TRUE), 2), nsmall=2)` ($\kappa_{pooled}$ = `r format(round(kMethPooled$k.pooled, 2), nsmall=2)`, $95\%CI_{boot}$[`r  format(round(kMethPooled$lwr, 2), nsmall=2)`, `r format(round(kMethPooled$upr, 2), nsmall=2)`]; for full inter-rater reliability see Table \@ref(tab:MethodologicalKappaTbl)).  

```{r MethodologicalKappaTbl}
kMeth %>%
  kbl(., 
      #label = "",
      caption = "Methodological Literature: <br>Cohen's $\\kappa$",
      format = "html", 
      #linesep = "",
      #booktabs = T,
      align = c('l', rep('c', length(.)-1)),
      digits=3)  %>%
  footnote(general = paste0("$\\kappa_{pooled}$ = ",format(round(kMethPooled$k.pooled, 2), nsmall=2), ", $95\\%CI_{boot}$[", format(round(kMethPooled$lwr, 2), nsmall=2), ", ", format(round(kMethPooled$upr, 2), nsmall=2), "]")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

We were particularly interested in the overall use of each experience aspect (see Table \@ref(tab:scalesElementFreq) and Figure \@ref(fig:TheoriesElementFreqBar)), the combined uses of experience aspects (see Table \@ref(tab:scalesElementCombinations) and Figure \@ref(fig:scalesElementCombinationsBar)), the resulting distribution of the number of aspects considered (see Table \@ref(tab:scalesElementComplexity) and Figure \@ref(fig:scalesElementComplexityBar)), as well as the number of other aspects that were considered with each of the aspects (see Table \@ref(tab:scalesElementAspectComplexity)).  

```{r scalesElementFreq}
# Count the times each dimension is measured
scalesElementFreq <- dt.Scales.Included %>%
  dplyr::select(Affect = AffectFinal, Behavior = BehaviorFinal,	Cognition = CognitionFinal,	Desire = DesireFinal) %>%
  mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  colSums(., na.rm = FALSE, dims = 1) 

# transform to data frame and make row names name variable
scalesElementFreq <- data.frame(Element = names(scalesElementFreq), 
                            Frequency = scalesElementFreq, 
                            Percentage = scalesElementFreq/nrow(dt.Scales.Included)*100) %>%
  mutate(Element = fct_reorder(Element, Frequency)) %>%
  arrange(desc(Frequency))

scalesElementFreq %>%
  kbl(., 
        #label = "",
        caption = "Methodological Literature: <br>Overall Aspect Frequency",
        format = "html", 
        #linesep = "",
        #booktabs = T,
        align = c('l', 'c', 'c'))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r scalesElementFreqBar, fig.cap="Methodological Literature: Bar Graph Aspect Frequency"}
# barplot of dimension frequency
scalesABCDBar <- ggplot(data=scalesElementFreq, aes(x=Element, y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    #aes(label = paste0("N = ",Frequency)),
    aes(label = paste0(format(round(Percentage,2), nsmall=2), "%")),
    position=position_stack(vjust=0.5),
    color = "white",
    size = 4,
    vjust = 0.5
    ) +
  labs(#title = "Aspect Frequency",
       y = "Percentage across all Scales",
       x = "Experience Aspect")+
  coord_flip()+
  theme_Publication()+
  theme(strip.background = element_rect(fill="grey14", color="grey14"),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=10, face="bold", hjust = 0.5),
        axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=10),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        legend.position="none")

scalesABCDBar
```

```{r scalesElementCombinations}
# frequency of unique combinations
scalesElementCombFreq <- dt.Scales.Included %>%
  dplyr::select(Affect = AffectFinal, Behavior = BehaviorFinal,	Cognition = CognitionFinal,	Desire = DesireFinal) %>%
  #mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  group_by(Affect, Behavior, Cognition, Desire) %>%
  summarise(Frequency = n()) %>%
  ungroup() %>%
  mutate(complexity = rowSums(dplyr::select(., Affect, Behavior, Cognition, Desire), na.rm = T))

# fill replace ones with colnames to be combined
for (i in 1:4) {
    scalesElementCombFreq[[i]] <- str_replace(as.character(scalesElementCombFreq[[i]]), "1", colnames(scalesElementCombFreq)[i])
}

# collect Elements names for each combination
scalesElementCombFreq <- scalesElementCombFreq %>%
  unite("ExperienceCombination",c("Affect", "Behavior", "Cognition", "Desire"), na.rm = TRUE, sep = ", ") %>%
  mutate(ExperienceCombination = fct_reorder(ExperienceCombination, Frequency),
         Percentage = Frequency/nrow(dt.Scales.Included)*100,
         Affect = ifelse(grepl("Affect", ExperienceCombination, fixed = TRUE), 1,0),
         Behavior = ifelse(grepl("Behavior", ExperienceCombination, fixed = TRUE), 1,0),
         Cognition = ifelse(grepl("Cognition", ExperienceCombination, fixed = TRUE), 1,0),
         Desire = ifelse(grepl("Desire", ExperienceCombination, fixed = TRUE), 1,0)) %>%
  arrange(-Frequency)

scalesElementCombFreq %>%
  kbl(., 
      #label = "",
      caption = "Methodological Literature: Aspect Combinations",
      format = "html", 
      #linesep = "",
      #booktabs = T,
      digits = 2,
      align = c('l', rep('c', length(scalesElementCombFreq)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r scalesElementCombinationsBar, fig.cap="Methodological Literature: Bar Graph Aspect Combinations"}
# bar plot frequencies
scalesABCDComb <- ggplot(scalesElementCombFreq, aes(x=ExperienceCombination, y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    aes(y=Percentage, label = paste0(format(round(Percentage,2), nsmall=2),"% [N = ", Frequency, "]")),
    color = "grey14",
    size = 4,
    hjust = -.1,
    inherit.aes = TRUE
    ) +
  scale_y_continuous(limits = c(0, ceiling(max(scalesElementCombFreq$Percentage)*1.15)),
                     breaks = seq(0, ceiling(max(scalesElementCombFreq$Percentage)*1.15), 5))+
  labs(y = "Proportion of all scales [in %]",
       x = "Combination of Experience Aspects")+
  coord_flip()+
  theme_Publication()+
  theme(strip.background = element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")

scalesABCDComb
```

```{r scalesElementComplexity}
# summarize by aspect complexity
scalesComplexity <- scalesElementCombFreq %>%
  dplyr::select(complexity, Frequency) %>%
  group_by(complexity) %>%
  summarise(Frequency = sum(Frequency),
            Percentage = sum(Frequency)/nrow(dt.Scales.Included)*100) %>%
  ungroup() %>%
  mutate(complexity = as.factor(complexity),
         complexity = fct_reorder(complexity, Frequency)) %>%
  arrange(desc(Frequency))

# overall complexity mean and standard deviation
scalesComplexityAverage <- weighted.mean(as.numeric(as.character(scalesComplexity$complexity)), scalesComplexity$Frequency)
scalesComplexitySD <- wtd.var(x = as.numeric(as.character(scalesComplexity$complexity)), weights = scalesComplexity$Frequency)

# Table complexity distribution
scalesComplexity %>%
  kbl(., 
        #label = "",
        caption = "Methodological Literature: <br>Number of Aspects considered",
        format = "html", 
        digits = 2,
        #linesep = "",
        #booktabs = T,
        align = c('l', rep('c', length(scalesComplexity)-1)))  %>%
  footnote(general = paste0("M = ",format(round(scalesComplexityAverage, 2), nsmall=2), ", SD = ", format(round(scalesComplexitySD, 2), nsmall=2))) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r scalesElementComplexityBar, fig.cap="Methodological Literature: Bar Graph Number of Aspects considered"}
# barplot of complexity frequency
scalesComplexityBar <- ggplot(data=scalesComplexity, aes(x=complexity, y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    #aes(label = paste0("N = ",Frequency)),
    aes(label = paste0(format(round(Percentage,2), nsmall=2), "%")),
    position=position_stack(vjust=0.5),
    color = "white",
    size = 4,
    vjust = 0.5
    ) +
  labs(title = "Numer of Aspects Considered",
       y = "Frequency across all Scales",
       x = "Number of Aspects Considered")+
  coord_flip()+
  theme_Publication()+
  theme(strip.background = element_rect(fill="grey14", color="grey14", ),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=10, face="bold", hjust = 0.5),
        axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=10),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        legend.position="none")

scalesComplexityBar
```

```{r scalesElementAspectComplexity}
# Numer of Aspects Considered for each element
scalesElementComplexity <- scalesElementCombFreq %>%
  gather(key = "Element", value = "ElementDum", Affect, Behavior, Cognition, Desire) %>%
  filter(ElementDum == 1) %>%
  group_by(Element) %>%
  summarise(n = sum(Frequency),
            avgComplexity = weighted.mean(x = complexity, w = Frequency),
            sdComplexity = wtd.var(x = complexity, weights = Frequency)) %>%
  ungroup() %>%
  mutate(seComplexity = sdComplexity/sqrt(n)) %>%
  arrange(-avgComplexity)

# Table Aspect complexity distribution
scalesElementComplexity %>%
  kbl(., 
        #label = "",
        caption = "Methodological Literature: <br>Number of Aspects considered with each aspect",
        col.names = c("Aspect", "N", "Mean", "Standard Deviation", "Standard Error"),
        format = "html", 
        digits = 2,
        #linesep = "",
        #booktabs = T,
        align = c('l', rep('c', length(scalesElementComplexity)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

We additionally inspected bi-variate relations between the individual aspects. We calculate the phi coefficient (for binary variables) together with the raw number of co-occurrences (see Table \@ref(tab:scalesElementCooccurrences)).  

```{r scalesElementCooccurrences}
# make crossproduct matrix to condense co-occurrences (off-diagonals) and get frequencies (diagonals)
as.matrix(dt.Scales.Included %>% dplyr::select(Affect = AffectFinal, Behavior = BehaviorFinal,	Cognition = CognitionFinal,	Desire = DesireFinal) %>%
            mutate_all(~replace(., is.na(.), 0))) %>%
  BinaryCor(., "pearson") %>%
  tibble::rownames_to_column(., var = "Aspect") %>%
  kbl(., 
        #label = "",
        caption = "Methodological Literature: <br>Aspects Bi-Variate Relations",
        format = "html", 
        linesep = "",
        booktabs = T,
        align = c('l', rep('c', ncol(.)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r scalesExperienceCombinedBar, fig.width=12, fig.height=12, fig.cap="Methodological Literature: Combined Bar Graphs"}
# draw combined graph
cowplot::ggdraw() +
  cowplot::draw_plot(scalesABCDComb, x = 0, y = 0.3, width = 1, height = .7)+
  cowplot::draw_plot(scalesABCDBar, x = 0, y = 0, width = .55, height = .3) +
  cowplot::draw_plot(scalesComplexityBar, x = .55, y = 0, width = .45, height = .3) +
  cowplot::draw_plot_label(c("(A)", "(B)", "(C)"), c(0, 0, 0.55), c(1, 0.3, 0.3), size = 15)
```

## Context
### Culture  
We also coded the cultural context the scales were validated in. We coded both the migrants' country of origin as well as the country of the receivong society in which the study was conducted (see Figure \@ref(fig:scalesCountryFreqBar)).  

```{r scalesCountryFreq, message=F}
# Frequencies of host country focus
scalesHostFreq <- dt.Scales.Included %>%
  dplyr::select(HostCountry) %>%
  mutate(country = strsplit(as.character(HostCountry), ", ")) %>% 
  unnest(country) %>%
  group_by(country) %>%
  summarise(Host = n()) %>%
  arrange(-Host)
  
# Frequencies of origin country focus
scalesOriginFreq <- dt.Scales.Included %>%
  dplyr::select(OriginCountry) %>%
  mutate(country = strsplit(as.character(OriginCountry), ", ")) %>% 
  unnest(country) %>%
  group_by(country) %>%
  summarise(Origin = n()) %>%
  arrange(-Origin)

# Frequencies of host country focus in wide format
scalesCountryFreqWide <- merge(scalesHostFreq, scalesOriginFreq, by = "country", all = TRUE) %>%
  mutate_if(is.numeric, funs(replace_na(., 0)))

# Frequencies of host country focus in long format
scalesCountryFreqLong <- scalesCountryFreqWide %>%
  melt(., id="country", value.name = "Frequency")
```

```{r scalesCountryFreqBar, fig.cap="Bar graph of scales counts for the individual host countries and countries of origin.", warning=F, fig.height=20}
# bar plot country frequencies
ggplot(scalesCountryFreqLong , aes(x=reorder(country, Frequency), y=Frequency)) +
  geom_bar(stat="identity", fill="grey14") +
  labs(x = "Country") +
  coord_flip()+
  facet_wrap( ~ variable, nrow = 1) +
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

### Individual  
The study sample a scale is validated in can be fairly important if one plans to use a scale for a context-specific phenomenon such as a cultural adaptation of two specific cultures. We, therefore, coded the type of sample the original authors used in their validation studies (see Figure \@ref(fig:scalesSampleFreq)).  

```{r scalesSampleFreq, fig.cap="Bar graph of the study samples used in the original validation studies."}
# tally different samples
scalesSampleFreq <- as.data.frame(table(Sample = dt.Scales.Included$Sample)) %>%
  arrange(Freq) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Sample=factor(Sample, levels=Sample)) # update factor levels
  
# barplot of sample frequency
ggplot(data=scalesSampleFreq, aes(x=Sample, y=Freq)) +
  geom_bar(stat="identity", fill="grey14") +
  ylab("Frequency") +
  ggtitle("Validation Sample") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

The category *general* refers to a sampling strategy in which any consenting adult could participate in the study.  

### Situation  
Acculturation can happen in different life domains [e.g., @Arends-Toth2007; @Zane2004]. We coded which life domains the scales referred to within the scale items.  (see Figure \@ref(fig:scalesDomainsBar)).  

```{r scalesDomains}
## prepare life domain data
# make vector with of unique life Domains
uniqueDomains <- purrr::discard(dt.Input$DomainTheory, is.na)
# make new dataframe withe only the life domain data from all scales
scalesDomains <- data.frame(lifeDomain = dt.Scales.Included$lifeDomain)
# add unique list of life domains as NA columns to the data frame
scalesDomains[,uniqueDomains] <- NA
# for each unique life domain [j] check whether it was included within the scale [i]
for (i in 1:nrow(scalesDomains)) {
  for (j in 1:length(uniqueDomains)) {
    scalesDomains[i,j+1] <- grepl(uniqueDomains[j], scalesDomains$lifeDomain[i], fixed = TRUE)*1
  }
}
# count how many life domains were coded for each scale
scalesDomains <- scalesDomains %>%
  mutate(nDomain = rowSums(across(contains(uniqueDomains))))
#make a frequency table for all the individual life domains
scalesDomainFreq <- colSums(scalesDomains %>% select(contains(uniqueDomains))) %>%
  data.frame(Domain=names(.), Frequency=., row.names=NULL) %>%
  mutate(Percentage = Frequency/nrow(scalesDomains)*100) %>%
  arrange(desc(Frequency))
# count frequencies of combinations
scalesDomainCombFreq <- scalesDomains %>%
  group_by(lifeDomain) %>%
  summarise(Frequency = n()) %>%
  mutate(Percentage = Frequency/nrow(scalesDomains)*100) %>%
  arrange(desc(Frequency))

scalesDomainUniqueComb <- format(round(sum(scalesDomainCombFreq$Percentage[scalesDomainCombFreq$Frequency==1]), 2), nsmall=2)
scalesDomainLess5 <- format(round(sum(scalesDomainCombFreq$Percentage[scalesDomainCombFreq$Percentage<5]), 2), nsmall=2)
```

```{r scalesDomainsBar, fig.cap="Empirical Literature: Bar Graph Situational Domains"}
# bar plot frequencies
scalesDomainsBar <- ggplot(scalesDomainFreq, aes(x=reorder(Domain, Frequency), y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    aes(y=Percentage, label = paste0(format(round(Percentage,2), nsmall=2),"% [N = ", Frequency, "]")),
    color = "grey14",
    size = 4,
    hjust = -.1,
    inherit.aes = TRUE
    ) +
  scale_y_continuous(limits = c(0, ceiling(max(scalesDomainFreq$Percentage)*1.15)),
                     breaks = seq(0, ceiling(max(scalesDomainFreq$Percentage)*1.15), 5))+
  labs(y = "Proportion of all theories [in %]",
       x = "Combination of Experience Aspects")+
  coord_flip()+
  theme_Publication()+
  theme(strip.background = element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")

scalesDomainsBar
```

We then assessed domain clusters (i.e., combinations of domains that were assessed jointly). Unfortunately, a large number of scales focused on a unique combination of life domains (`r scalesDomainUniqueComb`%) and a large majority of domain combinations was used by less then five percent of the scales (`r scalesDomainLess5`%, also see \@ref(tab:scalesDomainCombTbl)).

```{r scalesDomainCombTbl}
scalesDomainCombFreq %>%
  mutate(lifeDomain=str_replace_all(lifeDomain, ",", ", ")) %>%
  as.data.frame %>%
  kbl(., 
      #label = ,
      col.names = c("Life Domain Combination", "Frequency", "Percentage"),
      caption = "Empirical Literature: <br>Domain Combinations",
      #format = "html", 
      linesep = "",
      booktabs = T,
      align = c('l', rep('c', ncol(.)-1)))  %>%
  kableExtra::column_spec(1, width="50em") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
  scroll_box(width = "100%", height = "500px")
```

We additionally inspected bi-variate relations between the individual life domains. We calculate the phi coefficient (for binary variables) together with the raw number of co-occurrences (see Table \@ref(tab:methodologicalDomainCooccurrences) and Figure \@ref(fig:methodologicalDomainNetwork)).  

```{r methodologicalDomainCooccurrences}
# make crossproduct matrix to condense co-occurrences (off-diagonals) and get frequencies (diagonals)
as.matrix(scalesDomains %>% dplyr::select(contains(uniqueDomains), -"N/A") %>%
            mutate_all(~replace(., is.na(.), 0))) %>%
  BinaryCor(., "pearson") %>%
  tibble::rownames_to_column(., var = "Domain") %>%
  kbl(., 
        #label = "",
        caption = "Empirical Literature: <br>Domains Bi-Variate Relations",
        format = "html", 
        linesep = "",
        booktabs = T,
        align = c('l', rep('c', ncol(.)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r methodologicalDomainNetwork, fig.cap="Network graph of the domain frequencies and co-occurences. The nodes (i.e., circles) represent the life domains so that the size of the circle indicates the number of times the domain was coded and the edges (i.e., connections) represent the co-occurences so that the width of the line indicates how often the domains were measured together in one scale."}
# make crossproduct matrix to condense co-occurrences (off-diagonals) and get frequencies (diagonals)
X <- as.matrix(scalesDomains %>% dplyr::select(-c("lifeDomain", "N/A", "nDomain")))
 out <- crossprod(X)  # Same as: t(X) %*% X
 #diag(out) <- 0       # remove frequencies on diagonals

 # information on the concepts themselves
 nodes <- data.frame(id    = colnames(out), 
                     title = paste0(colnames(out), "<br>Frequency: ", diag(out)), 
                     value = diag(out),
                     size  = diag(out),
                     shape = "dot")

 # information on the co-occurrences
 edges           <- as.data.frame(t(combn(colnames(out),2)))
 colnames(edges) <- c('from','to')
 edges$width     <- NA
 for (i in 1:nrow(edges)) {
     edges$width[i] <- out %>%
      as.data.frame(.) %>%
      rownames_to_column('dim') %>%
      filter(dim == edges$to[i]) %>%
      dplyr::select(any_of(edges$from[i])) %>%
      as.numeric(.)
}
edges$label <- edges$width
edges$title <- paste0(edges$from, " - ", edges$to, "<br>Co-occurences: ", edges$width)

# plot network graph
visNetwork(nodes, edges %>% mutate(width = scales::rescale(edges$width, to=c(1,20))), 
           heigth = "100%", width = "100%", main = "Co-occurences of Life Domains as Network") %>%
            visIgraphLayout(layout = "layout_in_circle") %>%
            visNodes(
                shape = "dot",
                color = list(
                    background = "#0085AF",
                    border = "#013848",
                    highlight = "#FF8000"
                )
            ) %>%
            visEdges(
                shadow = FALSE,
                color = list(color = "#0085AF", highlight = "#C62F4B")
            ) %>%
            visOptions(highlightNearest = list(enabled = T, degree = 1, hover = T), 
                       nodesIdSelection = list(main = "Select variable")) %>% 
            visInteraction(keyboard = TRUE, tooltipDelay = 0) %>%
            visLayout(randomSeed = 11)
```

### Process  
To assess the temporal focus of the validated scales we also checked whether scales were validated for samples prior to migration, post-migration, or both (see Table \@ref(tab:scalesMigrationTimeFreq)).  

```{r scalesMigrationTimeFreq}
# table of the migration time focus
dt.Scales.Included %>%
  dplyr::select(MigrationTime) %>%
  mutate(MigrationTime = replace_na(MigrationTime, "N/A")) %>%
  group_by(MigrationTime) %>%
  summarise(Frequency = n(),
            Percentage = Frequency/nrow(.)*100) %>%
  arrange(desc(Frequency)) %>%
  kbl(., caption = "Methodological Literature: <br>Migration Time",
      format = "html",
      digits = 2,
      col.names = c("Migration Time", "Frequency", "Percentage")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Content

While a discussion of all the topics addressed by the included scales lies beyond the scope of this study, we would like to describe some of the larger patterns authors have focused on. To that aim, we ran a machine learning topic modeling procedure on the items of the scales to identify content topics. 

For the topic modeling of the acculturation scales, we particularly used the scale items in a Latent Dirichlet Allocation (LDA) analysis, an unsupervised machine learning method common within the natural language processing literature. The analysis essentially extracts sets of terms that tended to occur together, assuming that scales that measure a specific topic have more words that relate to the topic than scales that measure other topics. We followed the procedures outlined by @Schweinberger2022. 

In particular, we:

1. Transformed the items as a Text Corpus object 
2. Pre-processed the text data
    a. all words in lower case
    b. English stop words removed
    c. punctuation removed
    d. numerals removed
    e. word stems extracted
    f. superfluous white spaces removed
3. transformed the text corpus into a Document Term Matrix
4. determined the appropriate number of topics to extract
5. ran the LDA with varying alphas
6. extracted the most probable topics

```{r ScaleItemDescr, results='hide'}
scaleItemDescr <- psych::describe(as.numeric(dt.Scales.Included$NItems))
scaleDomainDescr <- psych::describe(as.numeric(str_count(dt.Scales.Included$lifeDomain, ',')+1))


# Based on 
# Schweinberger, Martin. 2022. Topic Modeling with R. Brisbane: The University of Queensland. url: https://slcladal.github.io/topicmodels.html (Version 2022.05.21).
library(DT)
library(tm)
library(topicmodels)
library(reshape2)
library(ggplot2)
library(wordcloud)
library(pals)
library(SnowballC)
library(lda)
library(ldatuning)
library(flextable)
textdata <- base::readRDS(url("https://slcladal.github.io/data/sotu_paragraphs.rda", "rb"))
textdata <- dt.Scales.Included %>%
  select(
    Scale,
    CitationKey,
    Item
  ) %>%
  mutate(
    doc_id = row_number(),
    text = gsub("[\r\n]", "", Item)
  ) %>%
  select(
    -Item
  ) %>% 
  as.data.frame

# load stopwords
english_stopwords <- readLines("https://slcladal.github.io/resources/stopwords_en.txt", encoding = "UTF-8")

# create corpus object
corpus <- Corpus(DataframeSource(textdata))
# Preprocessing chain
processedCorpus <- tm_map(corpus, content_transformer(tolower))
processedCorpus <- tm_map(processedCorpus, removeWords, english_stopwords)
processedCorpus <- tm_map(processedCorpus, removePunctuation, preserve_intra_word_dashes = TRUE)
processedCorpus <- tm_map(processedCorpus, removeNumbers)
processedCorpus <- tm_map(processedCorpus, stemDocument, language = "en")
processedCorpus <- tm_map(processedCorpus, stripWhitespace)

# compute document term matrix with terms >= minimumFrequency
minimumFrequency <- 5
DTM <- DocumentTermMatrix(processedCorpus, control = list(bounds = list(global = c(minimumFrequency, Inf))))
# have a look at the number of documents and terms in the matrix
dim(DTM)

# due to vocabulary pruning, we have empty rows in our DTM
# LDA does not like this. So we remove those docs from the
# DTM and the metadata
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
textdata <- textdata[sel_idx, ]

# create models with different number of topics
result <- ldatuning::FindTopicsNumber(
  DTM,
  topics = seq(from = 2, to = 20, by = 1),
  metrics = c("CaoJuan2009",  "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  verbose = TRUE
)

FindTopicsNumber_plot(result)

# number of topics
K <- 20
# set random number generator seed
set.seed(9161)
# compute the LDA model, inference via 1000 iterations of Gibbs sampling
topicModel <- LDA(DTM, K, method="Gibbs", control=list(iter = 500, verbose = 25))

# have a look a some of the results (posterior distributions)
tmResult <- posterior(topicModel)
# format of the resulting object
#attributes(tmResult)
# lengthOfVocab
#nTerms(DTM) 
# get beta from results
beta <- tmResult$terms   
#dim(beta)  
# rows in beta sum to 1
#rowSums(beta)    
# size of collection
#nDocs(DTM)               
# for every document we have a probability distribution of its contained topics
theta <- tmResult$topics 
#dim(theta)               # nDocs(DTM) distributions over K topics

exampleTermData <- terms(topicModel, 10)
exampleTermData[, 1:8]

top5termsPerTopic <- terms(topicModel, 5)
topicNames <- apply(top5termsPerTopic, 2, paste, collapse=" ")

# visualize topics as word cloud
topicToViz <- 11 # change for your own topic of interest
topicToViz <- grep('feel', topicNames)[1] # Or select a topic by a term contained in its name
# select to 40 most probable terms from the topic by sorting the term-topic-probability vector in decreasing order

topTopicTerms <- list()
topTopicTermsPlot <- list()
mycolors <- brewer.pal(8, "Dark2")

for (i in 1:K) {
  top40terms <- sort(tmResult$terms[i,], decreasing=TRUE)[1:40]
  topTopicTerms[[i]] <- top40terms
  topTopicTermsPlot[[i]] <- ggwordcloud(names(top40terms), top40terms, random.order = FALSE, color = mycolors)
}

#grid.arrange(grobs = topTopicTermsPlot, ncol = 5)

# focus on unique topics
set.seed(9161)
topicModel2 <- LDA(DTM, K, method="Gibbs", control=list(iter = 500, verbose = 25, alpha = 0.2))
tmResult <- posterior(topicModel2)
theta <- tmResult$topics
beta <- tmResult$terms
topicNames <- apply(terms(topicModel2, 5), 2, paste, collapse = " ")  # reset topicnames


# re-rank top topic terms for topic names
topicNames <- apply(lda::top.topic.words(beta, 5, by.score = T), 2, paste, collapse = " ")


## APROACH 1
# What are the most probable topics in the entire collection?
topicProportions <- colSums(theta) / nDocs(DTM)  # mean probabilities over all paragraphs
names(topicProportions) <- topicNames     # assign the topic names we created before
sort(topicProportions, decreasing = TRUE) # show summed proportions in decreased order

soP <- sort(topicProportions, decreasing = TRUE)
#paste(round(soP, 5), ":", names(soP))

## APPROACH 2
countsOfPrimaryTopics <- rep(0, K)
names(countsOfPrimaryTopics) <- topicNames
for (i in 1:nDocs(DTM)) {
  topicsPerDoc <- theta[i, ] # select topic distribution for document i
  # get first element position from ordered list
  primaryTopic <- order(topicsPerDoc, decreasing = TRUE)[1] 
  countsOfPrimaryTopics[primaryTopic] <- countsOfPrimaryTopics[primaryTopic] + 1
}
sort(countsOfPrimaryTopics, decreasing = TRUE)

so <- sort(countsOfPrimaryTopics, decreasing = TRUE)
#paste(so, ":", names(so))

# SCALES:
# get mean topic proportions per decade
topic_proportion_per_scale <- aggregate(theta, by = list(scale = textdata$CitationKey), mean)
# set topic names to aggregated columns
colnames(topic_proportion_per_scale)[2:(K+1)] <- topicNames
# reshape data frame
vizDataFrame <- melt(topic_proportion_per_scale, id.vars = "scale")
# plot topic proportions per decade as bar plot
ggplot(vizDataFrame, aes(x=scale, y=value, fill=variable)) + 
  geom_bar(stat = "identity") + ylab("proportion") + 
  scale_fill_manual(values = paste0(alphabet(20), "FF"), name = "scale") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r ldaTbl}
soP %>%
  kbl(., 
      caption = "LDA: Proportions of all 20 topics with the five most common terms extracted",
      format = "html",
      digits = 2) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```


# **Empirical Literature**  

## Descriptives  

### Publication Type  
A majority of the results were journal articles but we also reviewed a number of theses and book chapters (see Table \@ref(tab:PsychPublicationType)).  

```{r PsychPublicationType}
dt.Empirical.included %>%
  dplyr::select(PublicationType) %>%
  group_by(PublicationType) %>%
  summarise(Frequency = n(),
            Percentage = Frequency/nrow(.)*100) %>%
  arrange(desc(Frequency)) %>%
  kbl(., caption = "Empirical Literature: <br>Type of Publication",
      format = "html",
      digits = 2) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Data Type
A majority of the empirical papers were quantitative assessments of acculturation (for an overview of the data collection types see Table \@ref(tab:PsychMethod)).  

```{r PsychMethod}
dt.Empirical.included %>%
  dplyr::select(Method) %>%
  group_by(Method) %>%
  summarise(Frequency = n(),
            Percentage = Frequency/nrow(.)*100) %>%
  arrange(desc(Frequency)) %>%
  kbl(., caption = "Empirical Literature: <br>Type of Data Collection",
      format = "html",
      digits = 2,
      col.names = c("Data Type", "Frequency", "Percentage")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Sample
majority, year of publication

We firstly assessed how many of the scale validations included the dominant group was measured as well (see Table \@ref(tab:empiricalMajority)).  

```{r empiricalMajority}
# Count whether validations included Majority
empiricalMajFreq <- dt.Empirical.included %>%
  dplyr::select(IncludesMajority) %>%
  filter(!is.na(IncludesMajority)) %>%
  mutate(`Includes Majority` = recode_factor(.$IncludesMajority, `0` = "no", `1` = "yes")) %>%
  group_by(`Includes Majority`) %>%
  summarise(Frequency = n(),
            Percentage = Frequency/nrow(.)*100)

empiricalMajFreq %>%
  kbl(., 
      #label = "",
      caption = "Empirical Literature: <br>Dominant Group Included Frequency",
      format = "html", 
      #linesep = "",
      #booktabs = T,
      digits = 2,
      align = c('l', rep('c', ncol(.)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

Of the scale we included we also plotted the publication years of the scale validations in order to gain an understanding of the interest in scale development over time (see Figure \@ref(fig:empiricalYear)).   

```{r empiricalYear, fig.cap="Year of Publication [Empirical Works]. The graph shows the cumulative sum in the main graph as well as the number of works published over time in the marginal graph."}
# marginal histogram of number of manuscripts per year (with minimal theme)
empiricalHist <- dt.Empirical.included %>%
  dplyr::select(year) %>%
  mutate(year = as.POSIXct(as.character(year), format = "%Y")) %>%
  ggplot(., aes(x=year)) + 
  geom_histogram(bins = length(table(dt.Empirical.included$year)), fill = "grey14") +
  labs(title = "Year of Publication [Empirical works]",
       y = "Number of Studies",
       x = "Year") +
  #scale_y_continuous(breaks = seq(0,20,10)) +
  scale_x_datetime(breaks = as.POSIXct(as.character(seq(1920,2020,10)), format = "%Y"), date_labels = "%Y") +
  theme_Publication() +
  theme(strip.background = element_rect(fill="grey14", color="grey14"),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_blank(), #element_text(size=16, face="bold", hjust = 0.5),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.line.x = element_blank(),
        axis.line.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        plot.margin = unit(c(5, 5, 0, 5), "pt"),
        legend.position="none")

# Cumulative Sum of articles published over time
empiricalYearCum <- data.frame(table(Year = dt.Empirical.included$year)) %>%
  mutate(Year = as.POSIXct(Year, format = "%Y"),
         CumSum = cumsum(Freq)) %>%
  ggplot(., aes(x=Year, y=CumSum, group=1)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(breaks = seq(0,550,50)) +
  scale_x_datetime(breaks = as.POSIXct(as.character(seq(1920,2020,10)), format = "%Y"), date_labels = "%Y") +
  labs(title = "Year of Publication [Empirical works]",
       y = "Cumulative Sum",
       x = "Year") +
  theme_Publication() +
  theme(strip.background = element_rect(fill="grey14", color="grey14", ),
        axis.title.x = element_text(size=14, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        plot.title = element_blank(), #element_text(size=16, face="bold", hjust = 0.5),
        axis.text.x = element_text(size=14),
        axis.text.y = element_text(size=14),
        #panel.grid.major.x = element_blank(),
        #panel.grid.major.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        plot.margin = unit(c(0, 5, 5, 5), "pt"),
        legend.position="none")

# combine the two plots
cowplot::plot_grid(empiricalHist, empiricalYearCum, nrow=2, align = "v", rel_heights = c(1/5, 4/5))
```

We additionally assessed empirical developments in terms of publication type (see Figure \@ref(fig:empiricalYearPubtype)) and data collection type (see Figure \@ref(fig:empiricalYearMethod)).  

```{r empiricalYearPubtype, warning=F, fig.cap="Density plot of the yearly publication frequency by type of publication."}
ggplot(dt.Empirical.included, aes(x=year, linetype = PublicationType, shape = PublicationType)) + 
  geom_density(aes(y = ..count..)) +
  #geom_line(stat='count') +
  geom_point(stat='count', size = .9) +
  ylab("Number of Publications")+
  xlab("Year") +
  ggtitle("Publication Year by Publication Type (Density Plot)")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="bottom")
```

```{r empiricalYearMethod, warning=F, fig.cap="Density plot of the yearly publication frequency by data collection type."}
ggplot(dt.Empirical.included, aes(x=year, linetype = Method, shape = Method)) + 
  geom_density(aes(y = ..count..)) +
  #geom_line(stat='count') +
  geom_point(stat='count', size = .9) +
  ylab("Number of Results")+
  xlab("Year") +
  ggtitle("Publication Year by Data Type (Density Plot)")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="bottom")
```

### Focus
Term used, focus of the paper, variable type, analysis

The field of acculturation has been using a variety of terms to describe the process of cultural adaptation. We list the terms the authors used in their paper to refer to cultural adaptation in Table \@ref(tab:empiricalTerm).  

```{r empiricalTerm}
dt.Empirical.included %>%
  dplyr::select(term) %>%
  mutate(term = tolower(term)) %>%
  group_by(term) %>%
  summarise(Frequency = n(),
            Percentage = Frequency/nrow(.)*100) %>%
  arrange(desc(Frequency)) %>%
  kbl(., caption = "Empirical Literature: Terms used",
      format = "html",
      digits = 2,
      col.names = c("Term", "Frequency", "Percentage")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "100%", height = "500px")
```

For the empirical works we also coded the main focus of the papers. The wordcloud of the topics illustrates that although a majority of articles also have acculturation as their main focus, health and adjustment are also fields that measured acculturation in their empirical works (see Figure \@ref(fig:empiricalTopicFrequencies)).  

```{r empiricalTopicFrequencies, warning=F, fig.cap="Wordcloud of the article foci in the empirical results."}
# remove duplicate domains
UniqueDomains <- dt.Domains %>% 
  filter(Duplicate == "Unique")

# dataframe to compile domain frequency for Review Topics
empiricalTopicFreq <- data.frame(UniqueDomains, Frequency = NA)

# count domain frequency in dt.Scales.Included
for (i in 1:nrow(UniqueDomains)) {
  empiricalTopicFreq$Frequency[i] <- length(grep(UniqueDomains$Domain[i], dt.Empirical.included$domainPaper, value = T))
}

# prepare for ggplot
empiricalTopicFreq <- empiricalTopicFreq %>%
  dplyr::select(Domain, Frequency) %>%
  filter(Frequency > 0) %>%
  arrange(Frequency) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Domain=factor(Domain, levels=Domain)) # update factor levels

# Word cloud frequencies
set.seed(7) # for reproducibility 
wordcloud(words = empiricalTopicFreq$Domain, freq = empiricalTopicFreq$Frequency, 
          min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
```

### Measure Used  
We list the measures used by the authors in Table \@ref(tab:empiricalMeasures). Note that a majority of the measurements are not previously standardized and are not shared across articles.  

```{r empiricalMeasures}
dt.Empirical.included %>%
  dplyr::select(MeasureDefinition) %>%
  mutate(MeasureDefinition = tolower(MeasureDefinition)) %>%
  group_by(MeasureDefinition) %>%
  summarise(Frequency = n(),
            Percentage = Frequency / nrow(.) * 100) %>%
  filter(MeasureDefinition != "") %>%
  arrange(desc(Frequency)) %>%
  kbl(
    .,
    caption = "Empirical Literature: Measure used",
    format = "html",
    digits = 2,
    col.names = c("Measure", "Frequency", "Percentage")
  ) %>%
  kable_classic(
    full_width = F,
    lightable_options = "hover",
    html_font = "Cambria"
  ) %>%
  scroll_box(width = "100%", height = "500px")
```

## Experience  
```{r EmpiricalKappa}
names <- c("Affect", "Behavior", "Cognition", "Desire")
kEmp <- dt.Empirical.included %>%
  select(Affect, Affect2, Behavior, Behavior2, Cognition, Cognition2, Desire, Desire2) %>%
  mutate_all(~replace_na(., 0)) %>%
  kappa.full.multiple(., names)
kEmpPooled <- kappa.pooled2(kEmp)
```

We then look at the use of experience aspects within the empirical works in more detail. All inter-rater agreements were `r format(round(min(kEmp$Po, na.rm = TRUE)*100, 2), nsmall=2)`% or above and all $\kappa$s were above `r format(round(min(kEmp$k, na.rm = TRUE), 2), nsmall=2)` ($\kappa_{pooled}$ = `r format(round(kEmpPooled$k.pooled, 2), nsmall=2)`, $95\%CI_{boot}$[`r  format(round(kEmpPooled$lwr, 2), nsmall=2)`, `r format(round(kEmpPooled$upr, 2), nsmall=2)`]; for full inter-rater reliability see Table \@ref(tab:EmpiricalKappaTbl)).  

```{r EmpiricalKappaTbl}
kEmp %>%
  kbl(., 
      #label = "",
      caption = "Empirical Literature: <br>Cohen's $\\kappa$",
      format = "html", 
      #linesep = "",
      #booktabs = T,
      align = c('l', rep('c', length(.)-1)),
      digits=3)  %>%
  kableExtra::footnote(general = paste0("$\\kappa_{pooled}$ = ",format(round(kEmpPooled$k.pooled, 2), nsmall=2), ", $95\\%CI_{boot}$[", format(round(kEmpPooled$lwr, 2), nsmall=2), ", ", format(round(kEmpPooled$upr, 2), nsmall=2), "]")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

We were particularly interested in the overall use of each experience aspect (see Table \@ref(tab:empiricalElementFreq) and Figure \@ref(fig:TheoriesElementFreqBar)), the combined uses of experience aspects (see Table \@ref(tab:empiricalElementCombinations) and Figure \@ref(fig:empiricalElementCombinationsBar)), the resulting distribution of the number of aspects considered (see Table \@ref(tab:empiricalElementComplexity) and Figure \@ref(fig:empiricalElementComplexityBar)), as well as the number of other aspects that were considered with each of the aspects (see Table \@ref(tab:empiricalElementAspectComplexity)).  

```{r empiricalElementFreq}
# Count the times each dimension is measured
empiricalElementFreq <- dt.Empirical.included %>%
  dplyr::select(Affect=AffectFinal, Behavior=BehaviorFinal, Cognition=CognitionFinal, Desire=DesireFinal) %>%
  mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  colSums(., na.rm = FALSE, dims = 1) 

# transform to data frame and make row names name variable
empiricalElementFreq <- data.frame(Element = names(empiricalElementFreq), 
                            Frequency = empiricalElementFreq, 
                            Percentage = empiricalElementFreq/nrow(dt.Empirical.included)*100) %>%
  mutate(Element = fct_reorder(Element, Frequency)) %>%
  arrange(desc(Frequency))

empiricalElementFreq %>%
  kbl(., 
        #label = "",
        caption = "Empirical Literature: <br>Overall Aspect Frequency",
        format = "html", 
        #linesep = "",
        #booktabs = T,
        align = c('l', 'c', 'c'))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r empiricalElementFreqBar, fig.cap="Empirical Literature: Bar Graph Aspect Frequency"}
# barplot of dimension frequency
empiricalABCDBar <- ggplot(data=empiricalElementFreq, aes(x=Element, y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    #aes(label = paste0("N = ",Frequency)),
    aes(label = paste0(format(round(Percentage,2), nsmall=2), "%")),
    position=position_stack(vjust=0.5),
    color = "white",
    size = 4,
    vjust = 0.5
    ) +
  labs(#title = "Aspect Frequency",
       y = "Percentage across all Studies",
       x = "Experience Aspect")+
  coord_flip()+
  theme_Publication()+
  theme(strip.background = element_rect(fill="grey14", color="grey14"),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=10, face="bold", hjust = 0.5),
        axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=10),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        legend.position="none")

empiricalABCDBar
```

```{r empiricalElementCombinations}
# frequency of unique combinations
empiricalElementCombFreq <- dt.Empirical.included %>%
  dplyr::select(Affect=AffectFinal, Behavior=BehaviorFinal, Cognition=CognitionFinal, Desire=DesireFinal) %>%
  #mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  group_by(Affect, Behavior, Cognition, Desire) %>%
  summarise(Frequency = n()) %>%
  ungroup() %>%
  mutate(complexity = rowSums(dplyr::select(., Affect, Behavior, Cognition, Desire), na.rm = T))

# fill replace ones with colnames to be combined
for (i in 1:4) {
    empiricalElementCombFreq[[i]] <- str_replace(as.character(empiricalElementCombFreq[[i]]), "1", colnames(empiricalElementCombFreq)[i])
}

# collect Elements names for each combination
empiricalElementCombFreq <- empiricalElementCombFreq %>%
  unite("ExperienceCombination",c("Affect", "Behavior", "Cognition", "Desire"), na.rm = TRUE, sep = ", ") %>%
  mutate(ExperienceCombination = fct_reorder(ExperienceCombination, Frequency),
         Percentage = Frequency/nrow(dt.Empirical.included)*100,
         Affect = ifelse(grepl("Affect", ExperienceCombination, fixed = TRUE), 1,0),
         Behavior = ifelse(grepl("Behavior", ExperienceCombination, fixed = TRUE), 1,0),
         Cognition = ifelse(grepl("Cognition", ExperienceCombination, fixed = TRUE), 1,0),
         Desire = ifelse(grepl("Desire", ExperienceCombination, fixed = TRUE), 1,0)) %>%
  arrange(-Frequency)

empiricalElementCombFreq %>%
  kbl(., 
      #label = "",
      caption = "Empirical Literature: Aspect Combinations",
      format = "html", 
      #linesep = "",
      #booktabs = T,
      digits = 2,
      align = c('l', rep('c', length(empiricalElementCombFreq)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r empiricalElementCombinationsBar, fig.cap="Empirical Literature: Bar Graph Aspect Combinations"}
# bar plot frequencies
empiricalABCDComb <- ggplot(empiricalElementCombFreq, aes(x=ExperienceCombination, y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    aes(y=Percentage, label = paste0(format(round(Percentage,2), nsmall=2),"% [N = ", Frequency, "]")),
    color = "grey14",
    size = 4,
    hjust = -.1,
    inherit.aes = TRUE
    ) +
  scale_y_continuous(limits = c(0, ceiling(max(empiricalElementCombFreq$Percentage)*1.15)),
                     breaks = seq(0, ceiling(max(empiricalElementCombFreq$Percentage)*1.15), 5))+
  labs(y = "Proportion of all Studies [in %]",
       x = "Combination of Experience Aspects")+
  coord_flip()+
  theme_Publication()+
  theme(strip.background = element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")

empiricalABCDComb
```

```{r empiricalElementComplexity}
# summarize by aspect complexity
empiricalComplexity <- empiricalElementCombFreq %>%
  dplyr::select(complexity, Frequency) %>%
  group_by(complexity) %>%
  summarise(Frequency = sum(Frequency),
            Percentage = sum(Frequency)/nrow(dt.Empirical.included)*100) %>%
  ungroup() %>%
  mutate(complexity = as.factor(complexity),
         complexity = fct_reorder(complexity, Frequency)) %>%
  arrange(desc(Frequency))

# overall complexity mean and standard deviation
empiricalComplexityAverage <- weighted.mean(as.numeric(as.character(empiricalComplexity$complexity)), empiricalComplexity$Frequency)
empiricalComplexitySD <- wtd.var(x = as.numeric(as.character(empiricalComplexity$complexity)), weights = empiricalComplexity$Frequency)

# Table complexity distribution
empiricalComplexity %>%
  kbl(., 
        #label = "",
        caption = "Empirical Literature: <br>Number of Aspects considered",
        format = "html", 
        digits = 2,
        #linesep = "",
        #booktabs = T,
        align = c('l', rep('c', length(empiricalComplexity)-1)))  %>%
  kableExtra::footnote(general = paste0("M = ",format(round(empiricalComplexityAverage, 2), nsmall=2), ", SD = ", format(round(empiricalComplexitySD, 2), nsmall=2))) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r empiricalElementComplexityBar, fig.cap="Empirical Literature: Bar Graph Number of Aspects considered"}
# barplot of complexity frequency
empiricalComplexityBar <- ggplot(data=empiricalComplexity, aes(x=complexity, y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    #aes(label = paste0("N = ",Frequency)),
    aes(label = paste0(format(round(Percentage,2), nsmall=2), "%")),
    position=position_stack(vjust=0.5),
    color = "white",
    size = 4,
    vjust = 0.5
    ) +
  labs(title = "Empirical Literature: Numer of Aspects Considered",
       y = "Frequency across all Studies",
       x = "Number of Aspects Considered")+
  coord_flip()+
  theme_Publication()+
  theme(strip.background = element_rect(fill="grey14", color="grey14", ),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=10, face="bold", hjust = 0.5),
        axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=10),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        strip.text = element_text(colour = 'white', face="bold"),
        panel.background = element_rect(fill = "transparent"),
        plot.background = element_rect(fill = alpha('white', 0.5)), 
        legend.position="none")

empiricalComplexityBar
```

```{r empiricalElementAspectComplexity}
# Numer of Aspects Considered for each element
empiricalElementComplexity <- empiricalElementCombFreq %>%
  gather(key = "Element", value = "ElementDum", Affect, Behavior, Cognition, Desire) %>%
  filter(ElementDum == 1) %>%
  group_by(Element) %>%
  summarise(n = sum(Frequency),
            avgComplexity = weighted.mean(x = complexity, w = Frequency),
            sdComplexity = wtd.var(x = complexity, weights = Frequency)) %>%
  ungroup() %>%
  mutate(seComplexity = sdComplexity/sqrt(n)) %>%
  arrange(-avgComplexity)

# Table Aspect complexity distribution
empiricalElementComplexity %>%
  kbl(., 
        #label = "",
        caption = "Methodological Literature: <br>Number of Aspects considered with each aspect",
        col.names = c("Aspect", "N", "Mean", "Standard Deviation", "Standard Error"),
        format = "html", 
        digits = 2,
        #linesep = "",
        #booktabs = T,
        align = c('l', rep('c', length(empiricalElementComplexity)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

We additionally inspected bi-variate relations between the individual aspects. We calculate the phi coefficient (for binary variables) together with the raw number of co-occurrences (see Table \@ref(tab:empiricalElementCooccurrences)).  

```{r empiricalElementCooccurrences}
# make crossproduct matrix to condense co-occurrences (off-diagonals) and get frequencies (diagonals)
as.matrix(dt.Empirical.included %>% dplyr::select(Affect=AffectFinal, Behavior=BehaviorFinal, Cognition=CognitionFinal, Desire=DesireFinal) %>%
            mutate_all(~replace(., is.na(.), 0))) %>%
  BinaryCor(., "pearson") %>%
  tibble::rownames_to_column(., var = "Aspect") %>%
  kbl(., 
        #label = "",
        caption = "Empirical Literature: <br>Aspects Bi-Variate Relations",
        format = "html", 
        linesep = "",
        booktabs = T,
        align = c('l', rep('c', ncol(.)-1)))  %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r empiricalExperienceCombinedBar, fig.width=12, fig.height=12, fig.cap="Empirical Literature: Combined Bar Graphs"}
# draw combined graph
cowplot::ggdraw() +
  cowplot::draw_plot(empiricalABCDComb, x = 0, y = 0.3, width = 1, height = .7)+
  cowplot::draw_plot(empiricalABCDBar, x = 0, y = 0, width = .55, height = .3) +
  cowplot::draw_plot(empiricalComplexityBar, x = .55, y = 0, width = .45, height = .3) +
  cowplot::draw_plot_label(c("(A)", "(B)", "(C)"), c(0, 0, 0.55), c(1, 0.3, 0.3), size = 15)
```

## Context
### Culture  
We also coded the cultural context the scales were validated in. We coded both the migrants' country of origin as well as the country of the receivong society in which the study was conducted (see Figure \@ref(fig:empiricalCountryFreqBar)).  

```{r empiricalCountryFreq, message=F}
# Frequencies of host country focus
empiricalHostFreq <- dt.Empirical.included %>%
  dplyr::select(HostCountry) %>%
  mutate(country = strsplit(as.character(HostCountry), ", ")) %>% 
  unnest(country) %>%
  group_by(country) %>%
  summarise(Host = n()) %>%
  arrange(-Host)
  
# Frequencies of origin country focus
empiricalOriginFreq <- dt.Empirical.included %>%
  dplyr::select(OriginCountry) %>%
  mutate(country = strsplit(as.character(OriginCountry), ", ")) %>% 
  unnest(country) %>%
  group_by(country) %>%
  summarise(Origin = n()) %>%
  arrange(-Origin)

# Frequencies of host country focus in wide format
empiricalCountryFreqWide <- merge(empiricalHostFreq, empiricalOriginFreq, by = "country", all = TRUE) %>%
  mutate_if(is.numeric, funs(replace_na(., 0)))

# Frequencies of host country focus in long format
empiricalCountryFreqLong <- empiricalCountryFreqWide %>%
  melt(., id="country", value.name = "Frequency")
```

```{r empiricalCountryFreqBar, fig.cap="Empirical Literature: Bar graph of study counts for the individual host countries and countries of origin.", warning=F, fig.height=24}
# bar plot country frequencies
ggplot(empiricalCountryFreqLong , aes(x=reorder(country, Frequency), y=Frequency)) +
  geom_bar(stat="identity", fill="grey14") +
  labs(x = "Country") +
  coord_flip()+
  facet_wrap( ~ variable, nrow = 1) +
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

### Individual  
We, again, coded the type of sample the original authors used in their validation studies (see Figure \@ref(fig:empiricalSampleFreq)).  

```{r empiricalSampleFreq, fig.cap="Bar graph of the study samples used in the empirical studies."}
# tally different samples
empiricalSampleFreq <- as.data.frame(table(Sample = dt.Empirical.included$Sample)) %>%
  arrange(Freq) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Sample=factor(Sample, levels=Sample)) # update factor levels
  
# barplot of sample frequency
ggplot(data=empiricalSampleFreq, aes(x=Sample, y=Freq)) +
  geom_bar(stat="identity", fill="grey14") +
  ylab("Frequency") +
  ggtitle("Validation Sample") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

The category *general* refers to a sampling strategy in which any consenting adult could participate in the study.  

### Situation  
We coded which life domains the authors referred to, either as part of subscale labels, factor labels, explicit commentary of the authors, or clear question wordings to gain an understanding of the situational focus the authors chose. However, we did not code the theoretical situational life domains because such an undertaking would be beyond the scope of this paper. 

### Process  
To assess the temporal focus of the empirical studies, we also checked whether studies sampled migrants prior to migration, post-migration, or both (see Table \@ref(tab:empiricalMigrationTimeFreq)).  

```{r empiricalMigrationTimeFreq}
# table of the migration time focus
dt.Empirical.included %>%
  dplyr::select(MigrationTime) %>%
  mutate(MigrationTime = replace_na(MigrationTime, "N/A")) %>%
  group_by(MigrationTime) %>%
  summarise(Frequency = n(),
            Percentage = Frequency/nrow(.)*100) %>%
  arrange(desc(Frequency)) %>%
  kbl(., caption = "Empirical Literature: <br>Migration Time",
      format = "html",
      digits = 2,
      col.names = c("Migration Time", "Frequency", "Percentage")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

Finally, we also coded what kind of analyses the authors conducted with the acculturation measurements in the empirical studies (see Table \@ref(tab:empiricalAnalysis)).  

```{r empiricalAnalysis}
# tally different analysis types
dt.Empirical.included %>%
  dplyr::select(MainAnalysis) %>%
  mutate(MainAnalysis = replace_na(MainAnalysis, "N/A")) %>%
  group_by(MainAnalysis) %>%
  summarise(Frequency = n(),
            Percentage = Frequency/nrow(.)*100) %>%
  arrange(desc(Frequency)) %>%
  kbl(., caption = "Empirical Literature: Main Analysis in which Acculturation Measure was used",
      format = "html",
      digits = 2,
      col.names = c("Analysis", "Frequency", "Percentage")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

Additionally, we coded where in the model the acculturation measure was placed (see Table \@ref(tab:PsychVarType)).  

```{r PsychVarType}
# tally different variable types
dt.Empirical.included %>%
  dplyr::select(VariableType) %>%
  mutate(VariableType = replace_na(VariableType, "N/A")) %>%
  group_by(VariableType) %>%
  summarise(Frequency = n(),
            Percentage = Frequency/nrow(.)*100) %>%
  arrange(desc(Frequency)) %>%
  kbl(., caption = "Empirical Literature: Variable Type of Acculturation Analysis",
      format = "html",
      digits = 2,
      col.names = c("Variable Type", "Frequency", "Percentage")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

## Field Differences   

To assess the differences between fields we merged the [Scimago Journal Ranking Database](https://www.scimagojr.com/journalrank.php) with our empirical review. For all available <ins>journal articles</ins> we added information on key journal metrics:  

- Scimago Journal Rank Indicator (_SJR_, year-average weighted citations of articles published in past 3-year period)  
- H Index (h number of articles that have been cited at least h times)  
- Number of articles published in 2019  
- Number of articles published in 2017, 2018, 2019  
- Number of references in published articles (2019)  
- Number of citations in 2016-2018  
- Number of citable documents 2016-2018  
- Average number of citations per document in a 2-year period  
- Average number of references per document in 2019  
- Country of publisher  
- Region of publisher  
- Time period of journal activity (_Coverage_)  
- Keywords (_Categories_)  
- Field  

### Merging  
We first merged the full Scimago Journal database with our own database of empirical studies. 
```{r mergeJournalInfo, warning=F}
# unify Journal ISSNs for data merge 
psychData <- dt.Empirical.included %>%
  mutate(ISSN = gsub("-", "", ISSN))
PublisherInfo <- PublisherInfo %>%
  separate(Issn, c("Issn01", "Issn02"), remove = FALSE)

# Merge Scimago database with empirical studies
psychData <- sqldf("SELECT l.*, r.*
              FROM psychData as l
              LEFT JOIN PublisherInfo as r
              on l.PublicationTitle = r.PublicationTitleDb OR l.ISSN = r.Issn01 OR l.ISSN = r.Issn02")

# filter studies that are not in the Scimago database
psychDataJournal <- psychData %>% filter(!is.na(PublicationTitleDb))
```

_Note_ that dissertations, book chapters, and books were excluded from this analysis because data on their publishers is not readily available or unreliable. Additionally, `r nrow(psychData %>% filter(PublicationType == "journalArticle", is.na(PublicationTitleDb)) %>% dplyr::select(PublicationTitle) %>% unique())` journals were not included in the Scimago database (likely because they do not have an ISSN identifier or were discontinued before 1996; see Table \@ref(tab:MissingJournalTab) for the missing Journals).    

```{r MissingJournalTab, results='asis', warning=F, message=F}
# List Journals not in Scimago database
psychData %>% 
  filter(PublicationType == "journalArticle", 
         is.na(PublicationTitleDb)) %>%
  dplyr::select(`Journal Name` = PublicationTitle) %>%
  unique() %>%
  kbl(., caption = "Journal Information Missing in Scimago Journal Ranking",
      format = "html", row.names = FALSE) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

This meant that we ultimately had journal metrics for `r nrow(psychData %>% filter(!is.na(PublicationTitleDb)))` empirical articles. The frequencies of the journals, and a selection of their impact metrics is shown in Table \@ref(tab:JournalFreqTab).    

```{r JournalFreqTab}
# {r JournalFreqTab, results='asis', warning=F, message=F}
# table with basic frequencies and journal descriptives
psychDataJournal %>%
  dplyr::select(PublicationTitleDb, SJR, Hindex, TotalDocs3years, CitesDoc2years, RefDoc, PublisherCountry) %>%
  group_by(PublicationTitleDb, SJR, Hindex, TotalDocs3years, CitesDoc2years, RefDoc, PublisherCountry) %>%
  summarise(Frequency = n()) %>%
  arrange(desc(Frequency)) %>%
  dplyr::select(Journal = PublicationTitleDb, N = Frequency, SJR, CitesDoc2years, Hindex, RefDoc, TotalDocs3years, PublisherCountry) %>%
  kbl(., caption = "Journal Frequency",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
  kableExtra::footnote(general = "SJR = Scimago Journal Rank Indicator; 
           CitesDoc2years = Average number of citations per document in a 2-year period; 
           Hindex = H Index (h number of articles that have been cited at least h times);
           RefDoc = Average number of references per document in 2019;
           TotalDocs3years = Number of articles published in 2017, 2018, 2019") %>%
   scroll_box(height = "500px")
```

<br>
To gain a broad understanding of the interest development we plotted the yearly average H Index (Figure \@ref(fig:JournalHTime)) and yearly average of the journals' citations per paper over time (Figure \@ref(fig:JournalHCite)). It should be noted that the citation per paper metric is based in the years of 2018/19 and might not represent the citation impact of the journals at the time of the publications. Yet the metric should offer a first insight into average level of journal outlet selected by the authors. Also note that confidence bands are only calculated for a yearly `N > 1` and only displayed with two or more consecutive years of data.  

```{r JournalHTime, fig.cap="Line graph of average journal H Index per year."}
# summarize journal statistics by year
library(ggrepel)
hTime <- psychDataJournal %>%
  dplyr::select(year, SJR, Hindex, TotalDocs3years, CitesDoc2years, RefDoc) %>%
  mutate(across(SJR:RefDoc, ~ as.numeric(gsub("," ,".", .x)))) %>%
  group_by(year) %>%
  summarise_at(vars(c("SJR", "Hindex", "TotalDocs3years", "CitesDoc2years", "RefDoc")), 
               list(mean = ~ mean(., na.rm = T),
                    sd = ~ sd(., na.rm = T), 
                    n = ~ sum(!is.na(.)), 
                    se = ~ sd(.,na.rm=TRUE)/sqrt(sum(!is.na(.))),
                    lwr = ~ mean(., na.rm = T) - 1.96*sd(.,na.rm=TRUE)/sqrt(sum(!is.na(.))),
                    upr = ~ mean(., na.rm = T) + 1.96*sd(.,na.rm=TRUE)/sqrt(sum(!is.na(.)))
  )) %>%
  mutate(label = paste0('N = ', SJR_n))

# plot H factor per year
ggplot(hTime, aes(x=year, y = Hindex_mean)) + 
  geom_line() +
  geom_ribbon(aes(ymin=Hindex_lwr,ymax=Hindex_upr),alpha=0.3) +
  geom_point(size = .9) +
  #geom_text(aes(label=label),hjust=0.5, vjust=0) +
  geom_label_repel(data = hTime %>% filter(SJR_n <3),
                  aes(label = label),
                  box.padding   = .35, 
                  point.padding = .5,
                  force         = 10,
                  nudge_y       = -100,
                  segment.color = 'grey50') +
  #geom_histogram(bins = length(unique(dt.Empirical.included$year)), fill = "grey14")+
  ylab("Average H Index")+
  ylim(0, max(hTime$Hindex_upr[hTime$SJR_n>2], na.rm = T)+20) +
  xlab("Year") +
  ggtitle("Average H Index by publication year")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

```{r JournalHCite, fig.cap="Line graph of the journals' average citation numbers by publication year."}
# plot average journal citation per year
ggplot(hTime, aes(x=year, y = CitesDoc2years_mean)) + 
  geom_line() +
  geom_ribbon(aes(ymin=CitesDoc2years_lwr,ymax=CitesDoc2years_upr),alpha=0.3) +
  geom_point(size = .9) +
  #geom_text(aes(label=label),hjust=0.5, vjust=0) +
  # geom_label_repel(data = hTime %>% filter(SJR_n <3),
  #                 aes(label = label),
  #                 box.padding   = .35, 
  #                 point.padding = .5,
  #                 force         = 10,
  #                 nudge_y       = -100,
  #                 segment.color = 'grey50') +
  #geom_histogram(bins = length(unique(dt.Empirical.included$year)), fill = "grey14")+
  ylab("Average citations/article (2 years)")+
  ylim(0,10) +
  xlab("Year") +
  ggtitle("Average journal citations/article over time")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```


### Journal Keywords  
In the Scimago database each journal is assigned a set of keywords capturing their publication topics. Assessing these might offer a better understanding of the types of Journal and readership that are targeted by the authors. We assess the frequency of keyword lists (i.e., combinations of keywords, see Table \@ref(tab:CategoryFreqCombTab)) as well as the frequency of all available individual keywords (see Table \@ref(tab:CategoryFreqTab)).  

```{r CategoryFreqCombTab, results='asis', warning=F}
# table of unprocessed journal keywords
data.frame(table(gsub(" \\(Q[0-9]\\)", "", psychDataJournal$Categories))) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Frequency of Raw Journal Keywords",
      format = "html",
      col.names = c("Keyword",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
  scroll_box(height = "500px")
```

```{r CategoryFreqTab, results='asis', warning=F}
# table of individual journal keywords
data.frame(table(unlist(str_split(gsub(" \\(Q[0-9]\\)", "", psychDataJournal$Categories), "; ")))) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Frequency of Individual Journal Keywords",
      format = "html",
      col.names = c("Keyword",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
  add_footnote("_Note_ that journals can have multiple associated keywords.", notation = "none") %>%
  scroll_box(height = "500px")
```

### Coding   
Beyond the keywords, the Scimago database classifies each journal according to the _field(s)_ that the journal aims to address. These field codes aim to capture a higher level of academic classification (than the keywords). Importantly, (1) each journal can be be classified to address multiple fields and (2) the field include codes of fields (e.g., 'Social Sciences') as well as sub-fields (e.g., 'Social Psychology'). This leads to the case that there can be quite a lot of [overlap between fields](https://www.scimagojr.com/shapeofscience/) and journals cannot easily or readily be assessed in mutually exclusive subgroups. Yet, one of the aims of this review is to assess differences between fields and disciplines. We aim to address this issue in the following section. However, we first need to gain a better understanding of the fields that are addressed by the journals. We list the frequencies of all unique combinations (see Table \@ref(tab:FieldCombFreqTab), as well as the overall frequencies of all available field codes (see Table \@ref(tab:FieldFreqTab)).  

```{r FieldCombFreqTab, results='asis', warning=F}
# table of unprocessed journal field codes
data.frame(table(psychDataJournal$fields)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Frequency of Raw Journal Fields",
      format = "html",
      col.names = c("Field Code Combination",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r FieldFreqTab, results='asis', warning=F}
# table of individual journal fields
data.frame(table(unlist(str_split(psychDataJournal$fields, "; ")))) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Frequency of Individual Journal Fields",
      format = "html",
      col.names = c("Field Code",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
  add_footnote("_Note_ that journals can target multitple fields.", notation = "none")
```

To summarize the articles further we then classified the field combinations into superordinate discipline codes. These discipline codes are based in part on U.S. Department of Education's National Center for Education Statistics [Classification of Instructional Programs (CIP)](https://nces.ed.gov/ipeds/cipcode/default.aspx?y=55), the U.K. Higher Education Statistics Agency [Joint Academic Coding System (JACS 3.0)](https://www.hesa.ac.uk/support/documentation/jacs/jacs3-principal), the Australian Bureau of Statistics' [Australian and New Zealand Standard Research Classification (ANZSRC 2020)](https://www.abs.gov.au/ausstats/abs@.nsf/0/5D99AEA1DD8AA8E0CA2574180005421C?Opendocument), as well as the [Fields of Knowledge Map](http://www.thingsmadethinkable.com/item/fields_of_knowledge.php) from the 'Things Made Thinkable' initiative.  

In a first step we used the highest categories available (Social Sciences, Arts and Humanities, Professions and Applied Sciences, Natural Sciences, Formal Sciences, and Multidisciplinary) to summarize the fields. The Scimago database included some superordinate discipline codes (i.e., Social Sciences, Arts and Humanities) so we used these if a single discipline code was chosen by a journal. We then re-coded the fields that did not have a super-ordinate discipline code or had multiple (see Table \@ref(tab:DisciplinesRecode01), for the disciplines associated to each field combination).  

```{r DisciplinesRecode01, results='asis', warning=F, message=F}
# Create re-code categories
# Fields that fall within the Social Sciences 
socialSciences <- c("Business, Management and Accounting; Environmental Science; Social Sciences",
                    "Business, Management and Accounting; Psychology; Social Sciences", 
                    "Business, Management and Accounting; Social Sciences",
                    "Health Professions; Social Sciences",
                    "Medicine; Nursing; Psychology; Social Sciences",
                    "Medicine; Nursing; Social Sciences",
                    "Medicine; Psychology; Social Sciences",
                    "Medicine; Social Sciences",
                    "Neuroscience; Psychology; Social Sciences",
                    "Nursing; Social Sciences",
                    "Psychology",
                    "Psychology; Social Sciences",
                    "Social Sciences")

# Fields that fall within the Arts and Humanities
artsHumanities <- c("Arts and Humanities; Medicine; Psychology",
                    "Arts and Humanities; Psychology")

# Fields that fall within the Natural Sciences
naturalSciences <- c()

# Fields that fall within the Formal Sciences
formalSciences <- c()

# Fields that fall within the Professional and Applied Sciences
professionsAppliedSciences <- c("Business, Management and Accounting",
                                "Medicine", 
                                "Medicine; Neuroscience",
                                "Medicine; Nursing",
                                "Nursing")

# Field combinations that fall within multiple broader categories
crossDisciplinary <- c("Arts and Humanities; Medicine; Social Sciences",
                       "Arts and Humanities; Psychology; Social Sciences",
                       "Arts and Humanities; Social Sciences",
                       "Biochemistry, Genetics and Molecular Biology; Medicine; Psychology", 
                       "Business, Management and Accounting; Decision Sciences; Psychology",
                       "Medicine; Psychology",
                       "Multidisciplinary")

# other
other <- c()

# create database with discipline and field codes
disciplines01 <- data.frame(fields = c(socialSciences, 
                                       artsHumanities, 
                                       naturalSciences, 
                                       formalSciences, 
                                       professionsAppliedSciences, 
                                       crossDisciplinary, 
                                      other),
                         discipline01 = c(rep("Social Sciences", length(socialSciences)),
                                          rep("Arts and Humanities", length(artsHumanities)),
                                          rep("Natural Sciences", length(naturalSciences)),
                                          rep("Formal Sciences", length(formalSciences)),
                                          rep("Professions and Applied Sciences", length(professionsAppliedSciences)),
                                          rep("Multidisciplinary / Crossdisciplinary", length(crossDisciplinary)),
                                          rep("Other", length(other)))
                         )

# add discipline codes to empirical studies
empiricalDataDisciplines <- right_join(psychDataJournal, disciplines01)

# make table of Field to Discipline relations
disciplines01 %>%
  kbl(., caption = "Coding Schema for Disciplines (Version #1)",
      format = "html",
      col.names = c("Fields",
                    "Discipline #1")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")
```

Categorization in this -- highest order -- manner led to the following subgroup frequencies (see Table \@ref(tab:Disciplines01FreqTab)):  

```{r Disciplines01FreqTab, warning=F}
# Frequencies of discipline codes
data.frame(table(empiricalDataDisciplines$discipline01)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Discipline Frequency (Version #1)",
      format = "html",
      col.names = c("Discipline #1",
                    "Frequency")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")
```

This higher-order discipline-coding had two major concerns. Firstly, the category of 'Social Sciences' was too large and heterogeneous and secondly, the medical and health related fields were not sufficiently distinguished from the other categories (i.e., either as part of 'Social Sciences' or 'Applied Sciences'). We, therefore, created a second discipline coding breaking the 'Social Sciences' and 'Applied Sciences' categories into major fields (psychology; business;  medicine, nursing, & health). We retained the possibility of miscellaneous social sciences, arts and humanities, as well as multidisciplinary field codes (see Table \@ref(tab:DisciplinesRecode02), for the discipline codes associated with each fields code).    

```{r DisciplinesRecode02, results='asis', warning=F, message=F}
# Create re-code categories
# Fields that fall within the Psychological Sciences 
psychology <- c("Arts and Humanities; Psychology",
                "Arts and Humanities; Psychology; Social Sciences",
                "Psychology",
                "Psychology; Social Sciences",
                "Neuroscience; Psychology; Social Sciences")

# Fields that fall within the Business discipline 
business <- c("Business, Management and Accounting",
              "Business, Management and Accounting; Environmental Science; Social Sciences",
              "Business, Management and Accounting; Social Sciences")

# Fields that fall within the Medical Sciences 
medical <- c("Arts and Humanities; Medicine; Social Sciences",
             "Health Professions; Social Sciences",
             "Medicine", 
             "Medicine; Neuroscience",
             "Medicine; Nursing",
             "Medicine; Nursing; Social Sciences",
             "Medicine; Social Sciences",
             "Nursing",
             "Nursing; Social Sciences")

# Fields that fall within the Social Sciences 
social <- c("Social Sciences")

# Fields that fall within the Arts 
arts <- c()

# studies that fall within multiple disciplines
multi <- c("Arts and Humanities; Medicine; Psychology",
           "Arts and Humanities; Social Sciences",
           "Biochemistry, Genetics and Molecular Biology; Medicine; Psychology", 
           "Business, Management and Accounting; Decision Sciences; Psychology",
           "Business, Management and Accounting; Psychology; Social Sciences",
           "Medicine; Psychology",
           "Medicine; Psychology; Social Sciences",
           "Medicine; Nursing; Psychology; Social Sciences",
           "Multidisciplinary")

# create database with discipline and field codes
disciplines02 <- data.frame(fields = c(psychology, 
                                       medical, 
                                       business, 
                                       social, 
                                       arts, 
                                       multi),
                            discipline02 = c(rep("Psychology", length(psychology)),
                                             rep("Medicine, Nursing, & Health", length(medical)),
                                             rep("Business", length(business)),
                                             rep("Social Sciences (miscellaneous)", length(social)),
                                             rep("Arts and Humanities", length(arts)),
                                             rep("Multidisciplinary / Crossdisciplinary", length(multi)))
                         )


# add new discipline codes to empirical studies
empiricalDataDisciplines <- right_join(empiricalDataDisciplines, disciplines02)

# make table of new Field to Discipline relations
disciplines02 %>%
  kbl(., caption = "Coding Schema for Disciplines (Version #2)",
      format = "html",
      col.names = c("Fields",
                    "Discipline #2")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")
```

Re-categorization led to the following subgroup frequencies (see Table \@ref(tab:Disciplines02FreqTab)):  

```{r Disciplines02FreqTab, results='asis', warning=F}
# Frequencies of new discipline codes
data.frame(table(empiricalDataDisciplines$discipline02)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Discipline Frequency (Version #2)",
      format = "html",
      col.names = c("Discipline #2",
                    "Frequency")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")
```

Given the small number of 'Business' journals we reclassified these into the 'Social Sciences (miscellaneous)' category (see Table \@ref(tab:Disciplines02FreqTabAdj) and Figure \@ref(fig:Disciplines02AdjSankey)).  

```{r Disciplines02FreqTabAdj, results='asis', warning=F}
empiricalDataDisciplines$discipline02[empiricalDataDisciplines$discipline02 == "Business"] <- "Social Sciences (miscellaneous)"

data.frame(table(empiricalDataDisciplines$discipline02)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Discipline Frequency Ajusted",
      format = "html",
      col.names = c("Discipline #2 (adjusted)",
                    "Frequency")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")
```

```{r Disciplines02AdjSankey, warning=F, fig.cap="Sankey Graph fields to discipline re-coding."}
# tally links from number of combinations
links <- empiricalDataDisciplines %>%
  dplyr::select(source = fields, target = discipline02) %>%
  mutate(target = str_replace(target, "Psychology", "Psychology ")) %>%
  group_by(source, target) %>%
  summarise(value = n()) %>%
  arrange(desc(value))

# From these flows we need to create a node data frame: it lists every entities involved in the flow
nodes <- data.frame(
  name=c(as.character(links$source),
  as.character(links$target)) %>% unique()
)

# With networkD3, connection must be provided using id, not using real name like in the links dataframe.. So we need to reformat it.
links$IDsource <- match(links$source, nodes$name)-1
links$IDtarget <- match(links$target, nodes$name)-1

# Make the Network
sankeyNetwork(Links = links, Nodes = nodes,
              Source = "IDsource", Target = "IDtarget",
              Value = "value", NodeID = "name",
              sinksRight=F, height= 800)
```

```{r exportWrangledData}
# export cleaned datasets for methods and results section
save(dt.Input, 
     dt.Scales, dt.Scales.Included, 
     dt.Empirical, dt.Empirical.included, psychData, 
     dt.Theories, dt.Theories.Included, dt.TheorySearch, 
     dt.Domains, empiricalDataDisciplines, file = "data/wrangled.RData")

save(dt.Scales, dt.Scales.Included, dt.Theories, dt.Theories.Included, file = "data/AcculturationScales.RData")

# export reduced dataset for OSF repository
theorySearchCleand <- dt.TheorySearch %>%
  dplyr::select(-c(AuthorFull,TitleAlphaNum, 
                   TitleScreening, TitleNote, AbstractScreening, AbstractNote, 
                   SearchDuplicateDOI, SearchDuplicateTitle, DuplicateAny, 
                   ID, IDDuplicate,
                   Downloaded, DownloadReason, Extracted, ExtractedReason, TheoryName, Comment)) 
write.csv(theorySearchCleand,'data/OSF/theoretical01_SearchCleaned.csv')

theorySearchScreened <- dt.TheorySearch %>%
  dplyr::select(-c(AuthorFull,TitleAlphaNum))
write.csv(theorySearchScreened,'data/OSF/theoretical02_SearchScreened.csv')

write.csv(dt.Theories.Included, 'data/OSF/theoretical03_DatabaseCoded.csv')

write.csv(dt.Scales, 'data/OSF/methodological01_SearchCleaned.csv')
write.csv(dt.Scales.Included, 'data/OSF/methodological03_DatabaseCoded.csv')


empiricalSearchCleand <- dt.Empirical %>%
  dplyr::select(-c(TitleScreening,	TitleNote, AbstractScreening, AbstractNote, SearchDuplicate,
                   ID,	IDDuplicate,	CitationKey,	Downloaded,	empirical,	Method,	term,	MeasureDefinition,
                   Affect,	Behavior,	Cognition,	Desire,	Affect2,	Behavior2,	Cognition2,	Desire2, 
                   AffectFinal, BehaviorFinal, CognitionFinal, DesireFinal,
                   MissingABCD,	NoteMissing,	TypeComplexity,	MeasurementLevels,	domainScale,	domainPaper,
                   MainAnalysis,	VariableType,	Sample,	MigrationTime,	IncludesMajority,
                   `Host Country 1`,	`Host Country 2`,	`Host Country 3`,	`Host Country 4`,	HostCountry,
                   `Origin Country 1`,	`Origin Country 2`,	`Origin Country 3`,	`Origin Country 4`,	`Origin Country 5`,	`Origin Country 6`,	OriginCountry,	Comment))
write.csv(empiricalSearchCleand,'data/OSF/empirical01_SearchCleaned.csv')

empiricalSearchScreened <- dt.Empirical %>%
  dplyr::select(-c(empirical,	Method,	term,	MeasureDefinition,
                   Affect,	Behavior,	Cognition,	Desire,	Affect2,	Behavior2,	Cognition2,	Desire2,
                   AffectFinal, BehaviorFinal, CognitionFinal, DesireFinal,
                   TypeComplexity,	MeasurementLevels,	domainScale,	domainPaper,
                   MainAnalysis,	VariableType,	Sample,	MigrationTime,	IncludesMajority,
                   `Host Country 1`,	`Host Country 2`,	`Host Country 3`,	`Host Country 4`,	HostCountry,
                   `Origin Country 1`,	`Origin Country 2`,	`Origin Country 3`,	`Origin Country 4`,	`Origin Country 5`,	`Origin Country 6`,	OriginCountry))
write.csv(empiricalSearchScreened,'data/OSF/empirical02_SearchScreened.csv')

write.csv(dt.Empirical.included, 'data/OSF/empirical03_DatabaseCoded.csv')

# export numbers for Coding Protocol Fact Sheets
## Theoretical:
nTheo <- nrow(dt.Theories.Included)
percTheoMissing <- ((nrow(dt.Theories) - nrow(dt.Theories.Included)) / nrow(dt.Theories) * 100) %>%
  round(.,2)
nTheories <- dt.Theories.Included %>%
  filter(FrameworkTheoryModel == "Theory") %>%
  nrow
percTheories <- ((nTheories/nTheo) * 100) %>%
  round(.,1)
nFrameworks <- dt.Theories.Included %>%
  filter(FrameworkTheoryModel == "Framework") %>%
  nrow
percFrameworks <- ((nFrameworks/nTheo) * 100) %>%
  round(.,1)
nModels <- dt.Theories.Included %>%
  filter(FrameworkTheoryModel == "Model") %>%
  nrow
percModels <- ((nModels/nTheo) * 100) %>%
  round(.,1)
nConceptualizations <- dt.Theories.Included %>%
  filter(FrameworkTheoryModel == "Conceptualization") %>%
  nrow
percConceptualizations <- ((nConceptualizations/nTheo) * 100) %>%
  round(.,1)

cat("\\def \\nTheo {",nTheo,"}
\\def \\percTheoMissing {", percTheoMissing, "}
\\def \\nTheories {", nTheories, "}
\\def \\percTheories {", percTheories, "}
\\def \\nFrameworks {", nFrameworks, "}
\\def \\percFrameworks {", percFrameworks, "}
\\def \\nModels {", nModels, "}
\\def \\percModels {", percModels, "}
\\def \\nConceptualizations {", percTheoMissing, "}
\\def \\percTheoMissing {", percConceptualizations, "}",
    sep = "", 
    file = "Supplemental Material A - Coding Protocol/margins/theoNums.tex")
    
## Methodological:
nScales <- nrow(dt.Scales.Included)
nAllScales <- nrow(dt.Scales)
nMethInaccess <- scalesExcl %>%
  filter(grepl("accessible", `Exclusion Reason`)) %>%
  select(`Full Text`) %>%
  sum
percMethInaccess <- (nMethInaccess / (nMethInaccess + nScales) * 100) %>%
  round(.,2)

cat("\\def \\nScales {",nScales,"}
\\def \\nAllScales {", nAllScales, "}
\\def \\nMethInaccess {", nMethInaccess, "}
\\def \\percMethInaccess {", percMethInaccess, "}",
    sep = "", 
    file = "Supplemental Material A - Coding Protocol/margins/methNums.tex")

## Empirical:
nEmp <- nrow(dt.Empirical.included)
nAllEmp <- nrow(dt.Empirical.unique)
nEmpInaccess <- empiricalExclFull %>% 
  filter(grepl("accessible", Exclusion)) %>%
  select(Freq) %>%
  sum
percEmpInaccess <- (nEmpInaccess / (nEmpInaccess + nEmp) * 100) %>%
  round(., 0)
nEmpItemInaccess <- empiricalExclFull %>% 
  filter(grepl("items not accessible", Exclusion)) %>%
  select(Freq) %>%
  as.numeric
percEmpItemInaccess <- (nEmpItemInaccess / (nEmpInaccess + nEmp) * 100) %>%
  round(., 0)
nEmpThesisInaccess <- empiricalExclFull %>% 
  filter(grepl("thesis not accessible", Exclusion)) %>%
  select(Freq) %>%
  as.numeric
percEmpThesisInaccess <- (nEmpThesisInaccess / (nEmpInaccess + nEmp) * 100) %>%
  round(., 0)
nJournal <- dt.Empirical.included %>%
  filter(PublicationType == "journalArticle") %>%
  nrow
percJournal <- ((nJournal/nEmp) * 100) %>%
  round(.,1)
nThesis <- dt.Empirical.included %>%
  filter(PublicationType == "thesis") %>%
  nrow
percThesis <- ((nThesis/nEmp) * 100) %>%
  round(.,1)
nChapter <- dt.Empirical.included %>%
  filter(PublicationType == "bookSection") %>%
  nrow
percChapter <- ((nChapter/nEmp) * 100) %>%
  round(.,1)

cat("\\def \\nEmp {",nEmp,"}
\\def \\nAllEmp {",nAllEmp,"}
\\def \\nEmpInaccess {", nEmpInaccess, "}
\\def \\percEmpInaccess {", percEmpInaccess, "}
\\def \\nEmpItemInaccess {", nEmpItemInaccess, "}
\\def \\percEmpItemInaccess {", percEmpItemInaccess, "}
\\def \\nEmpThesisInaccess {", nEmpThesisInaccess, "}
\\def \\percEmpThesisInaccess {", percEmpThesisInaccess, "}
\\def \\nJournal {", nJournal, "}
\\def \\percJournal {", percJournal, "}
\\def \\nThesis {", nThesis, "}
\\def \\percThesis {", percThesis, "}
\\def \\nChapter {", nChapter, "}
\\def \\percChapter {", percChapter, "}",
    sep = "", 
    file = "Supplemental Material A - Coding Protocol/margins/empNums.tex")

cat("\\def \\nTheo {",nTheo,"}
\\def \\nScales {",nScales,"}
\\def \\nEmp {", nEmp, "}",
    sep = "", 
    file = "Supplemental Material A - Coding Protocol/margins/nNums.tex")
```


This coding resulted in `r length(unique(empiricalDataDisciplines$discipline02))` relatively well-balanced categories with non of the fields having too few observations. In the following sections we use these discipline codes to assess some general differences in assessing and addressing acculturation.    


### Descriptives   
terms, collection methods, measures, year of publication, focus of paper, variable type  

#### Acculturation Terms    

We first assess which terms the different disciplines use most frequently to describe the cultural adaptation process. We list the main terms the authors used in their paper to refer to cultural adaptation in Table \@ref(tab:PsychDisciplineTerm).  

```{r PsychDisciplineTerm, message=F, warning=F}
# Frequency Table of acculturation terms by field
empiricalDataDisciplines %>%
  dplyr::select(discipline02,term) %>%
  mutate(term = tolower(term)) %>%
  group_by(discipline02, Term = term) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  ungroup %>%
  mutate_if(is.numeric, funs(replace_na(as.character(.), ""))) %>%
  dplyr::select(Term, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Terms used per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

#### Data Collection Methods    

We then compare the data collection methods most frequently used by the authors in the different disciplines (see Table \@ref(tab:PsychDisciplineCollectionType) and Figure \@ref(fig:PsychDisciplineBarMethod)).   

```{r PsychDisciplineCollectionType, message=F, warning=F}
# Frequency Table of data collection type by field
empiricalDataDisciplines %>%
  dplyr::select(discipline02, Method) %>%
  mutate(Method = tolower(Method)) %>%
  group_by(discipline02, Method) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  mutate_if(is.numeric, funs(replace_na(as.character(.), ""))) %>%
  dplyr::select(Method, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Method used per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```
  
```{r PsychDisciplineBarMethod, warning=F, messages=F,fig.cap="Stacked bar chart of data collection method by discipline."}
# compare collection methods between disciplines
ggstatsplot::ggbarstats(
  data = empiricalDataDisciplines,
  x = Method,
  y = discipline02,
  #sampling.plan = "jointMulti",
  title = "Data Collection Method by Discipline",
  xlab = "Discipline",
  package = "wesanderson",
  palette = "Darjeeling2",
  ggtheme = ggthemes::theme_tufte(base_size = 12),
  ggplot.component = list(scale_x_discrete(guide = guide_axis(n.dodge = 2))),
  ggstatsplot.layer = FALSE,
  label.args = list(check_overlap = TRUE, alpha = 1, fill = "white"),
  messages = FALSE
)
```

#### Measures    
We also assessed the use of different validated and novel measures used by authors in the various disciplines (see Table \@ref(tab:PsychDisciplineMeasure)). Note, again, that a majority of the measurements are not previously standardized and are not shared across articles and disciplines.  

```{r PsychDisciplineMeasure, message=F, warning=F}
# Frequency Table of acculturation measures used by field
empiricalDataDisciplines %>%
  dplyr::select(discipline02, MeasureDefinition) %>%
  mutate(MeasureDefinition = tolower(MeasureDefinition)) %>%
  group_by(discipline02, Measure = MeasureDefinition) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  mutate_if(is.numeric, funs(replace_na(as.character(.), ""))) %>%
  dplyr::select(Measure, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Measure used per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "110%", height = "500px")
```

#### Study Focus
For the empirical works we also coded the main focus of the papers in each of the disciplines. The wordclouds of the topics within each discipline illustrate that the different disciplines also focus on different topics related to cultural adaptation (see Figure \@ref(fig:PsychDisciplineTopicFrequencies)).  

```{r PsychDisciplineTopicFrequencies, warning=F, fig.cap="Wordcloud of the article foci in the empirical results.", fig.height=12}
# unique domains already calculated

# dataframe to compile domain frequency for Review Scales
PsychDomainFreq <- data.frame(UniqueDomains)

# count domain frequency in dt.Scales.Included
for (i in 1:nrow(UniqueDomains)) {
  PsychDomainFreq$Psychology[i] <- length(grep(UniqueDomains$Domain[i], 
                                               empiricalDataDisciplines$domainPaper[empiricalDataDisciplines$discipline02=="Psychology"], 
                                               value = T))
  PsychDomainFreq$`Medicine, Nursing, & Health`[i] <- length(grep(UniqueDomains$Domain[i], 
                                               empiricalDataDisciplines$domainPaper[empiricalDataDisciplines$discipline02=="Medicine, Nursing, & Health"], 
                                               value = T))
  PsychDomainFreq$`Social Sciences (miscellaneous)`[i] <- length(grep(UniqueDomains$Domain[i], 
                                               empiricalDataDisciplines$domainPaper[empiricalDataDisciplines$discipline02=="Social Sciences (miscellaneous)"], 
                                               value = T))
  PsychDomainFreq$`Multidisciplinary / Crossdisciplinary`[i] <- length(grep(UniqueDomains$Domain[i], 
                                               empiricalDataDisciplines$domainPaper[empiricalDataDisciplines$discipline02=="Multidisciplinary / Crossdisciplinary"], 
                                               value = T))
}

library(ggwordcloud)
set.seed(7) # for reproducibility 
PsychDomainFreq %>%
  dplyr::select(Domain,
                Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  gather(discipline02, Frequency, -Domain) %>%
  filter(Frequency>0) %>%
ggplot( ., aes(label = Domain, size = Frequency, color = Frequency)) +
  geom_text_wordcloud_area(shape = 'circle', rm_outside = TRUE, eccentricity = 1) +
  scale_size(range = c(2,10)) +
  theme_minimal() +
  facet_wrap(~discipline02, ncol = 1)
```

Additionally, we coded where in the model the acculturation measure was placed most frequently in each of the disciplines (see Table \@ref(tab:empiricalDisciplineVarType)).  

```{r empiricalDisciplineVarType, message=F}

empiricalDataDisciplines %>%
  dplyr::select(discipline02, VariableType) %>%
  group_by(discipline02, `Variable Type` = VariableType) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  filter(!is.na(`Variable Type`)) %>%
  arrange(desc(Psychology)) %>%
  mutate_if(is.numeric, funs(replace_na(as.character(.), ""))) %>%
  dplyr::select(`Variable Type`, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Variable Type of Acculturation Measure per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

#### Majority Inclusion
Only a minority of studies included data on the acculturation process from the majority and migrant perspective jointly. And there is a stark contrast between the disciplines in how many of the total papers included the majority group (see Table \@ref(tab:empiricalDisciplineMayority)).  

```{r empiricalDisciplineMayority, message=F}
empiricalDataDisciplines %>%
  dplyr::select(discipline02, IncludesMajority) %>%
  mutate(`Includes Majority` = recode_factor(.$IncludesMajority, `0` = "no", `1` = "yes")) %>%
  group_by(discipline02, `Includes Majority`) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  filter(!is.na(`Includes Majority`)) %>%
  mutate_if(is.numeric, funs(replace_na(as.character(.), ""))) %>%
  dplyr::select(`Includes Majority`, 
                Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Includes Majority per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

#### Year of Publication  
As with the overall developments we also assessed the publication developments within the individual disciplines. Article ublication developments over time should indicate empirical interest in the topic of acculturation in the disciplines over time. We offer a global, developmental overview of the fields in Figure \@ref(fig:empiricalDisciplineHistTime), as well as a visualization that further distinguishes between data collection types within the fields (see Figure \@ref(fig:empiricalDisciplineHistTimeMethod)).  

```{r empiricalDisciplineHistTime, fig.cap="Histogram of the publications per year for all fields."}
# create super short labels for grid labels
discipline_labs_shrt <- c(
  'Psychology'="Psych.",
  'Medicine, Nursing, & Health'="Med.",
  'Social Sciences (miscellaneous)'="SocSci.",
  'Multidisciplinary / Crossdisciplinary'="Multi."
)

# create short labels for grid labels
discipline_labs_lng <- c(
  'Psychology'="Psychology",
  'Medicine, Nursing, & Health'="Medicine",
  'Social Sciences (miscellaneous)'="Social Sci.",
  'Multidisciplinary / Crossdisciplinary'="Multidiscipl."
)

# plot number of publications per year for each field
ggplot(empiricalDataDisciplines, aes(x=year)) + 
  geom_histogram(binwidth = .9, fill = "grey14")+
  facet_grid(rows = vars(discipline02), labeller = as_labeller(discipline_labs_shrt)) +
  ylab("Number of Results") +
  xlab("Year") +
  ggtitle("Publication Year of Results")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

```{r empiricalDisciplineHistTimeMethod, warning=F, fig.cap="Line plot of the yearly publication frequency for by data collection method."}
# plot type of data collected per year for each field
ggplot(empiricalDataDisciplines, aes(x=year, color = Method)) + 
  #geom_density(aes(y = ..count..)) +
  geom_line(stat='count') +
  geom_point(stat='count', size = .9) +
  facet_grid(rows = vars(discipline02), labeller = as_labeller(discipline_labs_shrt)) +
  ylab("Number of Results")+
  xlab("Year") +
  ggtitle("Data Collection Method by Discipline over Time")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="bottom", legend.title = element_blank())
```

### Experience   
Again, a major focus of our coding was the role of affect, behavior, cognition, and desires in the each of the disciplines. Figure \@ref(fig:PsychDisciplineABCDFreq) shows how often each of the four dimensions was coded in each of the disciplines. _Note_ that in order better compare the disciplines we output percentages in most of the figures of this section.    

```{r PsychDisciplineABCDFreq, message=F, warning=F, fig.cap="Bar graph of the counts for each of the dimensions across all included empirical works."}
# Plot aspect frequencies by field
empiricalDataDisciplines %>%
  dplyr::select(discipline02, Affect=AffectFinal, Behavior=BehaviorFinal, Cognition=CognitionFinal, Desire=DesireFinal) %>%
  gather(ABCD, Frequency, -discipline02) %>%
  group_by(discipline02, ABCD) %>%
  summarise_each(funs(sum(., na.rm = TRUE))) %>%
  ungroup() %>%
  group_by(discipline02) %>%
  mutate(Percentage = Frequency/sum(Frequency)*100) %>%
  ungroup() %>%
  ggplot(data = ., aes(x=reorder(ABCD, Percentage), y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    aes(label = round(Percentage,0), y = Percentage - 5),
    position = position_dodge(0.9),
    vjust = 0,
    color = "white") +
  facet_grid(cols = vars(discipline02), labeller = as_labeller(discipline_labs_lng)) +
  xlab("Dimension") +
  ylab("Percentage [in %]") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

Again, we also plot how often each of the dimensions were measured together. A bar graph of the compound frequencies in each discipline is shown Figure \@ref(fig:PsychDisciplineABCDCombFreq). Interestingly, there are certain dimensions and dimension combinations that are missing in some of the disciplines. There were, for example, only two articles in the psychological discipline that only measured behavioral acculturation a dimension that was important in all other disciplines.    

```{r PsychDisciplineABCDCombFreq, message=F, warning=F, fig.cap="Bar graph of the counts for each of the dimension combinations."}
# plot frequencies of aspect combinations by field
empiricalDataDisciplines %>%
  dplyr::select(discipline02, Affect=AffectFinal, Behavior=BehaviorFinal, Cognition=CognitionFinal, Desire=DesireFinal) %>%
  group_by(discipline02, Affect, Behavior, Cognition, Desire) %>%
  summarise(Frequency = n()) %>%
  ungroup() %>%
  group_by(discipline02) %>%
  mutate(Percentage = Frequency/sum(Frequency)*100) %>%
  ungroup() %>%
  mutate_at(.vars = c("Affect", "Behavior", "Cognition", "Desire"), funs(deparse(substitute(.))[.])) %>%
  unite("Dimension Combination", c(Affect, Behavior, Cognition, Desire), sep = ", ", na.rm = T) %>%
  ggplot(., aes(x=reorder(`Dimension Combination`, Percentage), y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    aes(label = round(Percentage,0)),
    position=position_stack(vjust=0.5),
    color = "white",
    size = 3,
    vjust = 0.5) +
  facet_wrap(vars(discipline02), nrow = 2, labeller = as_labeller(discipline_labs_lng)) +
  ggtitle("Compound Dimension Percentages") +
  ylab("Percentage [in %]") +
  xlab("Dimension Combination") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

### Context    

#### Culture
Similar to our overall overview we also assessed whether different disciplines relied on different migrant regions or host countries. Again, we coded both the migrants' country of origin as well as the country of the receiving society, in which the study was conducted for each discipline (see Table \@ref(tab:empiricalDisciplineCountryTab)).  

```{r empiricalDisciplineCountryPrep, message=F}
# Frequencies of host country focus
empiricalFieldHostFreq <- empiricalDataDisciplines %>%
  dplyr::select(HostCountry, discipline02) %>%
  mutate(country = strsplit(as.character(HostCountry), ", ")) %>% 
  unnest(country) %>%
  group_by(discipline02, country) %>%
  summarise(Host = n()) %>%
  arrange(-Host)
  
# Frequencies of origin country focus
empiricalFieldOriginFreq <- empiricalDataDisciplines %>%
  dplyr::select(OriginCountry, discipline02) %>%
  mutate(country = strsplit(as.character(OriginCountry), ", ")) %>% 
  unnest(country) %>%
  group_by(discipline02, country) %>%
  summarise(Origin = n()) %>%
  arrange(-Origin)

# Frequencies of host country focus in wide format
empiricalFieldCountryFreqWide <- merge(empiricalFieldHostFreq, empiricalFieldOriginFreq, by = c("discipline02", "country"), all = TRUE) %>%
  mutate_if(is.numeric, funs(replace_na(., 0)))

# Frequencies of host country focus in long format
empiricalFieldCountryFreqLong <- empiricalFieldCountryFreqWide %>%
  melt(., id = c("discipline02", "country"), value.name = "Frequency")
```

```{r empiricalDisciplineCountryTab, message=F}
# Create table of host and origin countries by field
empiricalFieldCountryFreqWide %>%
  filter(!is.na(country)) %>%
  arrange(discipline02, desc(Host), desc(Origin)) %>%
  dplyr::select(-discipline02) %>%
  kbl(., caption = "Considered Cultures per discipline",
      format = "html",
      align = c("l", "c", "c")) %>%
  pack_rows(index = table(empiricalFieldCountryFreqWide %>% 
                            filter(!is.na(country)) %>%
                            dplyr::select(discipline02))) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "100%", height = "500px")
```

#### Individual  

To gain a deeper understanding of the study setups in the empirical studies we coded the type of sample recruited within each of the disciplines (see Figure \@ref(fig:empiricalDisciplineSampleFreq)).  

```{r empiricalDisciplineSampleFreq, message=F, fig.cap="Bar graph of the study samples used in the empirical studies. Note: general = any migrant from specified country (no targeting).", fig.height=20}
# tally different samples per field
empiricalDataDisciplines %>%
  dplyr::select(discipline02, Sample) %>%
  group_by(discipline02, Sample) %>%
  summarise(Frequency = n()) %>%
  drop_na() %>%
  ggplot(data = ., aes(x=reorder(Sample, Frequency), y=Frequency)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    aes(label = round(Frequency,0), y = Frequency + 6),
    position = position_dodge(0.9),
    hjust = 0.5) +
  facet_grid(cols = vars(discipline02), labeller = as_labeller(discipline_labs_lng)) +
  xlab("Sample") +
  ylab("Frequency") +
  ylim(0,50) +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

Again the category *general* refers to a sampling strategy in which any consenting adult would be able to participate in the study.  

#### Situation  
We again coded which life domains the authors referred to, either as part of subscale labels, factor labels, explicit commentary of the authors, or clear question wordings to gain an understanding of the situational focus the authors chose. However, we did not code the theoretical situational life domains because such an undertaking would be beyond the scope of this paper. 

#### Process  
We also assessed which time point in the migration process was targeted within each discipline. Table \@ref(tab:PsychDisciplineMigrationTimeFreq) showcases that an overwhelming majority of studies targets migrants only after they had left their country of origin.  

```{r PsychDisciplineMigrationTimeFreq, message=F}
empiricalDataDisciplines %>%
  dplyr::select(discipline02, MigrationTime) %>%
  group_by(discipline02, MigrationTime) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  filter(!is.na(MigrationTime)) %>%
  mutate_if(is.numeric, funs(replace_na(as.character(.), ""))) %>%
  dplyr::select(MigrationTime, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Migration time per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

Finally, we also coded what kind of analyses the authors conducted with the acculturation measurements in each of the fields (see Table \@ref(tab:empiricalDisciplineAnalysis)).  

```{r empiricalDisciplineAnalysis, message=F}
# table of analyses by field
empiricalDataDisciplines %>%
  dplyr::select(discipline02,MainAnalysis) %>%
  group_by(discipline02, Analysis = MainAnalysis) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  filter(!is.na(Analysis)) %>%
  arrange(desc(Psychology)) %>%
  mutate_if(is.numeric, funs(replace_na(as.character(.), ""))) %>%
  dplyr::select(Analysis, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Analyses used per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

# **Software Information**  
The full session information with all relevant system information and all loaded and installed packages is available in the collapsible section below.  

<details>
  <summary>System Info</summary>
  
  \renewcommand{\arraystretch}{0.8} <!-- decrease line spacing for the table -->
```{r Reproducibility-SessionInfo-R-environment, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", out.width='100%', results='asis'}
  library("devtools")
  # library("knitr")
  
  df_session_platform <- devtools::session_info()$platform %>% 
    unlist(.) %>% 
    as.data.frame(.) %>% 
    rownames_to_column(.)
  
  colnames(df_session_platform) <- c("Setting", "Value")
  
  kbl(
    df_session_platform, 
    booktabs = T, 
    align = "l",
    caption = "R environment session info for reproducibility of results" # complete caption for main document
  ) %>% 
    kable_classic(full_width = F, 
                  lightable_options = "hover", 
                  html_font = "Cambria") 
```
  \renewcommand{\arraystretch}{1} <!-- reset row height/line spacing -->
 </details>
 <br>
 <details>
  <summary>Package Info</summary>

\renewcommand{\arraystretch}{0.6} <!-- decrease line spacing for the table -->
```{r Reproducibility-SessionInfo-R-packages, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", out.width='100%', results='asis'}
df_session_packages <- devtools::session_info()$packages %>% 
  as.data.frame(.) %>% 
  filter(attached == TRUE) %>% 
  dplyr::select(loadedversion, date, source) %>% 
  rownames_to_column

colnames(df_session_packages) <- c("Package", "Loaded version", "Date", "Source")

kbl(
  df_session_packages, 
  booktabs = T, 
  align = "l",
  caption = "Package info for reproducibility of results" # complete caption for main document
) %>% 
  kable_classic(full_width = F, 
                  lightable_options = "hover", 
                  html_font = "Cambria") 
```
\renewcommand{\arraystretch}{1} <!-- reset row height/line spacing -->
</details>
<br>
<details>
  <summary>Full Session Info (including loaded but unattached packages --- for troubleshooting only)</summary>
    `r pander(sessionInfo(), compact = FALSE)`
</details>


--------------------------------------------------------------------

</br>  

# **References**  

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>