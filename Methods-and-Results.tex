\subsection{Methodological Literature}

Based on the systematic review and its coding, the first data set we
assess is a database of scale validations. We bring together the scales
suggested in previous reviews as well as validation studies we
identified in our own review. Throughout our literature review we found
five major works that reviewed the measurement of acculturation
\citep{Celenk2011, Maestas2000, Matsudaira2006, Wallace2010, Zane2004}.
After removal of duplicate scales, we added any scale validation that
was present in our own systematic review but not included in the
previous reviews. For each measure we extracted the full item list as
well as the item scoring prior to coding. A comprehensive and
interactive database of the scales, with reference- and publication
information, as well as our experience elements and -context coding is
available in our online supplementary information as well as on our open
science repository (\hl{OSF and/or github citation here}).

\subsubsection{Methods}

Taken together these five reviews collected a total of 96 scales. From
our own review we added 149 additional validation studies. After
removing duplicates this meant that we considered a total of 244 unique
scales for our coding. Of these scales we ultimately had to exclude 23,
because they were either not accessible or did not fit the the topic of
our review (see Table \ref{tab:ScalesExclusion}). The scales had an
average of \hl{X.XX} items and \hl{X.XX} sub-scales. Most items were
rated on a five-point (\hl{XX.XX}\%) or four-point likert-type scale
(\hl{XX.XX}\%), with only \hl{X} scales including categorical ratings.
About a quarter of scales (24.18\%) included majority group members in
their validation studies. The earliest included validation was from 1948
with a majority of scales being validated around the turn of the
21\textsuperscript{st} century and the most recent included validation
study was published in 2020.

\input{Tables/ScalesExclusion}

\subsubsection{Results}

For the scale validations, we assessed both the role of experience
elements in the measures as well as contextual differences.

\paragraph{Experience}

With our main aim of examining the experience structure within the
scales, we examined whether scales included a specific experience
elements but also examined the used elements in their complex
combinations. In terms of general inclusion of elements, most studies
included a measure of cognition (86.76\%) and behavior (75.34\%),
whereas only roughly half the studies included a measure of affect
(52.97\%) and only a fourth of the scales included a measure of motives
(24.2\%). However, only a minority of scales included only a single
dimension. There were only 14 scales that exclusively relied on
cognitions (6.39\%) and 19 scales that measured only behaviors (8.68\%).
Yet, inversely, there were also only 30 scales that measured all four
dimensions (13.7\%). Most studies measured two (41.55\%) or three
(28.31\%) dimensions. A majority of scales either measured behavioral
and cognitive elements (25.57\%) or behavioral, cognitive, and affective
elements (21.46\%; also see Figure \ref{fig:ElementsScales} and Table
\ref{tab:ScaleElementCooccurrences}). Looking at the number of elements
measured together we also see substantial differences in what kind of
scales include a certain element. Scales that included cognitions
measured an average of 2.56 elements, scales measuring behavior, on
average, measured a 2.58, while scales that included affect measures had
a complexity average of 2.97 and scales measuring motivation even
measured an average of 3.42 scales. Thus, most scales measure multiple
dimensions, yet they focus on easily accessible dimensions (i.e.,
behavior and cognition), less of what is considered `less accessible' or
`subjective' (i.e., affect and desires). This is further visualized by
the observation that there were only 3 scales that exclusively measured
emotional adaptation and not a single scale that exclusively focused on
motivational adaptation (while this was the case for both cognitions and
behaviors). And if emotional or motivational aspects were measured they
were on average measured in scales that were already more complex (i.e.,
included more experience elements).

\begin{figure}[h]
\centering
\caption{Scales: Bar graph of the experience element combinations.}
\includegraphics[width=\textwidth]{Figures/ABCDFreq-1}
\label{fig:ElementsScales}
\end{figure}

\input{Tables/ScaleElementCooccurrences}

\paragraph{Context}

To gain a general understanding of contextual factors within the
validated studies, we also assessed cross-study patterns of cultural,
individual, situational, and process-related focus points.

\subparagraph{Country}

To assess the cultural contexts for which scales were validated, we
assessed the migrants' countries of settlement as well as the countries
of origin. We found that most scales investigated a single host country
(\textit{N} = 193) and most investigated one country of origin
(\textit{N} = 133). There were only 29 scales that were validated for
more than one receiving country. Looking at the country patterns, we
found that an overwhelming number of scales were validated within a U.S.
American settlement context (\textit{N} = 124). But also the remaining
receiving societies were mostly `western' countries (e.g., Canada, The
Netherlands, The United Kingdom, Israel, Australia) with non-western
settlement contexts, such as Taiwan, Nepal, or Russia, not being
investigated across more than two study. For the migrant origin
societies there was slightly more variation. There were a few migrant
groups that were investigated specifically (e.g., Mexico: 25, China:13,
South Korea: 12), however most validation studies targeted broader
categories of migrants (any migrants: 50, Asian: 10, Hispanic: 9,
LatinX: ). This also made it difficult to identify patterns of cultural
combinations investigated (apart from Mexican and LatinX migrants in the
United States).

\subparagraph{Sample}

To assess the role different groups of individuals targeted in the scale
validations, we coded the types of samples recruited for the validation
studies. A majority of studies sampled any consenting adult from the
migrant group of interest (\textit{N} = 119). As seems common in
academic research, a larger portion of the validated scales relied on
young migrants or students (\textit{N} = 64). Interestingly, only small
minority of validated scales targeted more vulnerable groups, such as
clinical samples (\textit{N} = 3) or refugees (\textit{N} = 4) --
despite a considerable focus on these groups within the broader
literature. Given the small cell counts, we did not investigate
differences in the experience measures across the different samples.

\subparagraph{Domains}

To assess the situational focus within the validated scales, we assessed
the number of domains within each scale as well as more common domains
across the scales. A relatively large number of scales asked about the
current state of the migrant in general manner without mentioning any
context or life domain (\textit{N} = 30; e.g., ``In general, in what
language do you read and speak?''). The remaining scales referred to an
average of NA dimensions (\textit{SD} = NA, range: NA -- NA). A total of
198 unique domains was measured across the 219 scales. The domains of
`language` (\hl{XX}\%), 'food' (\hl{XX}\%), `interactions' (\hl{XX}\%),
`family' (\hl{XX}\%) and `values' (\hl{XX}\%) were focused on most often
(see Online Supplementary Materials \hl{X}, Figure \hl{X}). Thus, while
there was large variation between the scales in the number, and
diversity of domains, the most frequently mentioned domains were in line
with the life domains proposed in the literature
\citep[e.g.,][]{Arends-Toth2007}. Yet again, given the large variability
between studies, we did not investigate differences in experience
elements across the different situational domains.

\subparagraph{Migration time}

Except for a single scale that was validated for potential migrants, all
scales were validated using cross-sectional data after the migrant
arrived in the settlement society. This is in line with observations by
previous reviews of the field \citep[e.g.,][]{Brown2011}. There was,
thus, no possibility to assess the experience elements across different
process approaches.

\subsection{Empirical Literature}

After analysis of the scales validations, we assessed the broader
empirical works we collected within the systematic review. We first
looked at all available empirical publications (incl.~books, chapters,
and dissertations). We later also assessed differences between fields
the work was published in. However, because we considered the fields on
an audience level, we used only empirical journal articles -- for which
journal-level audience data is available.

\subsubsection{Methods}

The search produced a total of 1629 results to which we added \hl{XX}
articles through contacts with experts in the field. We subsequently
screened out results that did not fit into our review. After duplicate
removal (\(N_{excluded}\) = 300, \(N_{screened}\) = 1329), we excluded
383 results in the title screening as well as an additional 272 results
during the abstract screening. Of the remaining 674 results, 559 papers
presented empirical work on acculturation and were coded. The 7
non-empirical results were reviews, which were not coded because they
did not measure cultural adaptation. During the full text coding we
excluded an additional 33 results because they were either not relevant
or were not accessible (for exclusion reasons see Table
\ref{tab:EmpiricalExclusion} and for our PRISMA diagram see Figure
\ref{fig:PRISMA}).

\begin{figure}[h]
\centering
\caption{PRISMA diagram. Position still undecided. Currently generated in R based on n(row) maybe make prettier. \Warning\ Re-check numbers before duplicates removed and number of papers added from other sources.}
\includegraphics[width=\textwidth]{Figures/PRISMA}
\label{fig:PRISMA}
\end{figure}

\input{Tables/EmpiricalExclusion}

Of the final works we coded, 452 were journal articles, 68 theses, and 6
book chapters. Most studies presented quantitative data (\textit{N} =
464), mixed methods (\textit{N} = 39), or qualitative data (\textit{N} =
20), while the remaining 3 manuscripts were reviews of empirical data. A
vast majority of the authors used the term `acculturation' (or
derivative versions, such as `acculturation attitudes' or `acculturation
orientation'; \textit{total N} = 416), or `integration' (\textit{N} = 7)
to refer to cultural adaptation. Notably, a majority of the empirical
investigations did not share common measures of cultural adaptation --
389 studies used measures that were reported a maximum of five times,
with a considerable majority of papers using new or ad-hoc measures of
cultural adaptation. Only about every tenth study included the local
majority in the study (\textit{N} = 77, 14.69\%). Cultural adaptation
most frequently was a predictor variable (\textit{N} = 285, 54.39\%), a
dependent variable (\textit{N} = 148, 28.24\%), or a correlation
variable (\textit{N} = 37, 7.06\%) in the empirical works. This pattern
was mirrored when looking at the focus of the papers, where a majority
of the papers had acculturation as their main focus (\textit{N} = 153,
29.48\%), with other bodies of work focusing on health outcomes
(\textit{N} = 51, 9.83\%), or inter-group relations (\textit{N} = 18,
3.47\%) as their main outcomes. The earliest included study was
published in 1948, with a continuous increase of publications after the
year 2000, with considerable publication peaks in 2011 and 2019. We
provide full descriptions of descriptive data extractions and additional
information about the data description in Online Supplementary
Information \hl{X}.

\paragraph{Field of Publication}

For the broader empirical literature, we also collected additional data
on the field the studies were published in. To assess the differences
between fields we merged the `Scimago Journal Ranking Database'
\citep{SCImago2020} with our empirical review. For all available journal
articles we added information on key journal metrics (incl.~H index,
impact factor, and data on the field and audiences). This also meant
that dissertations, book chapters, and books were excluded from this
analysis because data on their publishers is not readily available or
unreliable. Additionally, 10 journals were not included in the Scimago
database (likely because they do not have an ISSN identifier or were
discontinued before 1996, see Online Appendix \hl{X}, Table \hl{X} for
the missing journals). We ultimately had journal metrics for 437
empirical articles. The Scimago database classifies each journal
according to the field(s) that the journal aims to address. Importantly,
(1) each journal can be be classified to address multiple fields and (2)
the field include codes of fields (e.g., `Social Sciences') as well as
sub-fields (e.g., `Social Psychology'). This leads to the case that
there can be substantial overlap between fields, and journals cannot
readily be assessed in mutually exclusive subgroups.

To summarize the articles further we then classified the field
combinations into super-ordinate discipline codes. These discipline
codes are based in part on U.S. Department of Education's subject
classifications \citep[i.e., CIP;][]{InstituteofEducationSciences2020},
the U.K. academic coding system
\citep[JACS 3.0;][]{HigherEducationStatisticsAgency2013}, the Australian
and New Zealand Standard Research Classification
\citep[ANZSRC 2020;][]{AustralianBureauofStatistics2020}, as well as the
Fields of Knowledge project \citep{ThingsmadeThinkable2014}. We
ultimately classified each journal into one of four mutually exclusive
disciplines (psychology: \textit{N} = 131, multidisciplinary: \textit{N}
= 103, Medicine, Nursing, and Health: \textit{N} = 146, and Social
Sciences (miscellaneous): \textit{N} = 45. For a full discussion of the
classifications see Online Supplementary Materials \hl{X}).

\subsubsection{Results}

To test the utility of our framework, we again assessed the role of
experience elements in the measurement as well as contextual
differences.

\paragraph{Experience}

In terms of the overall frequencies of experience elements, the broader
empirical data mirrored that of the validation studies. Most studies
included a measure of cognition (80.04\%) and behavior (82.13\%),
whereas only about half of all studies included a measure of affect
(49.05\%) and only a fifth of the studies included a measure of motives
(17.11\%). Yet, only 119 studies focused on a single element
(\(N_{behavior\ only}\) = 75, \(N_{cognition\ only}\) = 38,
\(N_{emotion\ only}\) = 6). Similarly, only 42 papers included measures
of all four experience elements (7.98\%). Most studies measured three
(34.98\%) or two dimensions (34.41\%). Different from the scale
validations, within the broader empirical works, most works included
measures of emotions, behaviors, and cognitions (\textit{N} = 153,
29.09\%), with a further substantial number of articles measuring
behaviors and cognitions (\textit{N} = 120, 22.81\%. Also see Figure
\ref{fig:EmpPlotFreq-1} and Table
\ref{tab:EmpiricalElementCooccurrences}). Looking at the number of
elements measured together we again see substantial differences in what
kind of scales include the individual elements. Scales that included
cognitions measured an average of 2.54 elements, scales measuring
behavior, on average, measured a 2.43, while scales that included affect
measures had a complexity average of 2.93 and scales measuring
motivation even measured an average of 3.28 scales. Thus, interestingly,
not a single study measured only motivation, and measures of motives
remained mostly limited to scales that were already multidimensional.
The results exacerbate the pattern found in the scale validations,
complex measures and conceptions of acculturation are seen infrequently
and readily accessible (i.e., less subjective) dimensions of cognition
and behavior remain the focus of most studies.

\begin{figure}[h]
\centering
\caption{Empirical Literature: Bar graph of the experience element combinations.}
\includegraphics[width=\textwidth]{Figures/EmpPlotFreq-1}
\label{fig:EmpPlotFreq-1}
\end{figure}

\input{Tables/EmpiricalElementCooccurrences}

\paragraph{Context}

To gain a general understanding of contextual factors within the broader
empirical studies, we again assessed cross-study patterns of cultural,
individual, situational, and process-related focus points.

\subparagraph{Country}

To assess the cultural contexts on which the authors focused, we again
assessed the migrants' countries of settlement as well as the countries
of origin. Similar to the validations, an overwhelming number of scales
were validated within a North American settlement context (United
States: \textit{N} = 277, Canada: \textit{N} = 40). But also the
remaining receiving societies were mostly `western' -- Western Europe
(e.g., The Netherlands, United Kingdom, Germany, Italy, Spain),
Australasia (Australia, New Zealand), Russia, and Israel. And only 25
studies focused on data from multiple receiving societies.

When it came to the migrants' country of origin, a majority of studies
were indifferent to migrants background and simply recruited any
consenting migrant (\textit{N} = 108), or recruited a category of
migrants (e.g., LatinX or Hispanic: \textit{N} = 67, African: \textit{N}
= 14). Among the individual countries target there was a particular
focus on the east and south-east Asian region (e.g., China: \textit{N} =
47, South Korea: \textit{N} = 37, Vietnam: \textit{N} = 22). Yet,
different from the scale validations, there was a large variety of
different origin countries that were included in less than five studies
(\textit{N} = 113 regions were targeted less than five times). Thus, the
receiving countries mainly mirrored those for which scales were
validated, yet there was an extensive number origin countries which were
investigated individually or migrants were considered irrespective of
their cultural origin. Moreover, it was again not possible to identify
distinct cultural clusters within the literature that would be large
enough to compare measures of cultural adaptation.

\subparagraph{Sample}

To assess the role different groups of individuals targeted in the
empirical work, we again coded the types of samples recruited for the
studies. A majority of studies sampled any consenting adult from the
migrant group of interest (\textit{N} = 283, 53.8\%). Of the targeted
sampling strategies, most recruited refugees (\textit{N} = 35, 6.65\%),
young migrants (\textit{N} = 96, 18.44\%), or elderly people (\textit{N}
= 28, 5.32\%). The remaining fifth of the studies recruited other more
specific samples (e.g., nurses, athletes, Muslims). Interestingly,
despite the circumstance that a large portion of papers focused on
mental health outcomes, only 7 studies (1.33\%) recruited clinical
migrant samples. These results speak to the case that relatively few
empirical studies actually take individual differences into account in
their sample selection. Studies may still address individual differences
within the data description and within the modeling approaches (e.g.,
controlling for gender), yet it seems that inter-sectional
idiosyncrasies did not seem to play a major role in the targeting of
samples. Moreover, cell counts were again unbalanced and we did not
assess experience differences between the samples.

\subparagraph{Domains}

To capture the situational focus of the authors, we coded which life
domains the utilized measures referred to. A relatively large number of
studies assess cultural adaption in general manner without mentioning
any context or life domain (\textit{N} = 116). The remaining studies
referred to an average of 1.51 dimensions (\textit{SD} = 1.87, range: 1
-- 21)). We found a total of 183 unique domains across the 526 studies.
The dimensions of `language` (\hl{XX}\%), 'food' (\hl{XX}\%), `social
interactions,' and `friends' (\hl{XX}\%) were included most frequently.
So, while larger proportion of studies ask about cultural adaption in
general (outside of a specific domain), the number of domains included
and addressed is extensive and diverse. The mentioned domains at times
go beyond the life fields mentioned in previous work (also see Online
Supplementary Materials \hl{X}).

\subparagraph{Process}

To assess the process focus of the broader empirical works, we again
assessed when in the migration process was collected and we additionally
assessed the type analysis done by the authors. We found that a 512
studies (97.71\%) collected cross-sectional data after the arrival of
the migrant in the new society. A single study targeted potential
migrants and 10 studies collected data prior and following the migration
event. Moreover, only 24 studies included longitudinal data analyses
concerned with cultural adaptation. This observation, again underscores
the arguments made by authors, who have long pointed out that the
acculturation literature has thus far failed to provide data that
meaningfully captures migration as a process
\citep[e.g.,][]{Brown2011, Ward2019}. This also did not allow us to
assess differences in the experience measures.

\paragraph{Fields}

To further test the utility of our framework in comparing
conceptualizations, we assessed differences of experience elements
across different fields. We provide more elaborate descriptions of the
differences in the methods, and publication types as well as contextual
differences in terms of sampling procedures, situational domains,
process-focus, analyses, and cultural contexts in Supplementary Online
Material \hl{X}.

We first assessed the references to affect, behavior, cognition, and
desires separately, for each of the disciplines. We find that for all
fields motivations (11.64-25.95\% of all measures in the field) and
emotions (37.67-58.78\%) are the least frequently measured elements and
each of the fields measures them similarly often (in proportional
terms). However, for the cognitive and behavioral elements the
proportions diverge between the fields. While the multidisciplinary
field measured behaviors (79.61\%) and cognition (79.61\%) almost
equally often, in the medical and general social science journals
behaviors were measured considerably more often than cognitions
(\(Behavior_{SoSci}\) = 88.89\% \textgreater{} \(Cognition_{SoSci}\) =
62.22\%; \(Behavior_{Med}\) = 88.36\% \textgreater{} \(Cognition_{Med}\)
= 68.49\%). Inversely, in the psychological journals cognitions
(89.31\%) were measured more often than behaviors (73.28\%; also see
Figure \ref{fig:FieldPlotFreq} B and A).

When looking at differences in how many different elements were measured
and patterns within these element-combinations, differences between the
fields become increasingly evident (also see Figure
\ref{fig:FieldPlotFreq} A and C). While `affect, behavior, and
cognition' and `behavior, and cognition' measures are the most common
combinations across all fields (also at similar proportional
importance), there is less dimension complexity and variation for
medical and social science fields. In the psychological 85.5\% of all
studies measures at least two experience elements (\textit{M} = 2.47,
\textit{SD} = 0.76). Although mean complexity differences were not
significantly different between the fields (\textit{F}(3, 421) = 5.98,
\textit{p} = 0.001; see Figure \ref{fig:FieldPlotComplexityAverage}),

\begin{figure}[h]
\centering
\caption{Scale Complexity and their proportional occurences per field.}
\includegraphics[width=\textwidth]{Figures/FieldPlotComplexityAverage-1}
\label{fig:FieldPlotComplexityAverage}
\end{figure}

Further looking at the qualitative differences of element combinations
can be informative. For example, there was not a single study published
in a psychological journal that conceptualized cultural adaptation by
behavior alone (eventhough this is the third most common measures in the
other three fields. Also see Figure \ref{fig:FieldPlotFreq} A).
Similarly, in the broader social scientific journal desires are always
measured together with behaviors, which is very uncommon in the other
fields\footnote{Although it should be noted that the social science field was smaller and more heterogeneous than the other fields. \Warning\ Maybe drop this argument -- based on only two studies.}.
There are also interesting pattern when one considers how many other
elements an aspect is measured with within each of the fields. For
example, while for all fields motivations are found in the most complex
scales
\footnote{Except for the broader social science journals that do not have many papers measuring motivation in the first place.},
medical journal have a substantially higher average scale complexity
when measuring motivations. Inversely, psychological journal on average
report behavioral measures of cultural adaptation in more complex
scales. This hints to a pattern, where complexity might indicate
relative importance of an aspect within the field -- where only scales
that already have a broad and diverse measure also include the elements
that are usually measured less within a field (also see Figure
\ref{fig:FieldElementComp}). We did not test these differences formally
because the number of experience elements were not independent between
the experience elements. There are like other and more nuanced
differences in the conceptualizations highlighted within this analysis
(e.g., patterns relevant to a single field). Yet, the broader patterns
described here might already speak to the utility of the framework.

\begin{figure}[h]
\centering
\caption{Combinations of measured experience element and their frequencies per field.}
\includegraphics[width=\textwidth]{Figures/FieldPlotFreq-1}
\label{fig:FieldPlotFreq}
\end{figure}

\begin{figure}[h]
\centering
\caption{Average complexity (number of experience elements measured) for all scales that include a given experience aspect.}
\includegraphics[width=\textwidth]{Figures/FieldElementComp-1}
\caption*{Note that these categories are not mutually exclusive (and thus not independent) because scales can include multiple experience aspects (i.e., higher complexity).}
\label{fig:FieldElementComp}
\end{figure}
