---
title: "Integration of Migrants"
subtitle: "Annotated Analysis"
author:
- Jannis Kreienkamp^1^
- ^1^University of Groningen
date: "Last updated: `r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2:
    fig_caption: yes
    md_extensions: +footnotes
    code_folding: hide
    mathjax: default
    theme: yeti
    toc: yes
    toc_float: yes
    number_sections: false
    css: style.css
editor_options:
  chunk_output_type: console
bibliography: references.bib
csl: apa.csl
---

<style type="text/css">
.main-container {
  max-width: 1300px;
  margin-left: auto;
  margin-right: auto;
}
.table {
  margin-left:auto; 
  margin-right:auto;
}
</style>


```{r setup, include=FALSE}
# R Studio Clean-Up
  cat("\014") # clear console
  #rm(list=ls()) # clear workspace - use restart R instead
  gc() # garbage collector
  
# Install and Load Packages
lib <- c("rmarkdown", "knitr", "citr", "remedy", "bookdown", "papaja", "rmdfiltr", "psych",
         "ggplot2", "ggthemes", "haven", "RColorBrewer", "plotly", "forcats", "wordcloud", "visNetwork", "ggwordcloud",
         "rworldmap", "rnaturalearth", "rnaturalearthdata", "rgeos", "sp", "ggspatial",
         "data.table", "dplyr", "tidyr", "Hmisc", "kableExtra", "readxl", "stringr", "stringi", "reshape2",
         "tibble", "sqldf", "networkD3", "GGally", "ggstatsplot","hrbrthemes",
         "mada", "naniar", "stats", "matrixStats", "ISOcodes", "pander", "lubridate", "gsheet")
invisible(lapply(lib, library, character.only = TRUE))  
rm(lib)  

# Load Custom Packages  
  source("./scripts/functions/fun.panel.R")
  source("./scripts/functions/themes.R")

# Markdown Options
  knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # set working directory
  knitr::opts_knit$get("root.dir") # check working directory
  options(scipen = 999, digits = 4, width = 400) #removes scientific quotation
  #knitr::opts_chunk$set(echo = TRUE, cache = F, cache.path = rprojroot::find_rstudio_root_file('cache/')) # cache settings
  knitr::knit_hooks$set(
   error = function(x, options) {
     paste('\n\n<div class="alert alert-danger">',
           gsub('##', '\n', gsub('^##\ Error', '**Error**', x)),
           '</div>', sep = '\n')
   },
   warning = function(x, options) {
     paste('\n\n<div class="alert alert-warning">',
           gsub('##', '\n', gsub('^##\ Warning:', '**Warning**', x)),
           '</div>', sep = '\n')
   },
   message = function(x, options) {
     paste('\n\n<div class="alert alert-info">',
           gsub('##', '\n', x),
           '</div>', sep = '\n')
   }
  )
  htmltools::tagList(rmarkdown::html_dependency_font_awesome())

# Global Chunk Options
  knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figures/',
                      echo=FALSE, warning=FALSE, message=FALSE)
  knitr::opts_chunk$set(echo = TRUE)
```

<br/>

Note. Boxplots display the interquartile range (IQR, center box), and the whiskers extend 1.5*IQR from the lower and upper hinge. The white point indicates the mean and the white center line indicates the median.   

<br/>

# **Data Preparation**  

## Import Data  

In a first step we import the raw data of the review from the shared coding [Google Sheet](https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing). We, primarily, import the database of the scale validations and the review of the empirical papers. Beyond that we also import the separate lists of codes used.  

```{r importCoding, warning=F, message=F}
urlPsycInfo <- gsheet::construct_download_url('https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing',
                                              format = "csv", sheetid = "1151157759")
urlScales <- gsheet::construct_download_url('https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing',
                                             format = "csv", sheetid = "799109777")
urlInput <- gsheet::construct_download_url('https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing',
                                             format = "csv", sheetid = "168002198")
urlDomains <- gsheet::construct_download_url('https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing',
                                             format = "csv", sheetid = "1826792378")


dt.PsycInfo <- gsheet::gsheet2tbl(urlPsycInfo)
dt.Scales <- gsheet::gsheet2tbl(urlScales)
dt.Input <- gsheet::gsheet2tbl(urlInput)
dt.Domains <- gsheet::gsheet2tbl(urlDomains)

rm(list = ls(pattern='^url'))
```

```{r importJournals, warning=F, message=F}
fileNam = list.files(path = "data/JournalDatabase", pattern="scimagojr 2019  Subject Area")
fieldNam <- gsub("scimagojr 2019  Subject Area - |.csv", "", fileNam)

#for (i in 1:length(fileNam)) assign(fieldNam[i], read.csv2(paste0("data/JournalDatabase/",fileNam[i])))
fieldList <- list()
for (i in 1:length(fileNam)) fieldList[[fieldNam[i]]] <- read.csv2(paste0("data/JournalDatabase/",fileNam[i])) 

# There are some more Publishers in the individual field databases.
dfJournals <- plyr::ldply(fieldList, data.frame)
#length(unique(dfJournals$Title))

PublisherInfo <- read.csv2("data/JournalDatabase/scimagojr 2019.csv") 
PublisherInfo$fields <- ""
for (i in 1:nrow(PublisherInfo)) {
  for(j in 1:length(fileNam)) {
    PublisherInfo$fields[i] <- ifelse(PublisherInfo$Title[i] %in% fieldList[[fieldNam[j]]]$Title, 
                                       paste(PublisherInfo$fields[i],fieldNam[j], sep = "; "), 
                                       PublisherInfo$fields[i])
  }
}
PublisherInfo$fields <- gsub("^; ", "", PublisherInfo$fields)

colNam <- gsub("\\.", "", names(PublisherInfo))
colNam <- gsub("^Title$", "PublicationTitleDb", colNam)
colNam <- gsub("^Type$", "PublicationTypeDb", colNam)
colNam <- gsub("^Country$", "PublisherCountry", colNam)
colNam <- gsub("^Region$", "PublisherRegion", colNam)
colNam <- gsub("^Publisher$", "PublisherName", colNam)

names(PublisherInfo) <- colNam

rm(fileNam, fieldNam, fieldList, colNam)
```

## Prepare Data Frames  

We then go on to clean the data sets in order to use them in later analyses and keep track of exclusion filters.  

```{r cleanScales, results='asis'}
# Frequency of all scales within the 
n_occur_ScaleDT <- data.frame(table(Scale = dt.Scales$Scale)) 

# Extract publication year (crude but seems to work)
dt.Scales$year <- str_extract(dt.Scales$`reference with doi`, "([0-9]{4})")

# remove duplicates
dt.Scales.Unique <- dt.Scales %>%
  filter(Duplicate == "Unique")

# remove non-available scales
dt.Scales.Added <- dt.Scales %>%
  filter(Duplicate == "Unique",
         added == 1)

# remove excluded scales
dt.Scales.Included <- dt.Scales %>%
  filter(Duplicate == "Unique",
         added == 1, 
         is.na(Comment)
         )
```

```{r cleanEmpirical, results='asis'}
# remove duplicates
dt.psych <- dt.PsycInfo 

# title screening
dt.psych.title <- dt.PsycInfo %>%
  filter(FinalTitle == 1)

# abstract screening
dt.psych.abstract <- dt.PsycInfo %>%
  filter(FinalTitle == 1,
         FinalAbstract == 1)

# empirical
dt.psych.empirical <- dt.PsycInfo %>%
  filter(FinalTitle == 1,
         FinalAbstract == 1,
         empirical != 0)

# included
dt.psych.included <- dt.PsycInfo %>%
  filter(FinalTitle == 1,
         FinalAbstract == 1,
         empirical != 0,
         MissingABCD == 0)
```

```{r mergeJournalInfo, results='asis', warning=F}
psychData <- dt.psych.included %>%
  mutate(ISSN = gsub("-", "", ISSN))
PublisherInfo <- PublisherInfo %>%
  separate(Issn, c("Issn01", "Issn02"), remove = FALSE)

psychData <- sqldf("SELECT l.*, r.*
              FROM psychData as l
              LEFT JOIN PublisherInfo as r
              on l.PublicationTitle = r.PublicationTitleDb OR l.ISSN = r.Issn01 OR l.ISSN = r.Issn02")
```

# **Analysis** 

## **Scale Validations**  
The first data set we assess is a database of scale validations. We bring together the scales suggested in previous reviews as well as validation studies we identified in our own review. Throughout our literature review we found five major reviews that reviewed the measurement of acculturation [@Celenk2011; @Maestas2000; @Matsudaira2006; @Wallace2010; @Zane2004].  

### Exclusions  
Taken together these five reviews collected a total of `r nrow(dt.Scales[dt.Scales$Review != "own",])` scales, of which `r nrow(dt.Scales[dt.Scales$Duplicate == "Duplicate" & dt.Scales$Review != "own",])` were duplicates. From our own review we added `r nrow(dt.Scales[dt.Scales$Review == "own review",])` additional validation studies. After removing duplicates this meant that we considered a total of `r nrow(dt.Scales[dt.Scales$Duplicate == "Unique",])` unique scales for our coding. Of these scales we ultimately had to exclude `r nrow(dt.Scales[!is.na(dt.Scales$Comment),])`, because they were either not accessible or did not fit the the topic of our review (see Table \@ref(tab:ScalesExclusion)).  

```{r ScalesExclusion, results='asis'}
data.frame(table(Exclusion = dt.Scales$Comment)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Reasons for Exclusion",
      format = "html",
      col.names = c("Exclusion Reason",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")

data.frame(table(Exclusion = dt.Scales$Comment)) %>%
  arrange(desc(Freq)) %>%
  kbl(., 
      label = "ScalesExclusion",
      caption = "Reasons for Exclusion",
      format = "latex",
      col.names = c("Exclusion Reason",
                    "Frequency"), 
      linesep = "",
      booktabs = T,
      align = c("l", "c"))  %>%
  kable_styling(latex_options = c("repeat_header"),
                position = "left") %>%
  save_kable("Tables/ScalesExclusion.tex")
```

The remaining `r nrow(dt.Scales[dt.Scales$Duplicate == "Unique" & is.na(dt.Scales$Comment),])` scales are listed in Table \@ref(tab:ScaleTbl).  

```{r ScaleTbl}
dt.Scales.Included %>%
  mutate(SourceShort = stri_replace_all_fixed(Source,
                                         pattern = c("@Celenk2011", "@Maestas2000", "@Matsudaira2006", "@Wallace2010", "@Zane2004", "own review"), 
                                         replacement = c("CEL", "MAE", "MAT", "WAL", "ZAN", "OWN"), 
                                         vectorize_all = FALSE)) %>%
  dplyr::select(Scale, Reference, `Source ^a^` = SourceShort, 
                Affect, 	Behavior,	Cognition,	Desire,
                `domain scale`,Sample,	`Includes Majority`, 
                `Host Country Comb`,	`Origin Country Comb`) %>%
  mutate_at(vars(Affect, 	Behavior,	Cognition, Desire), ~replace_na(., 0)) %>%
  kbl(., caption = "Integration Scales",
      format = "html") %>%
  add_footnote(c("CEL = @Celenk2011, MAE = @Maestas2000, MAT = @Matsudaira2006, WAL = @Wallace2010, ZAN = @Zane2004, OWN = own review (only additional)"), 
               notation = "alphabet") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "110%", height = "750px")

dt.Scales.Included %>%
  mutate(SourceShort = stri_replace_all_fixed(Source,
                                         pattern = c("@Celenk2011", "@Maestas2000", "@Matsudaira2006", "@Wallace2010", "@Zane2004", "own review"), 
                                         replacement = c("CEL", "MAE", "MAT", "WAL", "ZAN", "OWN"), 
                                         vectorize_all = FALSE)) %>%
  dplyr::select(Scale, Reference, `Source [note]"` = SourceShort, 
                Affect, 	Behavior,	Cognition,	Desire,
                `domain scale`,Sample,	`Includes Majority`, 
                `Host Country Comb`,	`Origin Country Comb`) %>%
  mutate_at(vars(Affect, 	Behavior,	Cognition, Desire), ~replace_na(., 0)) %>%
  kbl(., 
      label = "ScaleTbl",
      caption = "Cultural Adaptation Scales",
      format = "latex",
      linesep = "",
      booktabs = T,
      longtable = T,
      align = c("l", "c"))  %>%
  add_footnote(c("CEL = @Celenk2011, MAE = @Maestas2000, MAT = @Matsudaira2006, WAL = @Wallace2010, ZAN = @Zane2004, OWN = own review (only additional)"), 
               notation = "alphabet") %>%
  kable_styling(latex_options = c("repeat_header"),
                position = "left") %>%
  save_kable("Tables/ScaleTbl.tex")
```

### Interest over time

Of the scale we included we also plotted the publication years of the scale validations in order to gain an understanding of the interest in scale development over time.   

```{r HistTime}
ggplotly(
ggplot(dt.Scales.Included %>% mutate(year = as.numeric(year)), aes(x=year)) + 
  geom_histogram(bins = length(unique(dt.Scales.Included$year)), fill = "grey14")+
  ylab("Number of Validations")+
  xlab("Year") +
  ggtitle("Scales in Review over Time") +
  theme_Publication() +
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
)
```

### Sample  

The study sample a scale is validated in can be fairly important if one plans to use a scale for a context-specific phenomenon such as a cultural adaptation of two specific cultures. We, therefore, coded the type of sample the original authors used in their validation studies (see Figure \@ref(fig:SampleFreq)).  

```{r SampleFreq, fig.cap="Bar graph of the study samples used in the original validation studies."}
# tally different samples
SampleFreq <- as.data.frame(table(Sample = dt.Scales.Included$Sample)) %>%
  arrange(Freq) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Sample=factor(Sample, levels=Sample)) # update factor levels
  
# barplot of sample frequency
ggplotly(  
ggplot(data=SampleFreq, aes(x=Sample, y=Freq)) +
  geom_bar(stat="identity", fill="grey14") +
  ylab("Frequency") +
  ggtitle("Validation Sample") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
)
```

The category *general* refers to a sampling strategy in which any consenting adult could participate in the study.  

### Dimensions  

One major focus of our coding efforts was put on identifying the phenomenological dimensions that were assessed by each individual scale. Based the ABCD framework of human experiences, we independently distinguished between emotional (affect), behavioral, cognitive, and need-based measurements of of acculturation. Examples of concepts that fell into the individual dimensions are shown in Table \@ref(tab:Dimensions):  
</br>

Table: (\#tab:Dimensions) Examples for Dimensions of Acculturation Measurements.  

| Dimension | Concept                                                             | Wording                                            |
|-----------|---------------------------------------------------------------------|----------------------------------------------------|
| Affect    | belonging, loneliness, satisfaction                                 | "I feel ...",                                      |
| Behavior  | language learning, media consumption, voting                        | "I do ...", "I speak ...", "I meet ..."            |
| Cognition | cultural identification, cultural values, attitude towards majority | "I prefer ...", "I think ...", "I identify as ..." |
| Desire    | needs, goals, wants                                                 | "I want ...", "I would like to ...", "I need ..."  |

Note that this also means that we do not include scales that measure aspects of acculturation that do can be measured without consideration of the individual's experiences, such as physical changes, cultural changes, or societal changes.  

Figure \@ref(fig:ABCDFreq) shows how often each of the dimensions was coded.  

```{r ABCDFreq, fig.cap="Bar graph of the counts for each of the dimensions."}
# Count the times each dimension is measured
DimensionFreq <- dt.Scales.Included %>%
  dplyr::select(Affect, Behavior, Cognition, Desire) %>%
  mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  colSums(., na.rm = FALSE, dims = 1) 

# transform to data frame and make row names name variable
DimensionFreq <- data.frame(Dimension = names(DimensionFreq), Frequency = DimensionFreq)

# barplot of dimension frequency
ggplotly(  
ggplot(data=DimensionFreq, aes(x=Dimension, y=Frequency)) +
  geom_bar(stat="identity", fill="grey14") +
  ggtitle("Overall Dimension Frequency") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
)
```

We also plot how often each of the dimensions were measured together. A bar graph of the compound frequencies is shown Figure \@ref(fig:ABCDCombFreq) and a network graph of frequencies and co-occurrences is shown in Figure \@ref(fig:dimensionNetwork).  

```{r ABCDCombFreq, message=F, fig.cap="Bar graph of the counts for each of the dimension combinations."}
# frequency of unique combinations
ABCD_comb <- dt.Scales.Included %>%
  dplyr::select(Affect, Behavior, Cognition, Desire) %>%
  #mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., "")) %>%
  group_by(Affect, Behavior, Cognition, Desire) %>%
  summarise(count = n())

# fill replace ones with colnames to be combined
for (i in 1:(length(ABCD_comb)-1)) {
    ABCD_comb[[i]] <- str_replace(as.character(ABCD_comb[[i]]), "1", colnames(ABCD_comb)[i])
}

# collect dimensions names for each combination
ABCD_comb <- ABCD_comb %>%
  unite("Dimension Combination",c("Affect", "Behavior", "Cognition", "Desire"), na.rm = TRUE, sep = ", ") %>%
  mutate(`Dimension Combination` = fct_reorder(`Dimension Combination`, count))

# bar plot frequencies
ggplotly(
ggplot(ABCD_comb %>% mutate(Frequency = count), aes(x=`Dimension Combination`, y=Frequency)) +
  geom_bar(stat="identity", fill="grey14") +
  ggtitle("Compound Dimension Frequency") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
)
```

```{r dimensionNetwork, fig.cap="Network graph of the dimension frequencies and co-occurences. The nodes (i.e., circles) represent the concepts so that the size of the circle indicates the number of times concept was coded and the edges (i.e., connections) represent the co-occurences so that the width of the line indicates how often the concepts were measured in one scale."}
# make crossproduct matrix to condense co-occurrences (off-diagonals) and get frequencies (diagonals)
X <- as.matrix(dt.Scales.Included %>% 
                 dplyr::select(Affect, Behavior, Cognition, Desire) %>% 
                 mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)))
out <- crossprod(X)  # Same as: t(X) %*% X
#diag(out) <- 0       # remove frequencies on diagonals

# information on the concepts themselves
nodes <- data.frame(id    = colnames(out), 
                    title = paste0(colnames(out), "<br>Frequency: ", diag(out)), 
                    value = diag(out),
                    size  = diag(out),
                    shape = "dot")

# information on the co-occurrences
edges           <- as.data.frame(t(combn(colnames(out),2)))
colnames(edges) <- c('from','to')
edges$width     <- NA
for (i in 1:nrow(edges)) {
    edges$width[i] <- out %>%
      as.data.frame(.) %>%
      rownames_to_column('dim') %>%
      filter(dim == edges$to[i]) %>%
      dplyr::select(any_of(edges$from[i])) %>%
      as.numeric(.)
}
edges$label <- edges$width
edges$title <- paste0(edges$from, " - ", edges$to, "<br>Co-occurences: ", edges$width)

# plot network graph
visNetwork(nodes, edges %>% mutate(width = scales::rescale(edges$width, to=c(10,30))), 
           heigth = "100%", width = "100%", main = "Network Graph Scale Validation Phenomenological Dimensions") %>%
            visIgraphLayout(layout = "layout_in_circle") %>%
            visNodes(
                shape = "dot",
                color = list(
                    background = "#0085AF",
                    border = "#013848",
                    highlight = "#FF8000"
                )
            ) %>%
            visEdges(
                shadow = FALSE,
                color = list(color = "#0085AF", highlight = "#C62F4B")
            ) %>%
            visOptions(highlightNearest = list(enabled = T, degree = 1, hover = T), 
                       nodesIdSelection = list(main = "Select variable")) %>% 
            visInteraction(keyboard = TRUE, tooltipDelay = 0) %>%
            visLayout(randomSeed = 11)
```

### Domains  

Acculturation can happen in different life domains [e.g., @Arends-Toth2007; @Zane2004]. We coded which life domains the scales referred to, either as part of subscale labels, factor labels, explicit commentary of the authors, or clear question wordings (see Figure \@ref(fig:ScaleDomainFrequencies)).  

```{r ScaleDomainFrequencies, warning=F, fig.cap="Wordcloud of the validation scale domains."}
# remove duplicate domains
UniqueDomains <- dt.Domains %>% 
  filter(Duplicate == "Unique")

# dataframe to compile domain frequency for Review Scales
ScaleDomainFreq <- data.frame(UniqueDomains, Frequency = NA)

# count domain frequency in dt.Scales.Included
for (i in 1:nrow(UniqueDomains)) {
  ScaleDomainFreq$Frequency[i] <- length(grep(UniqueDomains$Domain[i], dt.Scales.Included$`domain scale`, value = T))
}

# prepare for ggplot
ScaleDomainFreq <- ScaleDomainFreq %>%
  dplyr::select(Domain, Frequency) %>%
  filter(Frequency > 0) %>%
  arrange(Frequency) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Domain=factor(Domain, levels=Domain)) # update factor levels

# Word cloud frequencies
set.seed(7) # for reproducibility 
wordcloud(words = ScaleDomainFreq$Domain, freq = ScaleDomainFreq$Frequency, 
          min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
```

### Countries  

We also coded the cultural context the scales were validated in. We coded both the migrants' country of origin as well as the country of the receivong society in which the study was conducted (see Figure \@ref(fig:HostFreqEmpirical)).  

```{r CountryPrep, message=F}
# subset relevant variables
ScaleMap <- dt.Scales.Included %>%
  dplyr::select(Scale, ends_with("Comb"))

# Host Countries: Find all individual country names and count frequency of occurrence
HostCountryFreq <- data.frame(Country = unique(unlist(strsplit(ScaleMap$`Host Country Comb`, ", "))), Frequency = NA, source = "Host")
for (i in 1:nrow(HostCountryFreq)) {
  HostCountryFreq$Frequency[i] <- length(grep(HostCountryFreq$Country[i], ScaleMap$`Host Country Comb`, value = T))
}
HostCountryFreq <- HostCountryFreq %>%
  #filter(Frequency > 0) %>%
  arrange(Frequency) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Country=factor(Country, levels=Country)) # update factor levels

# Origin Countries: Find all individual country names and count frequency of occurrence
OriginCountryFreq <- data.frame(Country = unique(unlist(strsplit(ScaleMap$`Origin Country Comb`, ", "))), Frequency = NA, source = "Origin")
for (i in 1:nrow(OriginCountryFreq)) {
  OriginCountryFreq$Frequency[i] <- length(grep(OriginCountryFreq$Country[i], ScaleMap$`Origin Country Comb`, value = T))
}
OriginCountryFreq <- OriginCountryFreq %>%
  #filter(Frequency > 0) %>%
  arrange(Frequency) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Country=factor(Country, levels=Country)) # update factor levels

# combine Host and Origin list
CountryFreq <- rbind(OriginCountryFreq, HostCountryFreq)

# For compound country categories look up all possible countries
countriesLatinAmerica  <- c("Mexico", 
                            "Guatemala", "Honduras", "El Salvador", "Nicaragua", "Costa Rica", "Panama", 
                            "Colombia", "Venezuela", "Ecuador", "Peru", "Bolivia", "Chile", "French Guiana", "Paraguay", "Brazil", "Argentina", "Uruguay", 
                            "Cuba", "the Dominican Republic", "Haiti", "Puerto Rico")
countriesHispanic      <- c("Argentina", "Bolivia", "Chile", "Colombia", "Costa Rica", "Cuba", "Dominican Republic", "Ecuador", "El Salvador", "Guatemala", "Honduras", 
                            "Mexico", "Nicaragua", "Panama", "Paraguay", "Peru", "Puerto Rico", "Spain", "Uruguay", "Venezuela")
countriesArabic        <- c("Algeria", "Bahrain", "the Comoros", "Djibouti", "Egypt", "Iraq", "Jordan", "Kuwait", "Lebanon", "Libya", "Mauritania", "Morocco", "Oman",
                            "Palestine", "Qatar", "Saudi Arabia", "Somalia", "Sudan", "Syria", "Tunisia", "United Arab Emirates", "Yemen")
countriesSouthEastAsia <- c("Cambodia", "Laos", "Myanmar", "Malaysia", "Thailand", "Vietnam", "East Timor", "Indonesia", "Philippines", "Singapore", "Brunei")
countriesSouthAsia     <- c("Afghanistan", "Bangladesh", "Bhutan", "India", "Maldives", "Nepal", "Pakistan", "Sri Lanka")
countriesAsia          <- c("China", "India", "Indonesia", "Pakistan", "Bangladesh", "Japan", "Philippines", "Vietnam", "Turkey", "Iran", "Thailand", "Myanmar", "South Korea",
                            "Iraq", "Afghanistan", "Saudi Arabia", "Uzbekistan", "Malaysia", "Yemen", "Nepal", "North Korea", "Sri Lanka", "Kazakhstan", "Syria", "Cambodia",
                            "Jordan", "Azerbaijan", "United Arab Emirates", "Tajikistan", "Israel", "Laos", "Lebanon", "Kyrgyzstan", "Turkmenistan", "Singapore", "Oman",
                            "State of Palestine", "Kuwait", "Georgia", "Mongolia", "Armenia", "Qatar", "Bahrain", "Timor-Leste", "Cyprus", "Bhutan", "Maldives", "Brunei")
countriesFormerUDSSR   <- c("Armenia", "Azerbaijan", "Belarus", "Estonia", "Georgia", "Kazakhstan", "Kyrgyzstan", "Latvia", "Lithuania", "Moldova", "Russia", 
                            "Tajikistan", "Turkmenistan", "Ukraine", "Uzbekistan")
countriesAny <- c()
countriesMultiple <- c() 
```

```{r HostFreqEmpirical, fig.cap="Bar graph of study counts for the individual host countries and countries of origin.", warning=F}
# bar plot Host country frequencies
ggplotly(
ggplot(CountryFreq , aes(x=Country, y=Frequency)) +
  geom_bar(stat="identity", fill="grey14") +
  coord_flip()+
  facet_wrap( ~ source, nrow = 1) +
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none"),
height = 820)
```

<!-- <br> -->
<!-- <div class="alert alert-warning"> -->
<!-- <strong><i class="fa fa-exclamation-triangle"></i> To Do!</strong> <br> -->
<!-- Worldmap still needs to be filled. -->
<!-- </div> -->

<!-- ```{r migrationMap, message=F, fig.cap="Plan: worldmap visualization to showcase migrant flows investigated during validations."} -->
<!-- # load worldmap data from Natural Earth Project -->
<!-- world.data <- rnaturalearth::ne_countries(scale = "medium", returnclass = "sf") -->

<!-- # plot worldmap -->
<!-- ggplot(data = world.data) + -->
<!--   geom_sf(fill= "antiquewhite") + -->
<!--   xlab("Longitude") + ylab("Latitude") + -->
<!--   ggtitle("World map (to be filled with data)", subtitle = paste0("(", length(unique(world.data$name)), " countries)")) + -->
<!--   annotation_scale(location = "bl", width_hint = 0.25) + -->
<!--   annotation_north_arrow(location = "bl", which_north = "true",  -->
<!--                          pad_x = unit(0.5, "in"), pad_y = unit(0.5, "in"), -->
<!--                          style = north_arrow_fancy_orienteering) + -->
<!--   theme(panel.grid.major = element_line(color = gray(.5), linetype = "dashed", size = .2),  -->
<!--         panel.background = element_rect(fill = "aliceblue")) -->
<!-- ``` -->

## **Empirical: General**  

After analysis of the scales validations, we assessed the empirical papers we collected for the systematic review.  

### Exclusions  
The search produced a total of `r nrow(dt.psych)` results. We subsequently screened out results that did not fit into our review. We excluded `r nrow(dt.psych)-nrow(dt.psych.title)` results in the title screening (for exclusion reasons see Table \@ref(tab:PsychExclusionTitle)) as well as an additional `r nrow(dt.psych.title)-nrow(dt.psych.abstract)` results during the abstract screening (for exclusion reasons see Table \@ref(tab:PsychExclusionAbstract)).  

```{r PsychExclusionTitle, results='asis'}
data.frame(table(Exclusion = dt.psych$NoteTitle)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Reasons for Exclusion Title Screening",
      format = "html",
      col.names = c("Exclusion Reason",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r PsychExclusionAbstract, results='asis'}
data.frame(table(Exclusion = dt.psych$NoteAbstract)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Reasons for Exclusion Abstract Screening",
      format = "html",
      col.names = c("Exclusion Reason",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

Of the remaining `r nrow(dt.psych.abstract)` results, `r nrow(dt.psych.empirical)` papers presented empirical work on acculturation and were coded. The `r nrow(dt.psych.abstract %>% filter(empirical==0))` non-empirical results were reviews, which were not coded because they did not fit into our coding schema. During the full text coding we excluded an additional `r length(dt.psych.empirical$MissingABCD[dt.psych.empirical$MissingABCD==1])` results were dropped because they were either not relevant or were not accessible (for exclusion reasons see Table \@ref(tab:PsychExclusionCoded)).  
All included works are listed in the [Online Coding Database](https://docs.google.com/spreadsheets/d/1j3j7q15lhNqPxp3qGnRtc2zuaE7plxWYR7tWKltkdU8/edit?usp=sharing).  

```{r PsychExclusionCoded}
data.frame(table(dt.psych.empirical$NoteMissing)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Excluded during Coding",
      format = "html",
      col.names = c("Exclusion Reason",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Publication Type  

A majority of the results were journal articles but we also reviewed a number of theses and book chapters (see Table \@ref(tab:PsychPublicationType)).  

```{r PsychPublicationType}
data.frame(table(dt.psych.included$PublicationType)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Type of Publication",
      format = "html",
      col.names = c("Publication Type",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

A majority of the empirical papers were quantitative assessments of acculturation (for an overview of the data collection types see Table \@ref(tab:PsychMethod)).  

```{r PsychMethod}
data.frame(table(dt.psych.included$Method)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Type of Data Collection",
      format = "html",
      col.names = c("Data Type",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Terms used    

The field of acculturation has been using a variety of terms to describe the process of cultural adaptation. We list the terms the authors used in their paper to refer to cultural adaptation in Table \@ref(tab:PsychTerm).  

```{r PsychTerm}
data.frame(table(tolower(dt.psych.included$term))) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Terms used",
      format = "html",
      col.names = c("Term",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "100%", height = "500px")
```

### Measure used    

We list the measures used by the authors in Table \@ref(tab:PsychMeasure). Note that a majority of the measurements are not previously standardized and are not shared across articles.  

```{r PsychMeasure}
data.frame(table(tolower(dt.psych.included$MeasureDefinition))) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Measures used",
      format = "html",
      col.names = c("Term",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "110%", height = "500px")
```
<br>
<div class="alert alert-warning">
<strong><i class="fa fa-exclamation-triangle"></i> To Do!</strong> <br>
It seems as if there are still some inconsistencies and spelling problems in the terms and measures.
</div>

### Interest over time    

As with the validation scales we used the publication year of the articles, theses, book chapters to visualize empirical interest in the topic of acculturation over time. We offer a global, developmental overview of the field in Figure \@ref(fig:PsychHistTime).  

```{r PsychHistTime, fig.cap="Histogram of the publication year for all included results."}
ggplotly(
ggplot(dt.psych.included, aes(x=year)) + 
  geom_histogram(bins = length(unique(dt.psych.included$year)), fill = "grey14")+
  ylab("Number of Results")+
  xlab("Year") +
  ggtitle("Publication Year of Results")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
)
```

We additionally assessed empirical developments in terms of publication type (see Figure \@ref(fig:PsychHistTimePubtype)) and data collection type (see Figure \@ref(fig:PsychHistTimeMethod)).  

```{r PsychHistTimePubtype, warning=F, fig.cap="Density plot of the yearly publication frequency for by type of publication."}
ggplotly(
ggplot(dt.psych.included, aes(x=year, color = PublicationType)) + 
  #geom_density(aes(y = ..count..)) +
  geom_line(stat='count') +
  geom_point(stat='count', size = .9) +
  #facet_grid(.~PublicationType) +
  ylab("Number of Results")+
  xlab("Year") +
  ggtitle("Publication Year by Publication Type (Density Plot)")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="bottom")
)
```

```{r PsychHistTimeMethod, warning=F, fig.cap="Density plot of the yearly publication frequency for by data collection method."}
ggplotly(
ggplot(dt.psych.included, aes(x=year, color = Method)) + 
  #geom_density(aes(y = ..count..)) +
  geom_line(stat='count') +
  geom_point(stat='count', size = .9) +
  #facet_grid(.~PublicationType) +
  ylab("Number of Results")+
  xlab("Year") +
  ggtitle("Publication Year by Data Type (Density Plot)")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="bottom")
)
```

### Sample  

To gain a deeper understanding of the study setups in the empirical studies we coded the type of sample recruited (Figure \@ref(fig:PsychSampleFreq)).  

```{r PsychSampleFreq, fig.cap="Bar graph of the study samples used in the empirical studies."}
# tally different samples
PsychSampleFreq <- as.data.frame(table(Sample = dt.psych.included$Sample)) %>%
  arrange(Freq) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Sample=factor(Sample, levels=Sample)) # update factor levels
  
# barplot of sample frequency
ggplotly(  
ggplot(data=PsychSampleFreq, aes(x=Sample, y=Freq)) +
  geom_bar(stat="identity", fill="grey14") +
  ylab("Frequency") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
)
```

Again the category *general* refers to a sampling strategy in which any consenting adult would be able to participate in the study.  
Beyond the sample group itself we also coded which time point in the migration process was targeted. Table \@ref(tab:PsychMigrationTimeFreq) showcases that an overwhelming majority of studies targets migrants only after they had left their country of origin.  

```{r PsychMigrationTimeFreq}
# tally different migration times
data.frame(table(tolower(dt.psych.included$MigrationTime))) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Migration Time",
      format = "html",
      col.names = c("Migration Time",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

Additionally, only a minority of studies included data on the acculturation process from the majority and migrant perspective jointly (see Table \@ref(tab:PsychMayority)).  

```{r PsychMayority}
# tally different migration times
data.frame(table(dt.psych.included$IncludesMajority)) %>%
  mutate(Var1 = recode_factor(.$Var1, `0` = "no", `1` = "yes")) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Whether sample includes majority members",
      format = "html",
      col.names = c("Majority members",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Dimensions  

Again, a major focus of our coding was the role of affect, behavior, cognition, and desires in the measurement of acculturation. Based the ABCD framework of human experiences, we independently distinguished between emotional (affect), behavioral, cognitive, and need-based measurements of of acculturation.  

Figure \@ref(fig:PsychABCDFreq) shows how often each of the four dimensions was coded.  

```{r PsychABCDFreq, fig.cap="Bar graph of the counts for each of the dimensions across all included empirical works."}
# Count the times each dimension is measured
PsychDimensionFreq <- dt.psych.included %>%
  dplyr::select(Affect, Behavior, Cognition, Desire) %>%
  mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  colSums(., na.rm = FALSE, dims = 1) 

# transform to data frame and make row names name variable
PsychDimensionFreq <- data.frame(Dimension = names(PsychDimensionFreq), Frequency = PsychDimensionFreq) %>%
  arrange(Frequency) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Dimension=factor(Dimension, levels=Dimension)) # update factor levels

# barplot of dimension frequency
ggplotly(  
ggplot(data=PsychDimensionFreq, aes(x=Dimension, y=Frequency)) +
  geom_bar(stat="identity", fill="grey14") +
  ggtitle("Overall Dimension Frequency") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
)
```

Again, we also plot how often each of the dimensions were measured together. A bar graph of the compound frequencies is shown Figure \@ref(fig:PsychABCDCombFreq) and a network graph of frequencies and co-occurrences is shown in Figure \@ref(fig:PsychDimensionNetwork).  

```{r PsychABCDCombFreq, message=F, fig.cap="Bar graph of the counts for each of the dimension combinations."}
# frequency of unique combinations
PsychABCD_comb <- dt.psych.included %>%
  dplyr::select(Affect, Behavior, Cognition, Desire) %>%
  #mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., "")) %>%
  group_by(Affect, Behavior, Cognition, Desire) %>%
  summarise(count = n())

# fill replace ones with colnames to be combined
for (i in 1:(length(PsychABCD_comb)-1)) {
    PsychABCD_comb[[i]] <- str_replace(as.character(PsychABCD_comb[[i]]), "1", colnames(PsychABCD_comb)[i])
}

# collect dimensions names for each combination
PsychABCD_comb <- PsychABCD_comb %>%
  unite("Dimension Combination",c("Affect", "Behavior", "Cognition", "Desire"), na.rm = TRUE, sep = ", ") %>%
  mutate(`Dimension Combination` = fct_reorder(`Dimension Combination`, count))

# bar plot frequencies
ggplotly(
ggplot(PsychABCD_comb %>% mutate(Frequency = count), aes(x=`Dimension Combination`, y=Frequency)) +
  geom_bar(stat="identity", fill="grey14") +
  ggtitle("Compound Dimension Frequencies") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
)
```

<br>
<div class="alert alert-warning">
<strong><i class="fa fa-exclamation-triangle"></i> To Do: Alternative needed (?)</strong> <br>
Parallel coordinates plot is frequently recommended in the literature of multidimensional visualizations but does not paint a clear picture here - in my opinion. Look for alternative.
</div>

```{r PsychABCDParallelCoordinates, message=F, fig.cap="Parralel coordinate graph showcasing the dimension combinations."}
# frequency of unique combinations
dt.psych.included %>%
  dplyr::select(Affect, Behavior, Cognition, Desire) %>%
  group_by(Affect, Behavior, Cognition, Desire) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  mutate(id = letters[1:nrow(.)]) %>%
  gather(ABCD, value, -c(id, count)) %>%
  ggplot(aes(x = ABCD,y = value, group = id, color = id, size = count)) +
  geom_line(position = position_jitter(w=0.02, h=0.04), 
            alpha = .3) +
  scale_size(range = c(0.7, 5)) +
  #scale_color_viridis_c(option = "inferno", direction = -1)+
  scale_y_continuous(breaks=c(0,1),
                     labels=c("No", "yes")) +
  guides(color = FALSE) +
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"))
```

```{r PsychDimensionNetwork, fig.cap="Network graph of the dimension frequencies and co-occurences. The nodes (i.e., circles) represent the concepts so that the size of the circle indicates the number of times concept was coded and the edges (i.e., connections) represent the co-occurences so that the width of the line indicates how often the concepts were measured in one scale."}
# make crossproduct matrix to condense co-occurrences (off-diagonals) and get frequencies (diagonals)
PsychDim <- as.matrix(dt.psych.included %>% 
                 dplyr::select(Affect, Behavior, Cognition, Desire) %>% 
                 mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)))
PsychDim <- crossprod(PsychDim)  # Same as: t(X) %*% X
#diag(out) <- 0       # remove frequencies on diagonals

# information on the concepts themselves
nodes <- data.frame(id    = colnames(PsychDim), 
                    title = paste0(colnames(PsychDim), "<br>Frequency: ", diag(PsychDim)), 
                    value = diag(PsychDim),
                    size  = diag(PsychDim),
                    shape = "dot")

# information on the co-occurrences
edges           <- as.data.frame(t(combn(colnames(PsychDim),2)))
colnames(edges) <- c('from','to')
edges$width     <- NA
for (i in 1:nrow(edges)) {
    edges$width[i] <- PsychDim %>%
      as.data.frame(.) %>%
      rownames_to_column('dim') %>%
      filter(dim == edges$to[i]) %>%
      dplyr::select(any_of(edges$from[i])) %>%
      as.numeric(.)
}
edges$label <- edges$width
edges$title <- paste0(edges$from, " - ", edges$to, "<br>Co-occurences: ", edges$width)

# plot network graph
visNetwork(nodes, edges %>% mutate(width = scales::rescale(edges$width, to=c(10,30))), 
           heigth = "100%", width = "100%", main = "Network Graph Empirical Phenomenological Dimensions") %>%
            visIgraphLayout(layout = "layout_in_circle") %>%
            visNodes(
                shape = "dot",
                color = list(
                    background = "#0085AF",
                    border = "#013848",
                    highlight = "#FF8000"
                )
            ) %>%
            visEdges(
                shadow = FALSE,
                color = list(color = "#0085AF", highlight = "#C62F4B")
            ) %>%
            visOptions(highlightNearest = list(enabled = T, degree = 1, hover = T), 
                       nodesIdSelection = list(main = "Select variable")) %>% 
            visInteraction(keyboard = TRUE, tooltipDelay = 0) %>%
            visLayout(randomSeed = 11)
```

### Domains  

We, again, coded which life domains the acculturation measures referred to, either as part of subscale labels, factor labels, explicit commentary of the authors, or clear question wordings (see Figure \@ref(fig:PsychDomainFrequencies)).  

```{r PsychDomainFrequencies, warning=F, fig.cap="Wordcloud of the scale domains in empirical results."}
# remove duplicate domains
UniqueDomains <- dt.Domains %>% 
  filter(Duplicate == "Unique")

# dataframe to compile domain frequency for Review Scales
PsychDomainFreq <- data.frame(UniqueDomains, Frequency = NA)

# count domain frequency in dt.Scales.Included
for (i in 1:nrow(UniqueDomains)) {
  PsychDomainFreq$Frequency[i] <- length(grep(UniqueDomains$Domain[i], dt.psych.included$domainScale, value = T))
}

# prepare for ggplot
PsychDomainFreq <- PsychDomainFreq %>%
  dplyr::select(Domain, Frequency) %>%
  filter(Frequency > 0) %>%
  arrange(Frequency) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Domain=factor(Domain, levels=Domain)) # update factor levels

# Word cloud frequencies
set.seed(7) # for reproducibility 
wordcloud(words = PsychDomainFreq$Domain, freq = PsychDomainFreq$Frequency, 
          min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
```

### Focus of the Paper  

For the empirical works we also coded the main focus of the papers. The wordcloud of the topics illustrates that although a majority of articles also have acculturation as their main focus, health and adjustment are also fields that measured acculturation in their empirical works (see Figure \@ref(fig:PsychTopicFrequencies)).  

```{r PsychTopicFrequencies, warning=F, fig.cap="Wordcloud of the article foci in the empirical results."}
# remove duplicate domains
UniqueDomains <- dt.Domains %>% 
  filter(Duplicate == "Unique")

# dataframe to compile domain frequency for Review Topics
PsychTopicFreq <- data.frame(UniqueDomains, Frequency = NA)

# count domain frequency in dt.Scales.Included
for (i in 1:nrow(UniqueDomains)) {
  PsychTopicFreq$Frequency[i] <- length(grep(UniqueDomains$Domain[i], dt.psych.included$domainPaper, value = T))
}

# prepare for ggplot
PsychTopicFreq <- PsychTopicFreq %>%
  dplyr::select(Domain, Frequency) %>%
  filter(Frequency > 0) %>%
  arrange(Frequency) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Domain=factor(Domain, levels=Domain)) # update factor levels

# Word cloud frequencies
set.seed(7) # for reproducibility 
wordcloud(words = PsychTopicFreq$Domain, freq = PsychTopicFreq$Frequency, 
          min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
```


### Countries 

Similar as for the validation studies we again coded the cultural context the empirical studies. Again, we coded both the migrants' country of origin as well as the country of the receiving society, in which the study was conducted (see Figure \@ref(fig:PsychCountryFreqTab)).  

```{r PsychCountryPrep, message=F}
# subset relevant variables
PsychMap <- dt.psych.included %>%
  dplyr::select(MeasureDefinition, HostCountry, OriginCountry)

# Host Countries: Find all individual country names and count frequency of occurrence
PsychHostCountryFreq <- data.frame(Country = unique(unlist(strsplit(PsychMap$HostCountry, ", "))), Frequency = NA, source = "Host")
for (i in 1:nrow(PsychHostCountryFreq)) {
  PsychHostCountryFreq$Frequency[i] <- length(grep(PsychHostCountryFreq$Country[i], PsychMap$HostCountry, value = T))
}
PsychHostCountryFreq <- PsychHostCountryFreq %>%
  #filter(Frequency > 0) %>%
  arrange(Frequency) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Country=factor(Country, levels=Country)) # update factor levels

# Origin Countries: Find all individual country names and count frequency of occurrence
PsychOriginCountryFreq <- data.frame(Country = unique(unlist(strsplit(PsychMap$OriginCountry, ", "))), Frequency = NA, source = "Origin")
for (i in 1:nrow(PsychOriginCountryFreq)) {
  PsychOriginCountryFreq$Frequency[i] <- length(grep(PsychOriginCountryFreq$Country[i], PsychMap$OriginCountry, value = T))
}
PsychOriginCountryFreq <- PsychOriginCountryFreq %>%
  #filter(Frequency > 0) %>%
  arrange(Frequency) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(Country=factor(Country, levels=Country)) # update factor levels

# combine Host and Origin list
PsychCountryFreq <- rbind(PsychOriginCountryFreq, PsychHostCountryFreq) %>%
  filter(!is.na(Country))

# For compound country categories look up all possible countries
countriesLatinAmerica  <- c("Mexico", 
                            "Guatemala", "Honduras", "El Salvador", "Nicaragua", "Costa Rica", "Panama", 
                            "Colombia", "Venezuela", "Ecuador", "Peru", "Bolivia", "Chile", "French Guiana", "Paraguay", "Brazil", "Argentina", "Uruguay", 
                            "Cuba", "the Dominican Republic", "Haiti", "Puerto Rico")
countriesHispanic      <- c("Argentina", "Bolivia", "Chile", "Colombia", "Costa Rica", "Cuba", "Dominican Republic", "Ecuador", "El Salvador", "Guatemala", "Honduras", 
                            "Mexico", "Nicaragua", "Panama", "Paraguay", "Peru", "Puerto Rico", "Spain", "Uruguay", "Venezuela")
countriesArabic        <- c("Algeria", "Bahrain", "the Comoros", "Djibouti", "Egypt", "Iraq", "Jordan", "Kuwait", "Lebanon", "Libya", "Mauritania", "Morocco", "Oman",
                            "Palestine", "Qatar", "Saudi Arabia", "Somalia", "Sudan", "Syria", "Tunisia", "United Arab Emirates", "Yemen")
countriesSouthEastAsia <- c("Cambodia", "Laos", "Myanmar", "Malaysia", "Thailand", "Vietnam", "East Timor", "Indonesia", "Philippines", "Singapore", "Brunei")
countriesSouthAsia     <- c("Afghanistan", "Bangladesh", "Bhutan", "India", "Maldives", "Nepal", "Pakistan", "Sri Lanka")
countriesAsia          <- c("China", "India", "Indonesia", "Pakistan", "Bangladesh", "Japan", "Philippines", "Vietnam", "Turkey", "Iran", "Thailand", "Myanmar", "South Korea",
                            "Iraq", "Afghanistan", "Saudi Arabia", "Uzbekistan", "Malaysia", "Yemen", "Nepal", "North Korea", "Sri Lanka", "Kazakhstan", "Syria", "Cambodia",
                            "Jordan", "Azerbaijan", "United Arab Emirates", "Tajikistan", "Israel", "Laos", "Lebanon", "Kyrgyzstan", "Turkmenistan", "Singapore", "Oman",
                            "State of Palestine", "Kuwait", "Georgia", "Mongolia", "Armenia", "Qatar", "Bahrain", "Timor-Leste", "Cyprus", "Bhutan", "Maldives", "Brunei")
countriesFormerUDSSR   <- c("Armenia", "Azerbaijan", "Belarus", "Estonia", "Georgia", "Kazakhstan", "Kyrgyzstan", "Latvia", "Lithuania", "Moldova", "Russia", 
                            "Tajikistan", "Turkmenistan", "Ukraine", "Uzbekistan")
countriesAny <- c()
countriesMultiple <- c() 
```

```{r PsychCountryFreqTab, warning=F,  fig.cap="Bar graph of frequencies for host countries and countries of origin."}
# bar plot Host country frequencies
ggplotly(
ggplot(PsychCountryFreq , aes(x=Country, y=Frequency)) +
  geom_bar(stat="identity", fill="grey14") +
  coord_flip()+
  facet_wrap( ~ source, nrow = 1) +
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none"),
height = 1700)
```

<!-- <br> -->
<!-- <div class="alert alert-warning"> -->
<!-- <strong><i class="fa fa-exclamation-triangle"></i> To Do!</strong> <br> -->
<!-- Worldmap still needs to be filled. -->
<!-- </div> -->

<!-- ```{r PsychMigrationMap, message=F, fig.cap="Plan: worldmap visualization to showcase migrant flows investigated during empirical studies."} -->
<!-- # load worldmap data from Natural Earth Project -->
<!-- world.data <- rnaturalearth::ne_countries(scale = "medium", returnclass = "sf") -->

<!-- # plot worldmap -->
<!-- ggplot(data = world.data) + -->
<!--   geom_sf(fill= "antiquewhite") + -->
<!--   xlab("Longitude") + ylab("Latitude") + -->
<!--   ggtitle("World map (to be filled with data)", subtitle = paste0("(", length(unique(world.data$name)), " countries)")) + -->
<!--   annotation_scale(location = "bl", width_hint = 0.25) + -->
<!--   annotation_north_arrow(location = "bl", which_north = "true",  -->
<!--                          pad_x = unit(0.5, "in"), pad_y = unit(0.5, "in"), -->
<!--                          style = north_arrow_fancy_orienteering) + -->
<!--   theme(panel.grid.major = element_line(color = gray(.5), linetype = "dashed", size = .2),  -->
<!--         panel.background = element_rect(fill = "aliceblue")) -->
<!-- ``` -->


### Analysis

Finally, we also coded what kind of analyses the authors conducted with the acculturation measurements in the empirical studies (see Table \@ref(tab:PsychAnalysis)).  

```{r PsychAnalysis}
# tally different migration times
data.frame(table(dt.psych.included$MainAnalysis)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Main Analysis in which Acculturation Measure was used",
      format = "html",
      col.names = c("Analysis",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

Additionally, we coded where in the model the acculturation measure was placed (see Table \@ref(tab:PsychVarType)).  

```{r PsychVarType}
# tally different migration times
data.frame(table(dt.psych.included$VariableType)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Variable Type of Acculturation Measure",
      format = "html",
      col.names = c("Variable Type",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

## **Empirical: Keywords & Fields**  

To assess the differences between fields we merged the [Scimago Journal Ranking Database](https://www.scimagojr.com/journalrank.php) with our empirical review. For all available <ins>journal articles</ins> we added information on key journal metrics:  

- Scimago Journal Rank Indicator (_SJR_, year-average weighted citations of articles published in past 3-year period)  
- H Index (h number of articles that have been cited at least h times)  
- Number of articles published in 2019  
- Number of articles published in 2017, 2018, 2019  
- Number of references in published articles (2019)  
- Number of citations in 2016-2018  
- Number of citable documents 2016-2018  
- Average number of citations per document in a 2-year period  
- Average number of references per document in 2019  
- Country of publisher  
- Region of publisher  
- Time period of journal activity (_Coverage_)  
- Keywords (_Categories_)  
- Field  

### Journals  

_Note_ that dissertations, book chapters, and books were excluded from this analysis because data on their publishers is not readily available or unreliable. Additionally, `r nrow(psychData %>% filter(PublicationType == "journalArticle", is.na(PublicationTitleDb)) %>% dplyr::select(PublicationTitle) %>% unique())` journals were not included in the Scimago database (likely because they do not have an ISSN identifier or were discontinued before 1996; see Table \@ref(tab:MissingJournalTab) for the missing Journals).    

```{r MissingJournalTab, results='asis', warning=F, message=F}
psychData %>% 
  filter(PublicationType == "journalArticle", 
         is.na(PublicationTitleDb)) %>%
  dplyr::select(`Journal Name` = PublicationTitle) %>%
  unique() %>%
  kbl(., caption = "Journal Information Missing in Scimago Journal Ranking",
      format = "html", row.names = FALSE) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

This meant that we ultimately had journal metrics for `r nrow(psychData %>% filter(!is.na(PublicationTitleDb)))` empirical articles. The frequencies of the journals, and a selection of their impact metrics is shown in Table \@ref(tab:JournalFreqTab).    

```{r JournalFreqTab, results='asis', warning=F, message=F}
psychDataJournal <- psychData %>% filter(!is.na(PublicationTitleDb))

psychDataJournal %>%
  dplyr::select(PublicationTitleDb, SJR, Hindex, TotalDocs3years, CitesDoc2years, RefDoc, PublisherCountry) %>%
  group_by(PublicationTitleDb, SJR, Hindex, TotalDocs3years, CitesDoc2years, RefDoc, PublisherCountry) %>%
  summarise(Frequency = n()) %>%
  arrange(desc(Frequency)) %>%
  dplyr::select(Journal = PublicationTitleDb, N = Frequency, SJR, CitesDoc2years, Hindex, RefDoc, TotalDocs3years, PublisherCountry) %>%
  kbl(., caption = "Journal Frequency",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
  footnote(general = "SJR = Scimago Journal Rank Indicator; 
           CitesDoc2years = Average number of citations per document in a 2-year period; 
           Hindex = H Index (h number of articles that have been cited at least h times);
           RefDoc = Average number of references per document in 2019;
           TotalDocs3years = Number of articles published in 2017, 2018, 2019") %>%
   scroll_box(height = "500px")
```

<br>
To gain a broad understanding of the interest development we plotted the yearly average H Index (Figure \@ref(fig:JournalHTime)) and yearly average of the journals' citations per paper over time (Figure \@ref(fig:JournalHCite)). It should be noted that the citation per paper metric is based in the years of 2018/19 and might not represent the citation impact of the journals at the time of the publications. Yet the metric should offer a first insight into average level of journal outlet selected by the authors. Also note that confidence bands are only calculated for a yearly `N > 1` and only displayed with two or more consecutive years of data.  

```{r JournalHTime, fig.cap="Line graph of average H Index over time."}
library(ggrepel)
hTime <- psychDataJournal %>%
  dplyr::select(year, SJR, Hindex, TotalDocs3years, CitesDoc2years, RefDoc) %>%
  mutate(across(SJR:RefDoc, ~ as.numeric(gsub("," ,".", .x)))) %>%
  group_by(year) %>%
  summarise_at(vars(c("SJR", "Hindex", "TotalDocs3years", "CitesDoc2years", "RefDoc")), 
               list(mean = ~ mean(., na.rm = T),
                    sd = ~ sd(., na.rm = T), 
                    n = ~ sum(!is.na(.)), 
                    se = ~ sd(.,na.rm=TRUE)/sqrt(sum(!is.na(.))),
                    lwr = ~ mean(., na.rm = T) - 1.96*sd(.,na.rm=TRUE)/sqrt(sum(!is.na(.))),
                    upr = ~ mean(., na.rm = T) + 1.96*sd(.,na.rm=TRUE)/sqrt(sum(!is.na(.)))
  )) %>%
  mutate(label = paste0('N = ', SJR_n))

ggplot(hTime, aes(x=year, y = Hindex_mean)) + 
  geom_line() +
  geom_ribbon(aes(ymin=Hindex_lwr,ymax=Hindex_upr),alpha=0.3) +
  geom_point(size = .9) +
  #geom_text(aes(label=label),hjust=0.5, vjust=0) +
  geom_label_repel(data = hTime %>% filter(SJR_n <3),
                  aes(label = label),
                  box.padding   = .35, 
                  point.padding = .5,
                  force         = 10,
                  nudge_y       = -100,
                  segment.color = 'grey50') +
  #geom_histogram(bins = length(unique(dt.psych.included$year)), fill = "grey14")+
  ylab("Average H Index")+
  ylim(0, max(hTime$Hindex_upr[hTime$SJR_n>2], na.rm = T)+20) +
  xlab("Year") +
  ggtitle("Average H Index by publication year")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

```{r JournalHCite, fig.cap="Histogram of the publication year for all included results."}
ggplot(hTime, aes(x=year, y = CitesDoc2years_mean)) + 
  geom_line() +
  geom_ribbon(aes(ymin=CitesDoc2years_lwr,ymax=CitesDoc2years_upr),alpha=0.3) +
  geom_point(size = .9) +
  #geom_text(aes(label=label),hjust=0.5, vjust=0) +
  # geom_label_repel(data = hTime %>% filter(SJR_n <3),
  #                 aes(label = label),
  #                 box.padding   = .35, 
  #                 point.padding = .5,
  #                 force         = 10,
  #                 nudge_y       = -100,
  #                 segment.color = 'grey50') +
  #geom_histogram(bins = length(unique(dt.psych.included$year)), fill = "grey14")+
  ylab("Average citations/article (2 years)")+
  ylim(0,10) +
  xlab("Year") +
  ggtitle("Average journal citations/article over time")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

### Keywords  

In the Scimago database each journal is assigned a set of keywords capturing their publication topics. Assessing these might offer a better understanding of the types of Journal and readership that are targeted by the authors. We assess the frequency of keyword lists (i.e., combinations of keywords, see Table \@ref(tab:CategoryFreqCombTab)) as well as the frequency of all available individual keywords (see Table \@ref(tab:CategoryFreqTab)).  
_Note on possible follow-up_: It would be cool to use topic modeling (machine learning) to relate the Journal keywords to the domains and dimensions. For example, using [Latent Dirichlet allocation (LDA)](https://www.tidytextmining.com/topicmodeling.html).  

```{r CategoryFreqCombTab, results='asis', warning=F}
data.frame(table(gsub(" \\(Q[0-9]\\)", "", psychDataJournal$Categories))) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Keyword Combination Frequency",
      format = "html",
      col.names = c("Keyword",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
  scroll_box(height = "500px")
```

```{r CategoryFreqTab, results='asis', warning=F}
data.frame(table(unlist(str_split(gsub(" \\(Q[0-9]\\)", "", psychDataJournal$Categories), "; ")))) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Keyword Frequency",
      format = "html",
      col.names = c("Keyword",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
  add_footnote("_Note_ that journals can have multiple associated keywords.", notation = "none") %>%
  scroll_box(height = "500px")
```
  
### Fields  

Beyond the keywords, the Scimago database classifies each journal according to the _field(s)_ that the journal aims to address. These field codes aim to capture a higher level of academic classification (than the keywords). Importantly, (1) each journal can be be classified to address multiple fields and (2) the field include codes of fields (e.g., 'Social Sciences') as well as sub-fields (e.g., 'Social Psychology'). This leads to the case that there can be quite a lot of [overlap between fields](https://www.scimagojr.com/shapeofscience/) and journals cannot easily or readily be assessed in mutually exclusive subgroups. Yet, one of the aims of this review is to assess differences between fields and disciplines. We aim to address this issue in the following section (go to: ['Empirical: Disciplines'](#disciplines)). However, we first need to gain a better udnerstanding of the fields that are addressed by the journals -- both jointly and generally. We list the frequencies of all unique combinations (see Table \@ref(tab:FieldCombFreqTab), as well as the overall frequencies of all available field codes (see Table \@ref(tab:FieldFreqTab)).  

```{r FieldCombFreqTab, results='asis', warning=F}
data.frame(table(psychDataJournal$fields)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Fields Combination Frequency",
      format = "html",
      col.names = c("Field Combination",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

```{r FieldFreqTab, results='asis', warning=F}
data.frame(table(unlist(str_split(psychDataJournal$fields, "; ")))) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Fields Frequency",
      format = "html",
      col.names = c("Field",
                    "Frequency")) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
  add_footnote("_Note_ that journals can target multitple fields.", notation = "none")
```

To gain a more intuitive understanding of how the individual codes relate to the joint journal field codes we combined the previous two tables into a single Sankey diagram (see Figure \@ref(fig:parallelCat)). By highlighting a field category (e.g., Psychology) one gains an understanding of how many journals address the field and also compare the frequency of each of the fields in comparison with one another.    

<br>
<div class="alert alert-danger">
<strong><i class="fa fa-exclamation-triangle"></i> To Do: Find Alternative (?)</strong> <br>
N on either side off because Sankey flow charts originate from energy sciences where energy can't increase without external addition. Maybe visualizations of data flow charts. They should have the same problem because __the same__ information can to multiple targets.
</div>  

```{r parallelCat, results='asis', warning=F, message=F, fig.cap="Sankey graph showing the individual field frequencies and their combined composition in the journal codes."}

comb <- data.frame(table(source = psychDataJournal$fields))

CombList <- str_split(comb$source, "; ")

names(CombList) <- comb$source
links <- stack(CombList) %>%
  dplyr::select(source = ind, target = values)

links <- right_join(links, comb) %>%
  rename(value = Freq) %>%
  mutate(source = paste0("Journal: ", source)) #%>%
  #group_by(source) %>%
  #mutate(value = value/n()) %>%
  #ungroup()

# From these flows we need to create a node data frame: it lists every entities involved in the flow
nodes <- data.frame(
  name=c(as.character(links$source), 
  as.character(links$target)) %>% unique()
)
 
# With networkD3, connection must be provided using id, not using real name like in the links dataframe.. So we need to reformat it.
links$IDsource <- match(links$source, nodes$name)-1 
links$IDtarget <- match(links$target, nodes$name)-1

# Make the Network
sankeyNetwork(Links = links, Nodes = nodes,
              Source = "IDsource", Target = "IDtarget",
              Value = "value", NodeID = "name", 
              sinksRight=F, height= 800)
```
  
## **Empirical: Disciplines** {#disciplines}   
  
To summarize the articles further we then classified the field combinations into superordinate discipline codes. These discipline codes are based in part on U.S. Department of Education's National Center for Education Statistics [Classification of Instructional Programs (CIP)](https://nces.ed.gov/ipeds/cipcode/default.aspx?y=55), the U.K. Higher Education Statistics Agency [Joint Academic Coding System (JACS 3.0)](https://www.hesa.ac.uk/support/documentation/jacs/jacs3-principal), the Australian Bureau of Statistics' [Australian and New Zealand Standard Research Classification (ANZSRC 2020)](https://www.abs.gov.au/ausstats/abs@.nsf/0/5D99AEA1DD8AA8E0CA2574180005421C?Opendocument), as well as the [Fields of Knowledge Map](http://www.thingsmadethinkable.com/item/fields_of_knowledge.php) from the 'Things Made Thinkable' initiative.  

### Coding  

In a first step we used the highest categories available (Social Sciences, Arts and Humanities, Professions and Applied Sciences, Natural Sciences, Formal Sciences, and Multidisciplinary) to summarize the fields. The Scimago database included some superordinate discipline codes (i.e., Social Sciences, Arts and Humanities) so we used these if a single discipline code was chosen by a journal. We then recoded the fields that did not have a superordinate discipline code or had multiple (see Table \@ref(tab:DisciplinesRecode01), for the disciplines associated to each field combination).  

```{r DisciplinesRecode01, results='asis', warning=F, message=F}
socialSciences <- c("Business, Management and Accounting; Environmental Science; Social Sciences",
                    "Business, Management and Accounting; Psychology; Social Sciences", 
                    "Business, Management and Accounting; Social Sciences",
                    "Health Professions; Social Sciences",
                    "Medicine; Nursing; Psychology; Social Sciences",
                    "Medicine; Nursing; Social Sciences",
                    "Medicine; Psychology; Social Sciences",
                    "Medicine; Social Sciences",
                    "Neuroscience; Psychology; Social Sciences",
                    "Nursing; Social Sciences",
                    "Psychology",
                    "Psychology; Social Sciences",
                    "Social Sciences")

artsHumanities <- c("Arts and Humanities; Medicine; Psychology",
                    "Arts and Humanities; Psychology")

naturalSciences <- c()
formalSciences <- c()

professionsAppliedSciences <- c("Business, Management and Accounting",
                                "Medicine", 
                                "Medicine; Neuroscience",
                                "Medicine; Nursing",
                                "Nursing")

crossDisciplinary <- c("Arts and Humanities; Medicine; Social Sciences",
                       "Arts and Humanities; Psychology; Social Sciences",
                       "Arts and Humanities; Social Sciences",
                       "Biochemistry, Genetics and Molecular Biology; Medicine; Psychology", 
                       "Business, Management and Accounting; Decision Sciences; Psychology",
                       "Medicine; Psychology",
                       "Multidisciplinary")

other <- c()

disciplines01 <- data.frame(fields = c(socialSciences, 
                                       artsHumanities, 
                                       naturalSciences, 
                                       formalSciences, 
                                       professionsAppliedSciences, 
                                       crossDisciplinary, 
                                      other),
                         discipline01 = c(rep("Social Sciences", length(socialSciences)),
                                          rep("Arts and Humanities", length(artsHumanities)),
                                          rep("Natural Sciences", length(naturalSciences)),
                                          rep("Formal Sciences", length(formalSciences)),
                                          rep("Professions and Applied Sciences", length(professionsAppliedSciences)),
                                          rep("Multidisciplinary / Crossdisciplinary", length(crossDisciplinary)),
                                          rep("Other", length(other)))
                         )

psychDataDisciplines <- right_join(psychDataJournal, disciplines01)

disciplines01 %>%
  kbl(., caption = "Coding Schema for Disciplines (Version #1)",
      format = "html",
      col.names = c("Fields",
                    "Discipline #1")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")
```

Categorization in this -- highest order -- manner led to the following subgroup frequencies (see Table \@ref(tab:Disciplines01FreqTab)):  

```{r Disciplines01FreqTab, results='asis', warning=F}
data.frame(table(psychDataDisciplines$discipline01)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Discipline Frequency (Version #1)",
      format = "html",
      col.names = c("Discipline #1",
                    "Frequency")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")
```

This higher-order discipline-coding had two major concerns. Firstly, the category of 'Social Sciences' was too large and heterogeneous and secondly, the medical and health related fields were not sufficiently distinguished from the other categories (i.e., either as part of 'Social Sciences' or 'Applied Sciences'). We, therefore, created a second discipline coding breaking the 'Social Sciences' and 'Applied Sciences' categories into major fields (psychology; business;  medicine, nursing, & health). We retained the possibility of miscellaneous social sciences, arts and humanities, as well as multidisciplinary field codes (see Table \@ref(tab:DisciplinesRecode02), for the discipline codes associated with each fields code).    

```{r DisciplinesRecode02, results='asis', warning=F, message=F}
psychology <- c("Arts and Humanities; Psychology",
                "Arts and Humanities; Psychology; Social Sciences",
                "Psychology",
                "Psychology; Social Sciences",
                "Neuroscience; Psychology; Social Sciences")
business <- c("Business, Management and Accounting",
              "Business, Management and Accounting; Environmental Science; Social Sciences",
              "Business, Management and Accounting; Social Sciences")
medical <- c("Arts and Humanities; Medicine; Social Sciences",
             "Health Professions; Social Sciences",
             "Medicine", 
             "Medicine; Neuroscience",
             "Medicine; Nursing",
             "Medicine; Nursing; Social Sciences",
             "Medicine; Social Sciences",
             "Nursing",
             "Nursing; Social Sciences")
social <- c("Social Sciences")
arts <- c()
multi <- c("Arts and Humanities; Medicine; Psychology",
           "Arts and Humanities; Social Sciences",
           "Biochemistry, Genetics and Molecular Biology; Medicine; Psychology", 
           "Business, Management and Accounting; Decision Sciences; Psychology",
           "Business, Management and Accounting; Psychology; Social Sciences",
           "Medicine; Psychology",
           "Medicine; Psychology; Social Sciences",
           "Medicine; Nursing; Psychology; Social Sciences",
           "Multidisciplinary")

disciplines02 <- data.frame(fields = c(psychology, 
                                       medical, 
                                       business, 
                                       social, 
                                       arts, 
                                       multi),
                            discipline02 = c(rep("Psychology", length(psychology)),
                                             rep("Medicine, Nursing, & Health", length(medical)),
                                             rep("Business", length(business)),
                                             rep("Social Sciences (miscellaneous)", length(social)),
                                             rep("Arts and Humanities", length(arts)),
                                             rep("Multidisciplinary / Crossdisciplinary", length(multi)))
                         )

psychDataDisciplines <- right_join(psychDataDisciplines, disciplines02)

disciplines02 %>%
  kbl(., caption = "Coding Schema for Disciplines (Version #2)",
      format = "html",
      col.names = c("Fields",
                    "Discipline #2")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")

```

Re-categorization led to the following subgroup frequencies (see Table \@ref(tab:Disciplines02FreqTab)):  

```{r Disciplines02FreqTab, results='asis', warning=F}
data.frame(table(psychDataDisciplines$discipline02)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Discipline Frequency (Version #2)",
      format = "html",
      col.names = c("Discipline #2",
                    "Frequency")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")
```

Given the small number of 'Business' journals we reclassified these into the 'Social Sciences (miscellaneous)' category (see Table \@ref(tab:Disciplines02FreqTabAdj)).  

```{r Disciplines02FreqTabAdj, results='asis', warning=F}
psychDataDisciplines$discipline02[psychDataDisciplines$discipline02 == "Business"] <- "Social Sciences (miscellaneous)"

data.frame(table(psychDataDisciplines$discipline02)) %>%
  arrange(desc(Freq)) %>%
  kbl(., caption = "Discipline Frequency Ajusted",
      format = "html",
      col.names = c("Discipline #2 (adjusted)",
                    "Frequency")) %>%
  kable_classic(full_width = F,
                lightable_options = "hover",
                html_font = "Cambria")
```

This coding resulted in `r length(unique(psychDataDisciplines$discipline02))` relatively well-balanced categories with non of the fields having too few observations. In the following sections we use these discipline codes to assess some general differences in assessing and addressing acculturation.    

### Acculturation Terms    

We first assess which terms the different disciplines use most frequently to describe the cultural adaptation process. We list the main terms the authors used in their paper to refer to cultural adaptation in Table \@ref(tab:PsychDisciplineTerm).  

```{r PsychDisciplineTerm, message=F, warning=F}
psychDataDisciplines %>%
  dplyr::select(discipline02,term) %>%
  mutate(term = tolower(term)) %>%
  group_by(discipline02, Term = term) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  mutate_if(is.numeric, funs(replace_na(., ""))) %>%
  dplyr::select(Term, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Terms used per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Data Collection Methods    

We then compare the data collection methods most frequently used by the authors in the different disciplines (see Table \@ref(tab:PsychDisciplineCollectionType) and Figure \@ref(fig:PsychDisciplineBarMethod)).   

```{r PsychDisciplineCollectionType, message=F, warning=F}
psychDataDisciplines %>%
  dplyr::select(discipline02, Method) %>%
  mutate(Method = tolower(Method)) %>%
  group_by(discipline02, Method) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  mutate_if(is.numeric, funs(replace_na(., ""))) %>%
  dplyr::select(Method, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Method used per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```
  
```{r PsychDisciplineBarMethod, warning=F, messages=F,fig.cap="Stacked bar chart of data collection method by discipline."}
ggstatsplot::ggbarstats(
  data = psychDataDisciplines,
  x = Method,
  y = discipline02,
  #sampling.plan = "jointMulti",
  title = "Data Collection Method by Discipline",
  xlab = "Discipline",
  package = "wesanderson",
  palette = "Darjeeling2",
  ggtheme = ggthemes::theme_tufte(base_size = 12),
  ggplot.component = list(scale_x_discrete(guide = guide_axis(n.dodge = 2))),
  ggstatsplot.layer = FALSE,
  label.args = list(check_overlap = TRUE, alpha = 1, fill = "white"),
  messages = FALSE
)
# ggstatsplot::ggbarstats(
#   data = psychDataDisciplines,
#   x = Method,
#   y = discipline02,
#   sampling.plan = "jointMulti",
#   title = "Data Collection Method by Discipline",
#   xlab = "Discipline",
#   legend.title = "Method",
#   #ggtheme = hrbrthemes::theme_ipsum_pub(),
#   ggplot.component = list(scale_x_discrete(guide = guide_axis(n.dodge = 2))),
#   palette = "Set2",
#   messages = FALSE
# )
```

### Measures    

We also assessed the use of different validated and novel measures used by authors in the various disciplines (see Table \@ref(tab:PsychDisciplineMeasure)). Note, again, that a majority of the measurements are not previously standardized and are not shared across articles and disciplines.  

```{r PsychDisciplineMeasure, message=F, warning=F}
psychDataDisciplines %>%
  dplyr::select(discipline02, MeasureDefinition) %>%
  mutate(MeasureDefinition = tolower(MeasureDefinition)) %>%
  group_by(discipline02, Measure = MeasureDefinition) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  mutate_if(is.numeric, funs(replace_na(., ""))) %>%
  dplyr::select(Measure, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Measure used per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "110%", height = "500px")
```
<br>
<div class="alert alert-warning">
<strong><i class="fa fa-exclamation-triangle"></i> To Do!</strong> <br>
It seems as if there are still some inconsistencies and spelling problems in the terms and measures.
</div>

### Interest over time    

As with the overall developments we also assessed the publication developments within the individual disciplines. Article ublication developments over time should indicate empirical interest in the topic of acculturation in the disciplines over time. We offer a global, developmental overview of the fields in Figure \@ref(fig:PsychDisciplineHistTime), as well as a visualization that further distinguishes between data collection types within the fields (see Figure \@ref(fig:PsychDisciplineHistTimeMethod)).  

```{r PsychDisciplineHistTime, fig.cap="Histogram of the publication year for all included results."}
discipline_labs_shrt <- c(
  'Psychology'="Psych.",
  'Medicine, Nursing, & Health'="Med.",
  'Social Sciences (miscellaneous)'="SocSci.",
  'Multidisciplinary / Crossdisciplinary'="Multi."
)

discipline_labs_lng <- c(
  'Psychology'="Psychology",
  'Medicine, Nursing, & Health'="Medicine",
  'Social Sciences (miscellaneous)'="Social Sci.",
  'Multidisciplinary / Crossdisciplinary'="Multidiscipl."
)


ggplotly(
ggplot(psychDataDisciplines, aes(x=year)) + 
  geom_histogram(binwidth = .9, fill = "grey14")+
  facet_grid(rows = vars(discipline02), labeller = as_labeller(discipline_labs_shrt)) +
  ylab("Number of Results") +
  xlab("Year") +
  ggtitle("Publication Year of Results")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
)
```

```{r PsychDisciplineHistTimeMethod, warning=F, fig.cap="Density plot of the yearly publication frequency for by data collection method."}
ggplotly(
ggplot(psychDataDisciplines, aes(x=year, color = Method)) + 
  #geom_density(aes(y = ..count..)) +
  geom_line(stat='count') +
  geom_point(stat='count', size = .9) +
  facet_grid(rows = vars(discipline02), labeller = as_labeller(discipline_labs_shrt)) +
  ylab("Number of Results")+
  xlab("Year") +
  ggtitle("Data Collection Method by Discipline over Time")+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="bottom", legend.title = element_blank())
) %>%
  layout(legend = list(orientation = "h", x = 0.4, y = -0.2))
```

### Sample  

To gain a deeper understanding of the study setups in the empirical studies we coded the type of sample recruited within each of the disciplines (see Figure \@ref(fig:PsychDisciplineSampleFreq)).  

```{r PsychDisciplineSampleFreq, message=F, fig.cap="Bar graph of the study samples used in the empirical studies. Note: general = any migrant from specified country (no targeting)."}
# tally different samples
psychDataDisciplines %>%
  dplyr::select(discipline02, Sample) %>%
  group_by(discipline02, Sample) %>%
  summarise(Frequency = n()) %>%
  drop_na() %>%
  ggplot(data = ., aes(x=reorder(Sample, Frequency), y=Frequency)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    aes(label = round(Frequency,0), y = Frequency + 6),
    position = position_dodge(0.9),
    hjust = 0.5) +
  facet_grid(cols = vars(discipline02), labeller = as_labeller(discipline_labs_lng)) +
  xlab("Sample") +
  ylab("Frequency") +
  ylim(0,50) +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

Again the category *general* refers to a sampling strategy in which any consenting adult would be able to participate in the study.  
Beyond the sample group itself we also coded which time point in the migration process was targeted within each discipline. Table \@ref(tab:PsychDisciplineMigrationTimeFreq) showcases that an overwhelming majority of studies targets migrants only after they had left their country of origin.  

```{r PsychDisciplineMigrationTimeFreq, message=F}
psychDataDisciplines %>%
  dplyr::select(discipline02, MigrationTime) %>%
  group_by(discipline02, MigrationTime) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  filter(!is.na(MigrationTime)) %>%
  mutate_if(is.numeric, funs(replace_na(., ""))) %>%
  dplyr::select(MigrationTime, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Migration time per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

<br>
Similarly, only a minority of studies included data on the acculturation process from the majority and migrant perspective jointly. And there is a stark contrast between the disciplines in how many of the total papers included the majority group (see Table \@ref(tab:PsychDisciplineMayority)).  

```{r PsychDisciplineMayority, message=F}
psychDataDisciplines %>%
  dplyr::select(discipline02, IncludesMajority) %>%
  mutate(`Includes Majority` = recode_factor(.$IncludesMajority, `0` = "no", `1` = "yes")) %>%
  group_by(discipline02, `Includes Majority`) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  filter(!is.na(`Includes Majority`)) %>%
  mutate_if(is.numeric, funs(replace_na(., ""))) %>%
  dplyr::select(`Includes Majority`, 
                Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Includes Majority per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

### Dimensions  

Again, a major focus of our coding was the role of affect, behavior, cognition, and desires in the each of the disciplines. Figure \@ref(fig:PsychDisciplineABCDFreq) shows how often each of the four dimensions was coded in each of the disciplines. _Note_ that in order better compare the disciplines we output percentages in most of the figures of this section.    

```{r PsychDisciplineABCDFreq, message=F, warning=F, fig.cap="Bar graph of the counts for each of the dimensions across all included empirical works."}
psychDataDisciplines %>%
  dplyr::select(discipline02, Affect, Behavior, Cognition, Desire) %>%
  gather(ABCD, Frequency, -discipline02) %>%
  group_by(discipline02, ABCD) %>%
  summarise_each(funs(sum(., na.rm = TRUE))) %>%
  ungroup() %>%
  group_by(discipline02) %>%
  mutate(Percentage = Frequency/sum(Frequency)*100) %>%
  ungroup() %>%
  ggplot(data = ., aes(x=reorder(ABCD, Percentage), y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    aes(label = round(Percentage,0), y = Percentage - 5),
    position = position_dodge(0.9),
    vjust = 0,
    color = "white") +
  facet_grid(cols = vars(discipline02), labeller = as_labeller(discipline_labs_lng)) +
  xlab("Dimension") +
  ylab("Percentage [in %]") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

Again, we also plot how often each of the dimensions were measured together. A bar graph of the compound frequencies in each discipline is shown Figure \@ref(fig:PsychDisciplineABCDCombFreq) and parallel coordinates graph is shown in Figure \@ref(fig:PsychDisciplineDimensionNetwork). Interestingly, there are certain dimensions and dimension combinations that are missing in some of the disciplines. There was, for example, not a single article in the psychological discipline that only measured behavioral acculturation a dimension that was important in all other disciplines.    

```{r PsychDisciplineABCDCombFreq, message=F, warning=F, fig.cap="Bar graph of the counts for each of the dimension combinations."}
psychDataDisciplines %>%
  dplyr::select(discipline02, Affect, Behavior, Cognition, Desire) %>%
  group_by(discipline02, Affect, Behavior, Cognition, Desire) %>%
  summarise(Frequency = n()) %>%
  ungroup() %>%
  group_by(discipline02) %>%
  mutate(Percentage = Frequency/sum(Frequency)*100) %>%
  ungroup() %>%
  mutate_at(.vars = c("Affect", "Behavior", "Cognition", "Desire"), funs(deparse(substitute(.))[.])) %>%
  unite("Dimension Combination", c(Affect, Behavior, Cognition, Desire), sep = ", ", na.rm = T) %>%
  ggplot(., aes(x=reorder(`Dimension Combination`, Percentage), y=Percentage)) +
  geom_bar(stat="identity", fill="grey14") +
  geom_text(
    aes(label = round(Percentage,0)),
    position=position_stack(vjust=0.5),
    color = "white",
    size = 3,
    vjust = 0.5) +
  facet_wrap(vars(discipline02), nrow = 2, labeller = as_labeller(discipline_labs_lng)) +
  ggtitle("Compound Dimension Percentages") +
  ylab("Percentage [in %]") +
  xlab("Dimension Combination") +
  coord_flip()+
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"),
        legend.position="none")
```

<br>
<div class="alert alert-warning">
<strong><i class="fa fa-exclamation-triangle"></i> To Do: Alternative needed (?)</strong> <br>
Parallel coordinates plot is frequently recommended in the literature of multidimensional visualizations but does not paint a clear picture here - in my opinion. Look for alternative.
</div>

```{r PsychDisciplineDimensionNetwork, message= F, fig.cap="Parallel coordinates plot showing all combinaitons of scale dimensions colored by discipline."}
library(viridis)
psychDataDisciplines %>%
  dplyr::select(Key, discipline02, Affect, Behavior, Cognition, Desire) %>%
  mutate_at(vars(Affect, Behavior, Cognition, Desire), ~replace_na(., 0)) %>%
  gather(ABCD, value, -c(Key, discipline02)) %>%
  ggplot(aes(x = ABCD,y = value, group = Key, color = discipline02)) +
  geom_path(position = position_jitter(w=0.02, h=0.04), 
            alpha = .2,
            size = 1) +
  scale_y_continuous(breaks=c(0,1),
                     labels=c("No", "yes")) +
  xlab("Dimension") +
  ylab("Dimension measured") +
  #scale_color_viridis(discrete = TRUE, option = "D") +
  # scale_color_discrete(name="Test",
  #                        labels=discipline_labs_lng) +
  scale_color_brewer(palette = "Set1", 
                     name="Discipline",
                     labels=discipline_labs_lng) +
  theme_Publication()+
  theme(strip.background =element_rect(fill="grey14", color="grey14"),
        strip.text = element_text(colour = 'white', face="bold"))
  
```

### Domains  

We also, again, coded which life domains the acculturation measures referred to within each of the disciplines. Again, these were life domains referred to either as part of subscale labels, factor labels, explicit commentary of the authors, or clear question wordings (see Table \@ref(tab:PsychDisciplineDomainTab) and Figure \@ref(fig:PsychDisciplineDomainFrequencies)).  

```{r PsychDisciplineDomainTab, warning=F, message=F}
psychDataDisciplines %>%
  dplyr::select(discipline02, domainScale) %>%
  group_by(discipline02, domainScale) %>%
  summarise(Frequency = n()) %>%
  arrange(desc(Frequency)) %>%
  filter(!is.na(domainScale)) %>%
  spread(discipline02, Frequency) %>%
  arrange(desc(Psychology)) %>%
  mutate_if(is.numeric, funs(replace_na(., ""))) %>%
  dplyr::select(Domain = domainScale, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Scale Domains used per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "100%", height = "500px")
```

```{r PsychDisciplineDomainFrequencies, warning=F, fig.cap="Wordcloud of the scale domains in empirical results.", fig.height=13}
# remove duplicate domains
UniqueDomains <- dt.Domains %>% 
  filter(Duplicate == "Unique")

# dataframe to compile domain frequency for Review Scales
PsychDomainFreq <- data.frame(UniqueDomains)

# count domain frequency in dt.Scales.Included
for (i in 1:nrow(UniqueDomains)) {
  PsychDomainFreq$Psychology[i] <- length(grep(UniqueDomains$Domain[i], 
                                               psychDataDisciplines$domainScale[psychDataDisciplines$discipline02=="Psychology"], 
                                               value = T))
  PsychDomainFreq$`Medicine, Nursing, & Health`[i] <- length(grep(UniqueDomains$Domain[i], 
                                               psychDataDisciplines$domainScale[psychDataDisciplines$discipline02=="Medicine, Nursing, & Health"], 
                                               value = T))
  PsychDomainFreq$`Social Sciences (miscellaneous)`[i] <- length(grep(UniqueDomains$Domain[i], 
                                               psychDataDisciplines$domainScale[psychDataDisciplines$discipline02=="Social Sciences (miscellaneous)"], 
                                               value = T))
  PsychDomainFreq$`Multidisciplinary / Crossdisciplinary`[i] <- length(grep(UniqueDomains$Domain[i], 
                                               psychDataDisciplines$domainScale[psychDataDisciplines$discipline02=="Multidisciplinary / Crossdisciplinary"], 
                                               value = T))
}

library(ggwordcloud)
set.seed(7) # for reproducibility 
PsychDomainFreq %>%
  dplyr::select(Domain,
                Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  gather(discipline02, Frequency, -Domain) %>%
  filter(Frequency>0) %>%
ggplot( ., aes(label = Domain, size = Frequency, color = Frequency)) +
  geom_text_wordcloud_area(shape = 'circle', rm_outside = TRUE, eccentricity = 1) +
  scale_size(range = c(2,8)) +
  theme_minimal() +
  facet_wrap(~discipline02, ncol = 1)
```

### Focus of the Paper  

For the empirical works we also coded the main focus of the papers in each of the disciplines. The wordclouds of the topics within each discipline illustrate that the different disciplines also focus on different topics related to cultural adaptation (see Figure \@ref(fig:PsychDisciplineTopicFrequencies)).  

```{r PsychDisciplineTopicFrequencies, warning=F, fig.cap="Wordcloud of the article foci in the empirical results.", fig.height=12}
# remove duplicate domains
UniqueDomains <- dt.Domains %>% 
  filter(Duplicate == "Unique")

# dataframe to compile domain frequency for Review Scales
PsychDomainFreq <- data.frame(UniqueDomains)

# count domain frequency in dt.Scales.Included
for (i in 1:nrow(UniqueDomains)) {
  PsychDomainFreq$Psychology[i] <- length(grep(UniqueDomains$Domain[i], 
                                               psychDataDisciplines$domainPaper[psychDataDisciplines$discipline02=="Psychology"], 
                                               value = T))
  PsychDomainFreq$`Medicine, Nursing, & Health`[i] <- length(grep(UniqueDomains$Domain[i], 
                                               psychDataDisciplines$domainPaper[psychDataDisciplines$discipline02=="Medicine, Nursing, & Health"], 
                                               value = T))
  PsychDomainFreq$`Social Sciences (miscellaneous)`[i] <- length(grep(UniqueDomains$Domain[i], 
                                               psychDataDisciplines$domainPaper[psychDataDisciplines$discipline02=="Social Sciences (miscellaneous)"], 
                                               value = T))
  PsychDomainFreq$`Multidisciplinary / Crossdisciplinary`[i] <- length(grep(UniqueDomains$Domain[i], 
                                               psychDataDisciplines$domainPaper[psychDataDisciplines$discipline02=="Multidisciplinary / Crossdisciplinary"], 
                                               value = T))
}

library(ggwordcloud)
set.seed(7) # for reproducibility 
PsychDomainFreq %>%
  dplyr::select(Domain,
                Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  gather(discipline02, Frequency, -Domain) %>%
  filter(Frequency>0) %>%
ggplot( ., aes(label = Domain, size = Frequency, color = Frequency)) +
  geom_text_wordcloud_area(shape = 'circle', rm_outside = TRUE, eccentricity = 1) +
  scale_size(range = c(2,10)) +
  theme_minimal() +
  facet_wrap(~discipline02, ncol = 1)
```


### Countries 

Similar to our overall overview we also assessed whether different disciplines relied on different migrant regions or host countries. Again, we coded both the migrants' country of origin as well as the country of the receiving society, in which the study was conducted for each discipline (see Table \@ref(tab:PsychDisciplineCountryTab)).  

```{r PsychDisciplineCountryPrep, message=F}
# Host Countries: Find all individual country names and count frequency of occurrence
PsychHostCountryFreq <- data.frame(Country = unique(unlist(strsplit(psychDataDisciplines$HostCountry, ", "))), source = "Host")
for (i in 1:nrow(PsychHostCountryFreq)) {
  PsychHostCountryFreq$Psychology[i] <- length(grep(PsychHostCountryFreq$Country[i], 
                                               psychDataDisciplines$HostCountry[psychDataDisciplines$discipline02=="Psychology"], 
                                               value = T))
  PsychHostCountryFreq$`Medicine, Nursing, & Health`[i] <- length(grep(PsychHostCountryFreq$Country[i], 
                                               psychDataDisciplines$HostCountry[psychDataDisciplines$discipline02=="Medicine, Nursing, & Health"], 
                                               value = T))
  PsychHostCountryFreq$`Social Sciences (miscellaneous)`[i] <- length(grep(PsychHostCountryFreq$Country[i], 
                                               psychDataDisciplines$HostCountry[psychDataDisciplines$discipline02=="Social Sciences (miscellaneous)"], 
                                               value = T))
  PsychHostCountryFreq$`Multidisciplinary / Crossdisciplinary`[i] <- length(grep(PsychHostCountryFreq$Country[i], 
                                               psychDataDisciplines$HostCountry[psychDataDisciplines$discipline02=="Multidisciplinary / Crossdisciplinary"], 
                                               value = T))
}


# Origin Countries: Find all individual country names and count frequency of occurrence
PsychOriginCountryFreq <- data.frame(Country = unique(unlist(strsplit(psychDataDisciplines$OriginCountry, ", "))), 
                                     source = "Origin")
for (i in 1:nrow(PsychOriginCountryFreq)) {
  PsychOriginCountryFreq$Psychology[i] <- length(grep(PsychOriginCountryFreq$Country[i], 
                                               psychDataDisciplines$OriginCountry[psychDataDisciplines$discipline02=="Psychology"], 
                                               value = T))
  PsychOriginCountryFreq$`Medicine, Nursing, & Health`[i] <- length(grep(PsychOriginCountryFreq$Country[i], 
                                               psychDataDisciplines$OriginCountry[psychDataDisciplines$discipline02=="Medicine, Nursing, & Health"], 
                                               value = T))
  PsychOriginCountryFreq$`Social Sciences (miscellaneous)`[i] <- length(grep(PsychOriginCountryFreq$Country[i], 
                                               psychDataDisciplines$OriginCountry[psychDataDisciplines$discipline02=="Social Sciences (miscellaneous)"], 
                                               value = T))
  PsychOriginCountryFreq$`Multidisciplinary / Crossdisciplinary`[i] <- length(grep(PsychOriginCountryFreq$Country[i], 
                                               psychDataDisciplines$OriginCountry[psychDataDisciplines$discipline02=="Multidisciplinary / Crossdisciplinary"], 
                                               value = T))
}

# combine Host and Origin list
PsychCountryFreq <- rbind(PsychOriginCountryFreq, PsychHostCountryFreq) %>%
  filter(!is.na(Country)) %>%
  gather(disciplines02, Frequency, -c(Country, source)) %>%
  arrange(desc(Frequency))


PsychCountryFreqTab <- rbind(PsychOriginCountryFreq, PsychHostCountryFreq) %>%
  filter(!is.na(Country)) %>%
  arrange(source, desc(Psychology), Country) 
```

```{r PsychDisciplineCountryTab, message=F}
PsychCountryFreqTab %>% 
  dplyr::select(-source) %>%
  mutate_if(is.integer, list(~na_if(., 0))) %>%
  mutate_if(is.integer, funs(replace_na(., ""))) %>%
  kbl(., caption = "Migration time per discipline",
      format = "html",
      align = c("l","c", "c", "c", "c")) %>%
  pack_rows(index = table(PsychCountryFreqTab$source)) %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria") %>%
   scroll_box(width = "100%", height = "500px")
```

### Analysis

Finally, we also coded what kind of analyses the authors conducted with the acculturation measurements in each of the fields (see Table \@ref(tab:PsychDisciplineAnalysis)).  

```{r PsychDisciplineAnalysis, message=F}
psychDataDisciplines %>%
  dplyr::select(discipline02,MainAnalysis) %>%
  group_by(discipline02, Analysis = MainAnalysis) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  filter(!is.na(Analysis)) %>%
  arrange(desc(Psychology)) %>%
  mutate_if(is.numeric, funs(replace_na(., ""))) %>%
  dplyr::select(Analysis, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Analyses used per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```

Additionally, we coded where in the model the acculturation measure was placed most frequently in each of the disciplines (see Table \@ref(tab:PsychDisciplineVarType)).  

```{r PsychDisciplineVarType, message=F}

psychDataDisciplines %>%
  dplyr::select(discipline02, VariableType) %>%
  group_by(discipline02, `Variable Type` = VariableType) %>%
  summarise(Frequency=n()) %>%
  spread(discipline02, Frequency) %>%
  filter(!is.na(`Variable Type`)) %>%
  arrange(desc(Psychology)) %>%
  mutate_if(is.numeric, funs(replace_na(., ""))) %>%
  dplyr::select(`Variable Type`, Psychology, 
                `Medicine, Nursing, & Health`,
                `Social Sciences (miscellaneous)`,
                `Multidisciplinary / Crossdisciplinary`) %>%
  kbl(., caption = "Variable Type of Acculturation Measure per discipline",
      format = "html") %>%
  kable_classic(full_width = F, 
                lightable_options = "hover", 
                html_font = "Cambria")
```


# **Discussion**  

To be written.  

# **Notes**  

To Do:  

- Visualize migration patterns on map (from area to area; problem: meaningfully convert regions to countries)  
- Visualize ABCD co-occurrences meaningfully (alternative for network and parallel coordinates plots)  
- Fix Sankey illustration  
- Potentially: It would be cool to use topic modeling (machine learning) to relate the Journal keywords to the domains and dimensions. For example, using [Latent Dirichlet allocation (LDA)](https://www.tidytextmining.com/topicmodeling.html).  


</br>  

# References

